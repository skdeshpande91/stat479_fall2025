---
title: "Lecture 9: Expected Points Added & Multi-level Modeling"
format: html
execute: 
  cache: true
---


## Overview

### Accessing play-by-play NFL data

We will use of the play-by-play data available from the [**nflfastR**](https://www.nflfastr.com) package.

:::{.callout-warning}
If you haven't already done so, be sure to install the package using the code
```{r}
#| label: install-nflfastR
#| eval: false
install.packages("nflfastR")
```
:::
The package contains several functions for efficiently scraping NFL data and for pre-processing the play-by-play data.
In this lecture and in [Lecture 10](lecture10.qmd), we will work with pre-processed play-by-play data, which we can load into our R session using the function `[nflfastR::load_pbp()](https://www.nflfastr.com/reference/load_pbp.html)`.

```{r}
#| label: load-pbp
#| warning: false
pbp2024 <-
  nflfastR::load_pbp(season = 2024)
```
Each row of the table `pbp2024` corresponds to an individual play from the 2024-25 NFL season.
The data table contains information about `{r} nrow(pbp2024)` distinct plays.
Some columns of `pbp2024` contain game-level information like a unique identifer for the game (`game_id`); the week in which the game was played (`week`); whether the play took place in a regular season game (`season_type = "REG"`) or play-off game (`season_type="POST"`); and the identities of the home and away team (`home_team` and `away_team`).
Most of the other columns contain play-level information like a unique identifier for the play (`play_id`), 

A description of all the columns is available [here](https://www.nflfastr.com/articles/field_descriptions.html).


are self-explanatory like `game_id`, `week`, and `game_date`.
Other columns record information about the team that has possession of the ball at the start of the play (`posteam`) and the team that does not have possession at the start of the play `defteam`.


## Expected Points in Football

<!--
 Paraphrase from Section 1.1 of Yurko's paper 
-->
Paraphrasing @Yurko2019_nflWAR, the expected points framework uses historical data to *estimate* the average number of points eventually scored by teams in similar situations.
Similar to what we did in [Lecture 6](lecture06.qmd) with expected runs at the start and end of at-bats in baseball, the difference between the post-snap and pre-snap expected points is 
Generally speaking, plays that result in positive EPA are considered successful while plays resulting in negative EPA are not.

@Yurko2019_nflWAR introduced an expected points model that focused on predicting the next scoring event in the half after each play.
The "next score" responses, ignoring points after touchdown (PAT) attempts, are, with respect to the team in possession:
  * Touchdown (TD), which is worth 7 points
  * Field goal (FG), which is worth 3 points
  * Safety (SAF), which is worth 2 points
  * No score (NS), which worth 0 points
  * Opponent safety (oSAF), which is worth -2 points
  * Opponent field goal (oFG), which is worth -3 points
  * Opponent touch down (oTD), which is worth -7 points
 
Formally, for every play, collect features summarizing the state of the game in the $\boldsymbol{\mathbf{X}}.$
Typically, these features will include things like the time left in the half, the current score, the down and distance to the first down line, etc.

:::{.callout-note icon = false}

## Definition: Drive Outcome Probabilities

Given the state of the game at the beginning of a play $\boldsymbol{\mathbf{x}},$ within a drive, for each possible outcome $k \in \left\{\textrm{TD}, \textrm{FG}, \ldots, \textrm{oTD}\right\}$ let $\pi_{k}(\boldsymbol{\mathbf{x}})$ conditional probability that the drives containing plays characterized by $\boldsymbol{\mathbf{x}}$ end in outcome $k.$
We collect these probabilities into a vector $\boldsymbol{\pi}(\boldsymbol{\mathbf{x}}) = (\pi_{\textrm{TD}}(\boldsymbol{\mathbf{x}}), \ldots, \pi_{\textrm{oppFG}}(\boldsymbol{\mathbf{x}})).$  

:::

:::{.callout-note icon=false}
## Definition: Expected Points
Given a game state feature vector $\boldsymbol{\mathbf{x}}$ and vector of drive outcome probabilities $\boldsymbol{\pi}(\boldsymbol{\mathbf{x}}),$ the *expected points* $\textrm{EP}(\boldsymbol{\mathbf{x}})$ is 
$$
\begin{align}
\textrm{EP}(\boldsymbol{\mathbf{x}}) &=  7\times\pi_{\textrm{TD}}(\boldsymbol{\mathbf{x}}) + 
3\times\pi_{\textrm{FG}}(\boldsymbol{\mathbf{x}}) + 
2\times\pi_{\textrm{SAF}}(\boldsymbol{\mathbf{x}}) \\
~&~~-2\times\pi_{\textrm{oSAF}}(\boldsymbol{\mathbf{x}}) - 
3\times\pi_{\textrm{oFG}}(\boldsymbol{\mathbf{x}})
7\times\pi_{\textrm{oTD}}(\boldsymbol{\mathbf{x}})
\end{align}
$$
:::


### Estimating $\textrm{EP}(\boldsymbol{\mathbf{x}})$

**nflfastR** implemented a version of @Yurko2019_nflWAR's original EP model.
At a high-level, it is a multinomial classification model built using extreme gradient boosting (xgboost).
Like random forests, Xgboost builds an ensemble of decision trees, each of which map a vector of game state feature $\boldsymbol{\mathbf{x}}$ to one of the next score outcomes $k.$
The final prediction is formed using the proportions of trees outputting a certain outcome.
More details are about **nflfastR**'s EP model are available [here](https://opensourcefootball.com/posts/2020-09-28-nflfastr-ep-wp-and-cp-models/).

### Basic uses of EPA
For each play in `pbp2024`, the column `epa` records the expected points added on the play.
We interpret plays with positive (resp. negative) `epa` values as successful (resp. unsuccessful) for the offensive team.
On this view, we mmight rank different teams' offenses by their average EPA per play
```{r}
pbp2024 |>
  dplyr::group_by(posteam) |> #<1>
  dplyr::summarize(epa = mean(epa, na.rm = TRUE)) |> #<2>
  dplyr::arrange(desc(epa)) |>
  dplyr::slice(c(1:5, (dplyr::n()-4):(dplyr::n()))) #<3>
```
1. Divide plays by offensive team
2. Compute the average EPA for each team's offense
3. Show only the top-5 and bottom-5 teams in terms of average EPA per play

Interestingly, the top three offenses in terms of average EPA (the Baltimore Ravens, Buffalo Bills, and Detroit Lions) were also the three highest scoring offenses in the 2024 season, each scoring over 30 points per game, on average.

## Predicting EPA on a new pass

The play with highest EPA in the 2024-25 season was a deep pass from Justin Herbert to L. McConkey that went 86 yards
At the start of the play, the Chargers were at their TO DO.
Based on **nflfastR**'s model, 
If Justin Herbert were to throw several more passes, would we expect all of them to result in an EPA of about 8.54? 


Extending this thought experiment a bit, based on the 2024-25 regular season data, how might we predict the EPA on future passing play?
Without any additional information about the play --- i.e., who threw the pass, how long the pass was, whether it was thrown out of the shotgun formation, etc. --- it seems reasonable to use the average EPA across all passing plays in our dataset.
But, if we knew the identity of the passers, we might reasonably expect the average EPA across their passes would be a better predicition.

To compute the league-wide and player-specific average EPAs, we first create a data table containing only the passing plays from the regular season.
We can do this by filtering on the variables `play_type` and `season_type`.
We see that there are about 19,000 pass plays in the regular season.
```{r}
#| label: play-type
table(pbp2024[,c("play_type", "season_type")])
```


In addition to EPA, we also include the unique identifier of the passer (`passer_player_id`) and a narrative description of the play (`desc`).
```{r}
#| label: player-only-df
pass2024 <- 
pass2024 <-
  pbp2024 |>
  dplyr::filter(play_type == "pass" & season_type == "REG") |> 
  dplyr::filter(!grepl("TWO-POINT CONVERSION ATTEMPT", desc) & #<1>
                  !grepl("sacked", desc) &
                  !grepl("direct snap", desc, ignore.case = TRUE)) |>
  dplyr::select(epa, passer_player_id, desc)
pass2024 |> dplyr::slice_head(n = 2)
```
1. For now, we will ignore 2-point conversion passing attempts. We also ignore sacks, and direct snaps, which **nflfastR** sometimes treat as passing plays

After excluding passes on two-point conversion attempts and sacks, we have data for `{r} nrow(pass2024)` passes thrown by `{r} length(unique(pass2024$passer_player_id))` players.
Across all passes and passers, the average EPA per pass is about 0.159.
```{r}
#| label: pooled-epa
mean(pass2024$epa)
```


### Computing player-specific EPA per pass

Given the vast spread of EPAs in our dataset (roughly -12.7 to 8.5), using the league-wide average of 0.159 to predict the EPA on a future pass is a bit unsatisfactory.
One avenue for improvement is to condition on additional information, like the identity of the passer, which is recorded in the column `passer_player_id`.
Eventually, we will want to look up player names using the identifiers stored in `passer_player_id`.
We can load a table containing roster information, including player identifier, name, position, and team using the function [`nflfastR::fast_scraper_roster()`]()
```{r}
#| label: load-roster
roster2024 <-
  nflfastR::fast_scraper_roster(seasons = 2024)
```


We will model the observed EPA on each passing play as a noisy observation of an underlying average EPA specific to each passer.
So, the EPA's on passes thrown by Dak Prescott, for instance, are treated as noisy measurements of his *average* EPA. 
We can then predict the EPA on a future pass thrown by Prescott using an estimate of his per-pass EPA.
We can further rank passers by their per-pass EPAs. 

Formally, suppose that we have data for $I$ unique passers[^I] and for each passer $i = 1, \ldots, I,$ let $n_{i}$ be the total number of passes thrown by passer $i.$
Further, for each $j = 1, \ldots, n_{i},$ let $Y_{ij}$ be the EPA on the the $j$-th pass thrown by passer $i.$
Let $\alpha_{i}$ be the underlying --- and as yet unknown --- average EPA for passer $i.$
We model $Y_{ij} = \alpha_{i} + \epsilon_{ij}$ where the random errors $\epsilon_{ij}$ have mean zero and are assumed to be independent across passers and passes.
[^I]: In our dataset $I=$`{r} length(unique(pass2024$passer_player_id))`.

While we can certainly run this calculation by grouping plays in `pass2024` by `passer_player_id` and then computing the average EPA of the plays involving each passer, for reasons that will hopefully become clear soon, we will instead estimate the $\alpha_{i}$'s by fitting a linear regression model with ordinary least squares.
Specifically, we will regress `epa` onto the *categorical* variable `passer_player_id`, which we will represent as a factor variable.
As alluded to earlier in [Lecture](), when run with a single categorical predictor, function `lm()` does not directly estimate the average outcome within each level of the predictor.
Instead, it returns the average outcome within one *reference* level of the predictor and the average *difference* in outcomes between the non-reference levels and the reference.
We will, rather arbitrarily, use Aaron Rodgers as the reference player.
```{r}
#| label: set-reference
rodgers_id <- 
  roster2024 |> 
  dplyr::filter(full_name == "Aaron Rodgers") |> 
  dplyr::pull(gsis_id) #<1>

pass2024 <-
  pass2024 |>
  dplyr::mutate(
    passer_player_id = factor(passer_player_id),
    passer_player_id = relevel(passer_player_id, ref = rodgers_id)) #<2>
```
1. Pull out Aaron Rodgers' id number
2. Set the reference level to Rodgers

We can now fit our linear model and collect the estimated parameters in the vector `ols_betas`.
Notice that the names of all but the first element of `ols_betas` contain the string "passer_player_id" and a player identifier. 
```{r}
#| label: fit-ols
ols_fit <-
  lm(formula = epa ~ 1 + passer_player_id, #<1>
     data = pass2024) #<2>
ols_betas <- coefficients(ols_fit)
ols_betas[1:5] #<3>
```
1. The `1+` is not strictly necessary (since R usually includes an intercept by default).
2. Because the `formula` argument only involves `epa` and `passer_player_id`, none of the other variables in `pass2024` are included as outcomes or predictors in the model
3. Print out a handful of parameter estimates

In our simple EPA model, the estimated intercept is exactly the average EPA on all passes thrown by Aaron Rodgers.
```{r}
mean( pass2024$epa[pass2024$passer_player_id == rodgers_id])
```
To get the average EPA on all passes thrown by a different quarterback (e.g., Dak Prescott whose id is `{r} roster24|> dplyr::filter(full_name == "Dak Prescott") |> dplyr::pull(gsis_id)`), we need to add the corresponding entry in `ols_beta` to the estimated intercept[^prove].

[^prove]: You can prove that computing group-level averages is mathematically equivalent to fitting a linear regression model with a single categorical predictor encoding group membership. Try doing this yourself or come by office hours if you'd like to see the derivation. 

```{r}
mean(pass2024$epa[pass2024$passer_player_id == "00-0033077"]) 
ols_betas["passer_player_id00-0033077"] + ols_betas["(Intercept)"]
```
We will repeat this calculation for each of the 101 unique passers in our data set and build a table `alphas` with columns containing the player's identifier, name, and average EPA on passing plays.
In the following code, we strip out the string "passer_player_id" from the names of `ols_beta`.

```{r}
#| label: build-alpha
names(ols_betas)[1] <- paste0("passser_player_id", rodgers_id) #<1>
names(ols_betas) <- 
  stringr::str_remove(string = names(ols_betas), pattern = "passer_player_id") #<2>
alphas <- 
  data.frame(gsis_id = names(ols_betas), ols = ols_betas) |> #<3>
  dplyr::mutate(ols = ifelse(gsis_id == rodgers_id, ols, ols + dplyr::first(ols))) |> #<4>
  dplyr::inner_join(y = roster2024 |> dplyr::select(gsis_id, full_name), by = "gsis_id")
```
1. Rename first element of `ols_beta` so its name follows the same format as the names of all other elements
2. Remove the string "passer_player_id" from all names of `ols_beta`
3. Facilitate a later join with `roster24`, which records player identifiers as `gsis_id`
4. Since the first row of `alphas` corresponds to Aaron Rodgers, we need to add the first element in the column `ols` to all other elements in the column. 

Somewhat surprisingly, the top- and bottom-five passers based on average EPA per play are not quarterbacks but include kickers.
What's going on??
```{r}
#| label: sort-ols
alphas |>
  dplyr::arrange(dplyr::desc(ols)) |>
  dplyr::slice(c(1:5, (dplyr::n()-4):dplyr::n()))
```
### Issues with our initial model

By this point in the course, you probably already suspect what's going on: the extreme average EPA estimates are an artifact of small sample sizes.
To verify that this is so, we'll add a column to `alphas` recording the number of passes thrown by each player.
```{r}
#| label: n_passes

n_passes <-
  pass2024 |>
  dplyr::group_by(passer_player_id) |> 
  dplyr::summarise(n = dplyr::n()) |> #<1>
  dplyr::rename(gsis_id = passer_player_id) #<2>

alphas <-
  alphas |>
  dplyr::inner_join(y = n_passes, by = "gsis_id")

alphas |>
  dplyr::arrange(dplyr::desc(ols)) |>
  dplyr::slice(c(1:5, (dplyr::n()-4):dplyr::n())) #<3>
```
1. Counts the number of passes thrown by each player in our dataset
2. So that we can join the counts to `alphas`, we need to rename the column recording the player identifiers
3. Look at the top-5 and bottom-5 rows

As anticipated, the passers with the top- and bottom-5 per-pass EPAs all threw 1 or 2 passes. 
For instance, AJ Cole is a punter who threw a single pass that ultimately gained 34 yards and resulted in a very large EPA of around 4.33.
```{r}
#| label: aj-cole
pass2024 |>
  dplyr::filter(passer_player_id == "00-0035190") |>
  dplyr::select(desc, epa)
```

Plotting each player's average EPA against the number of pass attempts reveals that there is a lot of (resp. very little) variation in EPA-per-pass amongst passers who threw a very small (resp. very large) number of passes.
```{r}
#| label: avg-plot
#| fig-width: 6.5
#| fig-asp: 0.5625
#| fig-align: center

oi_colors <- 
  palette.colors(palette = "Okabe-Ito")

par(mar = c(3,3,2,1), mgp = c(1.8, 0.5, 0))
plot(alphas$n, alphas$ols, 
     xlab = "Number of passes",
     ylab = "Avg. EPA per pass",
     main = "EPA per pass",
     pch = 16, cex = 0.5, col = oi_colors[1])
abline(h = mean(pass2024$epa), col = oi_colors[3])
```


### Towards partial pooling

Let's return to the problem of forecasting EPA on a single new pass based solely on the identity of the passer.
One option is to ignore the passer identity and just use the overall mean of about 0.159.
Doing so completely ignores differences between passers, which is fairly unreasonable given the large gaps in talent between NFL quarterbacks.
At the other extreme, we could use the player-specific average EPA estimates. 
While this approach acknowledges differences between players, it can sometimes lead to very extreme estimates.
Neither option seems particularly compelling.

As with most things, an ideal solution lies somewhere bewteen the two extremes.
For players who threw a large number of passes, we may be more comfortable using the their average EPA value since we are more *certain* about its value[^avg].
But for players who threw a very small number of passes, it's probably less risky to assume that they'll perform closer to the league-average rather than to rely on their potentially very noisy average EPA estimate[^cole].
And for players who threw a moderate number of passes, we might prefer a value somewhere between the league-wide average and the player-specific estimate.
[^avg]: Mathematically, we know that the average of 100 independent samples from some population has much more variance than the average of 10,000 independent samples from the same population.

[^cole]: Indeed, if AJ Cole, who is a punter, were to throw many more passes, do we really think he'd consistently add around 4 expected points? 

Formally, we can form such predictions with a weighted average: letting $\overline{y}$ be the overall league-wide average, we can predict the EPA on a new pass thrown by player $i$ using the quantity
$$
w_{i}\times \hat{\alpha}_{i} + (1 - w_{i}) \times \overline{y},
$$
where the weight $w_{i}$ depends on the number of passes thrown by player $i$ and how far $\hat{\alpha}_{i}$ differs from $\overline{y}.$

<!--
##

We can also use EPA to assess player performance.
Intuitively, we would more highly value offensive players who tend to produce positive EPA for their team.
As the quarterback is arguably the [most important offensive player](https://www.nfl.com/news/ranking-each-position-s-importance-from-quarterback-to-returner-0ap3000000503855), it is natural to start there.
In particular, we will try to determine how much EPA is due to the quarterback on each passing play.

We begin by first creating a data table containing only passing plays from the regular season using the column `play_type`
```{r}
#| label: play-type
table(pbp2024$play_type)
```








### An initial linear model






  Think about trying to forecast the EPA on another future pass.
  
  One option would be to use the overall grand mean $\overline{Y}$ of the observed averages.
  This is problematic 
  Alternatively, we might try to use the indi
  
  Intuitively, we might try to use $\hat{\alpha}_{i}.$
  Is this a reasonable estimate? A much more reasonable approach would involve "adjusting" the initial estimate so that players with very few pass attempts 
-->
##  Multi-level models


*Multi-level models* provide a prinipled way to compute such weights *automatically*. 
Like in our initial analysis, our first multilevel will model the observed EPA's as noisy measurements of some underlying player-specific parameter.
However, we make an additional model assumption: that the $\alpha_{i}$'s are themselves normally distributed around some grand mean $\alpha_{0}$ with standard deviation $\sigma_{\alpha}.$
We can specify our model in *two-levels*.

$$
\begin{align}
\textrm{Level 1}:\quad  Y_{ij} &= \alpha_{i} + \epsilon_{ij} \\
\textrm{Level 2:} \quad \alpha_{i} &= \alpha_{0} + u_{i}
\end{align}
$$

We can fit multi-level models using the [**lme4** package](https://cran.r-project.org/web/packages/lme4/index.html).
```{r}
multilevel_fit <-
  lme4::lmer(formula = epa ~ 1 + (1|passer_player_id),
             data = pass2024)
```

We can learn a lot based on the model summary
```{r}
#| label: multilevel-summary
summary(multilevel_fit)
```
In particular, we estimate the grand average EPA across all passes and all passers to be $\hat{\alpha}_{0} \approx 0.130.$
Moreover, our initial estimate of $\sigma,$ which captures the average variability of EPA that we'd see across passes thrown by a single player, is about 1.523
And our estimate of $\sigma_{\alpha}$, which captures the average variability across passers, is much much smaller (roughly 0.1232). 

We can use the function `ranef` to extract the estimates of the $u_{i}$'s and the function `coef` to extract the estimates of $\alpha_{i} = \alpha_{0} + u_{i}.$
The function `coef` returns a named list with one element per grouping variable[^grouping].
Each element of the `coef`'s output is a matrix 
```{r}
#| label: display-coef
tmp <- coef(multilevel_fit)
tmp[["passer_player_id"]] |> dplyr::slice_head(n = 5) #<1>
```
1. For brevity, we only display the first 5 rows

[^grouping]: For now, we are only using one grouping variable. But later in [Lecture 10](lecture10.qmd), we will have multiple grouping variables. 


We will append our multi-leve estimates to our data table `alpha`
```{r}
lmer_alpha <- #<1>
  data.frame( 
    lmer = tmp[["passer_player_id"]][,1], #<2>
    gsis_id = rownames(tmp[["passer_player_id"]])) #<3>

alphas <-
  alphas |>
  dplyr::inner_join(y = lmer_alpha, by = "gsis_id")

```
1. We'll create a data frame with columns containing the player identifier and their corresponding parameter estimate
2. In this case, the output of `coef` is a matrix with 1 column whose row names are just the levels of the grouping variable
3. For our eventual join, we will store the player's identifier as `gsis_id`


<!--
  This is by no means a comprehensive review
  I **highly** recommend checking out the Chapter 8 of the book *Beyond *, which you can find online [here](https://bookdown.org/roback/bookdown-BeyondMLR/ch-multilevelintro.html#twolevelmodeling).
  
-->

```{r}
#| label: shrinkage-plot
#| fig-width: 6.5
#| fig-asp: 0.5625
#| fig-align: center

oi_colors <- 
  palette.colors(palette = "Okabe-Ito")

par(mar = c(3,3,2,1), mgp = c(1.8, 0.5, 0))
plot(alphas$n, alphas$ols, 
     ylim = c(-4.5, 4.5),
     xlab = "Number of passes",
     ylab = "Avg. EPA per pass",
     main = "EPA per pass",
     pch = 16, cex = 0.5, col = oi_colors[1])
points(alphas$n, alphas$lmer, pch = 15, col = oi_colors[2], cex = 0.5)
abline(h = mean(pass2024$epa), col = oi_colors[3])
```
We see that our multilevel estimates for players who threw very few passes are are aggressively shrunk towards to the overall grand-mean.


<!--
### Motivation:
Grouped data, when we fit linear models there is an assumption about independence across observations
  In the context of our football data, there's actually quite a bit of grouping structure: play-to-play, it is not likely that the observations are similarly independent as they involve a lot of the same players.
If a player is very skilled, we would expect the outcome to be high.
-->
<!--
  Do a QB only model. We could fit a linaer model only to the data for QB 1; we can then look at the intercepts across players
  Level 2: asserts that in fact each alpha_i = alpha_0 + u_i 

  Fixed effects are the unknown population effects associated with certain covariates; in the case of an intercept only mode
  The individual alpha_i's serve to conceptually link Level 1 and Lever 2.
  Together, we can write this as a composite model

  random effects descrie levels of a factor that can be thought of a sample from a larger population of factor levels. 

  Useful to always start with a random intercept model.
  compare estimated variacne in within-person deviations to variance in between-person deviations. This gives rise to an intraclass correlation coefficient


-->


## Adjusting for additional covariates

Up to this point, we've worked with a rather toy problem, predicting EPA given only the identity of the passer.
But what if we include additional information about the pass (e.g., whether it was throw by the home or away team, whether it was thrown out of the shotgun formation, etc.)? 
Do we still run into the small sample size issues when determining how much EPA an individual player adds, after accounting for this other information?

To see, we re-build our data table `pass2024` but now include: 
  * `air_yards`: the distance traveled by the pass through the air[^airyard]
  * `shotgun`: whether the pass was thrown out of the [shotgun formation](https://en.wikipedia.org/wiki/Shotgun_formation)
  * `qb_hit`: whether the quarterback was hit while throwing
  * `no_huddle`: whether the play was run [without a huddle](https://en.wikipedia.org/wiki/Hurry-up_offense)
  * `posteam_type`: whether the home team had possession (i.e., was on offense)
  * `pass_location`: whether the pass was thrown to the left, right, or center of the field

```{r}
pass2024 <-
  pbp2024 |>
  dplyr::filter(play_type == "pass" & season_type == "REG") |> 
  dplyr::filter(!grepl("TWO-POINT CONVERSION ATTEMPT", desc) &
                  !grepl("sacked", desc) &
                  !grepl("direct snap", desc, ignore.case = TRUE)) |>
  dplyr::select(epa, passer_player_id, 
                air_yards, 
                posteam_type, shotgun, no_huddle, qb_hit,
                pass_location,
                desc)
pass2024 |> dplyr::slice_head(n = 2)
```

[^airyard]: @Yurko2015_nflWAR defines *air yards* as "the perpendicular distance in yards from the line of scrimmage to the yard line at which the receiver was targeted or caught the ball.

We can elaborate our initial models
$$
Y_{ij} = \alpha_{i} + x * \beta
$$

Adjusting for pass-level covariates, we can obtain least squares estimates of player spe
Under this model, $\alpha_{i}$ represents the additional bit of EPA that can be attributed to the passer over and above what can be explained by the 

First, we first a single-level model, which does not attempt to introduce any shrinkage.
We find that even after accounting for covariates, the estimates for passers with low samples sizes are fairly extreme.
```{r}
#| label: full-ols


ols_fit_full <- 
  lm(epa ~ passer_player_id + air_yards + posteam_type + shotgun +
       no_huddle + qb_hit + pass_location, data = pass2024)
ols_betas_full <- coefficients(ols_fit_full)

names(ols_betas_full)[1] <- paste0("passser_player_id", rodgers_id) 
names(ols_betas_full) <- 
  stringr::str_remove(string = names(ols_betas_full), pattern = "passer_player_id") 
alphas_full <- 
  data.frame(gsis_id = names(ols_betas_full), ols = ols_betas_full) |> 
  dplyr::mutate(ols = ifelse(gsis_id == rodgers_id, ols, ols + dplyr::first(ols))) |> 
  dplyr::inner_join(y = roster2024 |> dplyr::select(gsis_id, full_name), by = "gsis_id") |>
  dplyr::inner_join(y = n_passes, by = "gsis_id")

alphas_full |>
  dplyr::arrange(dplyr::desc(ols)) |>
  dplyr::slice(c(1:5, (dplyr::n()-4):dplyr::n())) 
```

We can similarly fit a more elaborate multi-level model in which $\alpha_{i} \sim N(\alpha_{0}, \sigma^{2}_{\alpha}).$

```{r}
#| label: multilevel-full

ml_fit_full <-
  lme4::lmer(formula = epa ~ 1 + (1|passer_player_id) + 
               air_yards + posteam_type + shotgun +
               no_huddle + qb_hit + pass_location, data = pass2024)

tmp <- coef(ml_fit_full)
lmer_alpha_full <- #<1>
  data.frame( 
    lmer = tmp[["passer_player_id"]][,1], #<2>
    gsis_id = rownames(tmp[["passer_player_id"]])) #<3>

alphas_full <-
  alphas_full |>
  dplyr::inner_join(y = lmer_alpha_full, by = "gsis_id")
alphas_full |>
  dplyr::arrange(dplyr::desc(lmer)) |>
  dplyr::slice(c(1:5, (dplyr::n()-4):dplyr::n())) 

```



## Looking ahead

[Next lecture](lecture10.qmd), we will fit a series of multi-level models.
We will then take the estimated player-specific effects


Up to this point, we fit models that gave all credit to the quarterback.
This is patently absurd.

We need to also allocate credit to recievers.

And we need to adjust for many many covariates

