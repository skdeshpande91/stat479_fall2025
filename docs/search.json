[
  {
    "objectID": "lectures/lecture4.html",
    "href": "lectures/lecture4.html",
    "title": "Flexible regression: Building our own XG model",
    "section": "",
    "text": "Last lecture, we fit two very basic models for XG. The first used only body part to predict the probability of the shot resulting in a goal while the second used both body part and shot technique. By looking at a few of Beth Mead’s shots from EURO 2022, we decided that the second model was a better because it assigned a higher XG to her one-on-one lob than the shot through multiple defenders. In this lecture, we will\nLike in Lecture 3, we will work with all shot event data from women’s international competitions that StatsBomb makes publicly available. As before, we make sure to load the tidyverse suite of packages and define a color-blind friendly palette.\n\nlibrary(tidyverse)\n# save a nice color-blind friednly color palette into our environment\noi_colors &lt;- palette.colors(palette = \"Okabe-Ito\") \n\nUsing some code from Lecture 3, we load in all the shot event data and create a binary outcome recording whether the shot resulted in a goal.\n\nwi_shots &lt;-\n  StatsBombR::FreeCompetitions() |&gt; # get table of available competitions\n  filter(competition_gender == \"female\" & competition_international)|&gt; # filter to women's internationals\n  StatsBombR::FreeMatches() |&gt; # Gets match data for all women's internationals\n  StatsBombR::free_allevents() |&gt; # Gets all events for all matches\n  StatsBombR::allclean() |&gt; # Apply StatsBomb's pre-processing\n  StatsBombR::get.opposingteam() |&gt;\n  filter(type.name == \"Shot\" & shot.body_part.name != \"Other\") |&gt;  # Subsets only shot event data\n  mutate(Y = ifelse(shot.outcome.name == \"Goal\", 1, 0))\n\nWe will also construct the two simple XG models, one that conditions only on body part and the other that conditions on body part and technique. We then use a join to add a column\n\nxg_model1 &lt;- \n  wi_shots |&gt;\n  group_by(shot.body_part.name) |&gt;\n  summarize(XG1 = mean(Y))\nxg_model2 &lt;-\n  wi_shots |&gt;\n  group_by(shot.body_part.name, shot.technique.name) |&gt;\n  summarise(XG2 = mean(Y), .groups = \"drop\") \n\nwi_shots &lt;-\n  wi_shots |&gt;\n  left_join(y = xg_model1, by = c(\"shot.body_part.name\")) |&gt;\n  left_join(y = xg_model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))",
    "crumbs": [
      "Flexible regression: Building our own XG model"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#overview",
    "href": "lectures/lecture4.html#overview",
    "title": "Flexible regression: Building our own XG model",
    "section": "",
    "text": "Last lecture, we fit two very basic models for XG. The first used only body part to predict the probability of the shot resulting in a goal while the second used both body part and shot technique. By looking at a few of Beth Mead’s shots from EURO 2022, we decided that the second model was a better because it assigned a higher XG to her one-on-one lob than the shot through multiple defenders. In this lecture, we will\nLike in Lecture 3, we will work with all shot event data from women’s international competitions that StatsBomb makes publicly available. As before, we make sure to load the tidyverse suite of packages and define a color-blind friendly palette.\n\nlibrary(tidyverse)\n# save a nice color-blind friednly color palette into our environment\noi_colors &lt;- palette.colors(palette = \"Okabe-Ito\") \n\nUsing some code from Lecture 3, we load in all the shot event data and create a binary outcome recording whether the shot resulted in a goal.\n\nwi_shots &lt;-\n  StatsBombR::FreeCompetitions() |&gt; # get table of available competitions\n  filter(competition_gender == \"female\" & competition_international)|&gt; # filter to women's internationals\n  StatsBombR::FreeMatches() |&gt; # Gets match data for all women's internationals\n  StatsBombR::free_allevents() |&gt; # Gets all events for all matches\n  StatsBombR::allclean() |&gt; # Apply StatsBomb's pre-processing\n  StatsBombR::get.opposingteam() |&gt;\n  filter(type.name == \"Shot\" & shot.body_part.name != \"Other\") |&gt;  # Subsets only shot event data\n  mutate(Y = ifelse(shot.outcome.name == \"Goal\", 1, 0))\n\nWe will also construct the two simple XG models, one that conditions only on body part and the other that conditions on body part and technique. We then use a join to add a column\n\nxg_model1 &lt;- \n  wi_shots |&gt;\n  group_by(shot.body_part.name) |&gt;\n  summarize(XG1 = mean(Y))\nxg_model2 &lt;-\n  wi_shots |&gt;\n  group_by(shot.body_part.name, shot.technique.name) |&gt;\n  summarise(XG2 = mean(Y), .groups = \"drop\") \n\nwi_shots &lt;-\n  wi_shots |&gt;\n  left_join(y = xg_model1, by = c(\"shot.body_part.name\")) |&gt;\n  left_join(y = xg_model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))",
    "crumbs": [
      "Flexible regression: Building our own XG model"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#from-pitch-by-pitch-to-plate-appearance",
    "href": "lectures/lecture4.html#from-pitch-by-pitch-to-plate-appearance",
    "title": "Lecture 4: Wins above Replacement I",
    "section": "From pitch-by-pitch to plate appearance",
    "text": "From pitch-by-pitch to plate appearance",
    "crumbs": [
      "Lecture 4: Wins above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#expected-runs",
    "href": "lectures/lecture4.html#expected-runs",
    "title": "Lecture 4: Wins above Replacement I",
    "section": "Expected Runs",
    "text": "Expected Runs\nOf the following two hypothetical at-bats, which do we think will generate more runs for the batting team\n\nThere are no outs and there are runners on all three bases.\nThere are 2 outs and there are no baserunners.\n\nWith runners on and no outs in the first scenario, there is a good chance of scoring at least one run if the batter gets a hit in the at-bat. By contrast, in the second scenario, it is perhaps more likely that the batting team scores no runs. On this view, batting teams would value the first scenario much more highly and fielding teams much prefer the second.\nWe can more precisely quantify this intuition using expected runs, which is a key tool used in sabermetrics. The expected runs \\(\\rho(\\textrm{o}, \\textrm{br})\\) is the average number of runs scored in the remainder of the half-inning following at-bats beginning with \\(\\textrm{o}\\) outs and baserunner configuration \\(\\textrm{br}.\\) We will encode baserunner configuration using a binary string of length 3. If there is a runner on first base, the first digit will be a 1 and if there is not a runner on first base, the first digit will be a 0. Similarly, the second and third digits respectively indicate whether there are runners on second and third base. So if \\(\\textrm{br} = \"011\"\\) that means that there are runners on second and third base at the beginning of the at-bat but not on first base. The raw StatCast data contains variables on_1b, on_2b, and on_3b. From a quick visual inspection of the dataset (e.g., with statcast2024$on_1b[1:100]), we find many NA values. These correspond to pitches when there is nobody on that particular base. When the value is not NA, it is the numeric id of the batting team player who is on that base. To create the 3-digit binary string encoding baserunner configuration, notice that 1*(!is.na(on_1b)) will return a 1 if there is somone on first base and 0 otherwise. So by pasting together the results of 1*(!is.na(on_1b)), 1*(!is.na(on_2b)), and 1*(!is.na(on_3b)), we can form the 3-digit binary string described above. In the codeblock below, we also rename the column outs_when_up to Outs.\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  mutate(\n    BaseRunner = \n      paste0(1*(!is.na(on_1b)),\n             1*(!is.na(on_2b)),\n             1*(!is.na(on_3b)))) %&gt;%\n  rename(Outs = outs_when_up)\n\nThere are 3 possible values for the number of outs (\\(\\textrm{o} \\in \\{0,1,2\\}\\)) and 8 possible values for the baserunner configuration (\\(\\textrm{br} \\in \\{\"000\", \"100\", \"010\", \"001\", \"110\", \"101\", \"011\", \"111\"\\}\\)). So, there are 24 different values of run expectancy, which is often presented in a table with rows corresponding to baserunner configuration and columns corresponding to outs.\n\nComputing \\(\\rho(\\textrm{o}, \\textrm{br})\\)\nFor each at-bat across these 2009 to 2023 seasons, we will compute the number of runs scored by the batting team in the remainder of the half-inning after every at-bat. Then, we will divide the at-bats into 24 groups, one for each combination of outs and baserunner configuration and compute the average number of runs scored in the remainder of the half-inning.\n\nComputing runs scored in the half-inning\nSuppose that in a given at-bat \\(a\\) that there are \\(n_{a}\\) pitches. Within at-bat \\(a,\\) for each \\(i = 1, \\ldots, n_{a},\\) let \\(R_{i,a}\\) be the number of runs scored in the half-inning after that pitch (including any runs scored as a result of pitch \\(i\\)). So \\(R_{1,a}\\) is the number of runs scored in the half-inning after the first pitch, \\(R_{2,a}\\) is the number of runs scored subsequent to the second pitch, etc. Our first step towards building the necessary at-bat-level data set will be to append a column of \\(R_{i,a}\\) values to each season’s StatCast data.\nWe start by illustrating the computation using a single half-inning from a single game. The code below pulls out all pitches thrown in the 8th inning of the March 20, 2024 game between the Dodgers and Padres. During this inning, the Dodgers scored 4 runs.\n\ndodgers_inning &lt;-\n  statcast2024 %&gt;%\n  filter(game_pk == 745444 & inning == 8 & inning_topbot == \"Top\") %&gt;%\n  select(at_bat_number, pitch_number, \n         bat_score, post_bat_score, events, description, des) %&gt;%\n  arrange(at_bat_number, pitch_number)\n\nThe column bat_score records the batting team’s score before each pitch is thrown. The column post_bat_score records the batting team’s score after the the outcome of the pitch. For most of the 25 pitches, we find that bat_score is equal to post_bat_score; this is because only a few pitches result in scoring events.\n\nrbind(bat_score = dodgers_inning$bat_score, post_bat_score = dodgers_inning$post_bat_score)\n\n               [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\nbat_score         1    1    1    1    1    1    1    1    1     1     1     1\npost_bat_score    1    1    1    1    1    1    1    1    1     1     1     1\n               [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\nbat_score          1     1     2     3     3     3     4     5     5     5\npost_bat_score     1     2     3     3     3     4     5     5     5     5\n               [,23] [,24] [,25]\nbat_score          5     5     5\npost_bat_score     5     5     5\n\n\nLooking at the play-by-play, we see that the Dodgers score their second run after the 14th pitch of the half-inning (on a Enrique Hernández sacrifice fly). They scored their third run on the very next pitch (Gavin Lux grounding into a fielder’s choice). They scored their fourth and fifth runs on consecutive pitches as well (on singles by Mookie Betts and Shohei Ohtani).\n We can verify this by looking at the variable des, which stores a narrative description about what happened during the at-bat.\n\ndodgers_inning$des[c(14,15, 18, 19)]\n\n[1] \"Enrique Hernández out on a sacrifice fly to left fielder José Azocar. Max Muncy scores.\"                                                                                             \n[2] \"Gavin Lux reaches on a fielder's choice, fielded by first baseman Jake Cronenworth. Teoscar Hernández scores. James Outman to 2nd. Fielding error by first baseman Jake Cronenworth.\"\n[3] \"Mookie Betts singles on a ground ball to left fielder José Azocar. James Outman scores. Gavin Lux to 2nd.\"                                                                           \n[4] \"Shohei Ohtani singles on a line drive to left fielder José Azocar. Gavin Lux scores. Mookie Betts to 2nd.\"                                                                           \n\n\nNotice that the maximum value of post_bat_score is the batting team’s score at the end of the inning1. Thus, to compute \\(R_{i,a}\\) for all pitches in this inning, it is enough to subtract the corresponding bat_score value from the maximum value of post_bat_score across the whole half-inning.\n\nmax(dodgers_inning$post_bat_score) - dodgers_inning$bat_score\n\n [1] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 1 0 0 0 0 0 0\n\n\nWe now append a column with these values to our data table dodgers_inning\n\ndodgers_inning &lt;-\n  dodgers_inning %&gt;%\n  mutate(RunsRemaining = max(post_bat_score) - bat_score)\n\nWe now need to extend these calculation to every half-inning of every game. To do this, we will take advantage of the group_by() command in dplyr to apply the same calculation to small groups defined by game and half-inning.\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  group_by(game_pk, inning, inning_topbot) %&gt;%\n  mutate(RunsRemaining = max(post_bat_score) - bat_score) %&gt;%\n  ungroup()\n\n\n\nFrom pitches to at-bats\nWe now have the number of runs scored in the half-inning after each pitch. But to compute run expectancy, we need this quantity at the at-bat level and not the pitch-level. Using our notation from before, note that \\(R_{1,a}\\) is the number of runs scored after the first pitch of at-bat \\(a.\\) So, to compute run expectancy, it is enough to pull out the first pitch from each at-bat (i.e., those pitches withpitch_number == 1) using the filter() function.\n\n\nPutting it all together\nWe can loop over the pitch-by-pitch data from multiple seasons, append \\(R_{i,a}\\) values to each one, and the number of outs, baserunner configuration, and \\(R_{1,a}\\) for each at-bat in that season. In the code below, we loop over each season and save the at-bat level run expectancy data in a list. Then we stack the data frames on top over each other using the bind_rows() command.\n\ner_data_list &lt;- list() # list of save at-bat level data for previous seasons\nfor(y in 1:2){\n  er_data &lt;-\n    get(paste0(\"statcast\", y+2021)) %&gt;%\n    filter(game_type == \"R\") %&gt;%\n    filter(strikes &gt;= 0 & strikes &lt; 3 & \n           balls &gt;= 0 & balls &lt; 4 & \n           outs_when_up &gt;= 0 & outs_when_up &lt; 3) %&gt;%\n    group_by(game_pk, inning, inning_topbot) %&gt;%\n    mutate(RunsRemaining = max(post_bat_score) - bat_score) %&gt;%\n    ungroup() %&gt;%\n    mutate(BaseRunner = \n             paste0(1*(!is.na(on_1b)), # 1st digit of string for baserunner\n                    1*(!is.na(on_2b)), # 2nd digit of string for baserunner\n                    1*(!is.na(on_3b)))) %&gt;% # 3rd digit of string for baserunner\n    arrange(game_pk, \n            inning, \n            desc(inning_topbot), # show bottom of innings before top\n            at_bat_number, pitch_number) %&gt;%\n    filter(pitch_number == 1) %&gt;%\n    rename(Outs = outs_when_up) %&gt;%\n    select(Outs, BaseRunner, RunsRemaining)\n er_data_list[[y]] &lt;- er_data\n rm(er_data)\n}\n# stack data from all previous seasons into one bit dataframe\ner_data_all &lt;- dplyr::bind_rows(er_data_list)\n\nWe can now group the rows of er_data_all by combinations of baserunner and outs to compute \\(\\rho(\\textrm{o}, \\textrm{br}).\\)\n\nexpected_runs &lt;-\n  er_data_all %&gt;%\n  group_by(Outs, BaseRunner) %&gt;%\n  summarize(rho = mean(RunsRemaining), .groups = \"drop\")\n\nFor reasons that will become clear shortly, we will create a new column that combines the out and baserunner configuration into a single string and will also add a new row for an end of inning (with corresponding \\(\\rho\\) value equal to 0)\n\nexpected_runs &lt;-\n  expected_runs %&gt;%\n  add_row(Outs=3, BaseRunner=\"000\", rho = 0) %&gt;%\n  mutate(obr_key = paste(Outs, BaseRunner, sep = \".\"))\n\n\n\n\nRun expectancy (RE24)\nParaphrasing from FanGraphs, Run Expectancy based on the 24 baserunner-out states (RE24) measures the change in expected runs from the beginning of a plate appearance to the end of the plate appearance. It also measures the For each at-bat, we now need to look at the run expectancy at the start of the at-bat, the run-expectancy at the end of the at-bat.\n\nRuns scored in each at-bat\nWe need to compute how many runs were scored during each at-bat. To do this, we can go back to our pitch-level data, group everything by at-bat number and look at the max(post_bat_score).\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  group_by(game_pk, at_bat_number) %&gt;%\n  mutate(RunsAB = max(post_bat_score) - bat_score) %&gt;%\n  ungroup()",
    "crumbs": [
      "Lecture 4: Wins above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#base-running",
    "href": "lectures/lecture4.html#base-running",
    "title": "Lecture 4: Wins above Replacement I",
    "section": "Base-running",
    "text": "Base-running\nQuote from Baumer et al. “baserunners should only get credit for advancement beyond what would be expected given their starting locations, number of outs, and the hitting event that occurred”  ### Expected base advancement",
    "crumbs": [
      "Lecture 4: Wins above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#batting",
    "href": "lectures/lecture4.html#batting",
    "title": "Lecture 4: Wins above Replacement I",
    "section": "Batting",
    "text": "Batting",
    "crumbs": [
      "Lecture 4: Wins above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture2.html",
    "href": "lectures/lecture2.html",
    "title": "Lecture 2: Expected Goals in Soccer",
    "section": "",
    "text": "Consider the following goals scored by Beth Meade during EURO 2022.\n\n\n\n\n\n\n\nWe can make these statements more quantiatively precise using expected goals\nDefinition of xG",
    "crumbs": [
      "Lecture 2: Expected Goals in Soccer"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#motivation-beth-meades-performance-at-euro2022",
    "href": "lectures/lecture2.html#motivation-beth-meades-performance-at-euro2022",
    "title": "Lecture 2: Expected Goals in Soccer",
    "section": "",
    "text": "Consider the following goals scored by Beth Meade during EURO 2022.\n\n\n\n\n\n\n\nWe can make these statements more quantiatively precise using expected goals\nDefinition of xG",
    "crumbs": [
      "Lecture 2: Expected Goals in Soccer"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#digression-conditional-probability",
    "href": "lectures/lecture2.html#digression-conditional-probability",
    "title": "Lecture 2: Expected Goals in Soccer",
    "section": "Digression: Conditional Probability",
    "text": "Digression: Conditional Probability",
    "crumbs": [
      "Lecture 2: Expected Goals in Soccer"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#working-with-statsbombs-xg",
    "href": "lectures/lecture2.html#working-with-statsbombs-xg",
    "title": "Lecture 2: Expected Goals in Soccer",
    "section": "Working with StatsBomb’s XG",
    "text": "Working with StatsBomb’s XG\n\nAs an illustration, here is a visualization of all of Beth Meade’s shots along with the associated XG value. Notice that some are very low and some are very high.",
    "crumbs": [
      "Lecture 2: Expected Goals in Soccer"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#goals-above-expected-team-based",
    "href": "lectures/lecture2.html#goals-above-expected-team-based",
    "title": "Lecture 2: Expected Goals in Soccer",
    "section": "Goals Above Expected (Team-Based)",
    "text": "Goals Above Expected (Team-Based)",
    "crumbs": [
      "Lecture 2: Expected Goals in Soccer"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#goals-above-expected-player-based",
    "href": "lectures/lecture2.html#goals-above-expected-player-based",
    "title": "Lecture 2: Expected Goals in Soccer",
    "section": "Goals Above Expected (Player-Based)",
    "text": "Goals Above Expected (Player-Based)\n\nMathematically, let \\(Y_{ij}\\) be the outcome of shot \\(j\\) taken by player \\(i\\) with \\(Y_{ij} = 1\\) if a goal is scored off that shot and \\(Y_{ij} = 0\\) otherwise. Additionally \\(\\textrm{XG}_{ij}\\) be the corresponding XG value for that shot.\nWe can compute the difference \\(y_{ij} - \\textrm{xg}_{ij}\\) for each shot that player \\(i\\) takes",
    "crumbs": [
      "Lecture 2: Expected Goals in Soccer"
    ]
  },
  {
    "objectID": "lectures/lecture1.html",
    "href": "lectures/lecture1.html",
    "title": "Lecture 1: Boxscore Metrics",
    "section": "",
    "text": "Who is the best shooter in the NBA? How do we determine this using data? \nIn this lecture, we will practice using functions from the tidyverse suite of packages (especially dplyr) to manipulate tables of NBA box score data. Hopefully, much of the functionality we encounter in this lecture will be familiar to you. But, if you need a high-level refresher, I highly recommend the following resources:\n\nChapter 3 and Chapter 5 of R for Data Science.\nSection 1.9 and Chapter 3 of *Data Science: A First Introduction.\n\nWe will use the package hoopR to scrape NBA boxscore data. You should install the package using the code install.packages(\"hoopR\").",
    "crumbs": [
      "Lecture 1: Boxscore Metrics"
    ]
  },
  {
    "objectID": "lectures/lecture1.html#overview",
    "href": "lectures/lecture1.html#overview",
    "title": "Lecture 1: Boxscore Metrics",
    "section": "",
    "text": "Who is the best shooter in the NBA?\nHow do we determine this using data? \n\n\nWhile they may be predictive, box score metrics are primarily retrospective: they tell (part of) the story of what happened.\n\n\n\nIn this lecture, we will practice using functions from the tidyverse suite of packages (especially dplyr) to manipulate tables of NBA box score data. Hopefully, much of the functionality we encounter in this lecture will be familiar to you. But, if you need a high-level refresher, I highly recommend the following resources:\n\nChapter 3 and Chapter 5 of R for Data Science.\nSection 1.9 and Chapter 3 of *Data Science: A First Introduction.\n\nWe will use\n\n\n\n\n\n\nSystem setup\n\n\n\n\n\nFor this lecture, we will use a new R package to scrape NBA boxscore data. In order to do this, it is critical that you have already installed the devtools package, as noted in the Getting Started guide. To check that you have successfully installed the package, run the following code.\n\nif(!\"devtools\" %in% rownames(installed.packages())){\n  stop(\"devtools not installed\")\n}",
    "crumbs": [
      "Lecture 1: Boxscore Metrics"
    ]
  },
  {
    "objectID": "lectures/lecture1.html#basic-box-score-statistics",
    "href": "lectures/lecture1.html#basic-box-score-statistics",
    "title": "Lecture 1: Boxscore Metrics",
    "section": "Basic box score statistics",
    "text": "Basic box score statistics\n\nScraping and wrangling box score data\nTo get all the boxscore data, we will use the function load_nba_player_box\n\nlibrary(tidyverse)\nraw_box &lt;-\n  hoopR::load_nba_player_box(seasons = 2002:(hoopR::most_recent_nba_season()))\n\nThe data table raw_box contains 813246 rows and 57 columns. Checking the column names, we see that there are columns for the numbers of field goals, three point shots, and free throws made and attempted.\n\ncolnames(raw_box)\n\n [1] \"game_id\"                           \"season\"                           \n [3] \"season_type\"                       \"game_date\"                        \n [5] \"game_date_time\"                    \"athlete_id\"                       \n [7] \"athlete_display_name\"              \"team_id\"                          \n [9] \"team_name\"                         \"team_location\"                    \n[11] \"team_short_display_name\"           \"minutes\"                          \n[13] \"field_goals_made\"                  \"field_goals_attempted\"            \n[15] \"three_point_field_goals_made\"      \"three_point_field_goals_attempted\"\n[17] \"free_throws_made\"                  \"free_throws_attempted\"            \n[19] \"offensive_rebounds\"                \"defensive_rebounds\"               \n[21] \"rebounds\"                          \"assists\"                          \n[23] \"steals\"                            \"blocks\"                           \n[25] \"turnovers\"                         \"fouls\"                            \n[27] \"plus_minus\"                        \"points\"                           \n[29] \"starter\"                           \"ejected\"                          \n[31] \"did_not_play\"                      \"active\"                           \n[33] \"athlete_jersey\"                    \"athlete_short_name\"               \n[35] \"athlete_headshot_href\"             \"athlete_position_name\"            \n[37] \"athlete_position_abbreviation\"     \"team_display_name\"                \n[39] \"team_uid\"                          \"team_slug\"                        \n[41] \"team_logo\"                         \"team_abbreviation\"                \n[43] \"team_color\"                        \"team_alternate_color\"             \n[45] \"home_away\"                         \"team_winner\"                      \n[47] \"team_score\"                        \"opponent_team_id\"                 \n[49] \"opponent_team_name\"                \"opponent_team_location\"           \n[51] \"opponent_team_display_name\"        \"opponent_team_abbreviation\"       \n[53] \"opponent_team_logo\"                \"opponent_team_color\"              \n[55] \"opponent_team_alternate_color\"     \"opponent_team_score\"              \n[57] \"reason\"                           \n\n\nNotice as well that there are columns for the game date (game_date), game id (game_id), and player (e.g., athlete_display_name). This suggests that each row corresponds to a unique combination of game and player and records the players individual statistics in that game.\nFor instance, here are the box score statistics for several players from a single game in 2011.\n\nraw_box |&gt;\n  filter(game_date == \"2011-06-12\") |&gt;\n  select(athlete_display_name, \n         field_goals_made, field_goals_attempted,\n         three_point_field_goals_made, three_point_field_goals_attempted,\n         free_throws_made, free_throws_attempted)\n\n── ESPN NBA Player Boxscores from hoopR data repository ───────── hoopR 2.1.0 ──\n\n\nℹ Data updated: 2025-07-16 06:37:20 CDT\n\n\n# A tibble: 30 × 7\n   athlete_display_name field_goals_made field_goals_attempted\n   &lt;chr&gt;                           &lt;int&gt;                 &lt;int&gt;\n 1 Dirk Nowitzki                       9                    27\n 2 Tyson Chandler                      2                     4\n 3 Jason Kidd                          2                     4\n 4 Shawn Marion                        4                    10\n 5 J.J. Barea                          7                    12\n 6 Brian Cardinal                      1                     1\n 7 Caron Butler                       NA                    NA\n 8 Ian Mahinmi                         2                     3\n 9 Rodrigue Beaubois                  NA                    NA\n10 DeShawn Stevenson                   3                     5\n# ℹ 20 more rows\n# ℹ 4 more variables: three_point_field_goals_made &lt;int&gt;,\n#   three_point_field_goals_attempted &lt;int&gt;, free_throws_made &lt;int&gt;,\n#   free_throws_attempted &lt;int&gt;\n\n\nAs a sanity check, we can cross-reference the data in our table with the box score from ESPN. Luckily, these numbers match up!\nIt turns out that raw_box contains much more data than we need. Specifically, it includes statistics from play-in and play-off games as well as data from some (but not all) All-Star games. Since we’re ultimately interested in identifying the best player-seasons in terms of shooting performance, we need to remove all play-off, play-in, and All-Star games from the dataset. Additionally, the column did_not_play contains a Boolean (i.e., logical) variable that is TRUE is the player did not play in the game and is FALSE if the player did not play in the game\n\nallstar_dates &lt;-\n  date(c(\"2002-02-10\", \"2003-02-09\", \"2004-02-15\",\n    \"2005-02-20\", \"2006-02-19\", \"2007-02-18\", \n    \"2008-02-17\", \"2009-02-15\", \"2010-02-14\",\n    \"2011-02-20\", \"2012-02-26\", \"2013-02-17\", \n    \"2014-02-16\", \"2015-02-15\", \"2016-02-14\",\n    \"2017-02-19\", \"2018-02-18\", \"2019-02-17\",\n    \"2020-02-16\", \"2021-03-07\", \"2022-02-20\",\n    \"2023-02-19\", \"2024-02-18\", \"2025-02-16\"))\nreg_box &lt;-\n  raw_box |&gt;\n  filter(season_type == 2 & !did_not_play & !game_date %in% allstar_dates)\n\nLooking at the data table reg_box, we see that in about 9% of rows, the number of minutes played is missing. These likely correspond to players who were active but did not play or logged only a few seconds (generally at the end of games). We will replace these NA values with 0’s and, while doing so, rename some of the columns in reg_box.\n\nreg_box &lt;-\n  reg_box |&gt;\n1  rename(\n    Player = athlete_display_name,\n    FGM = field_goals_made,\n    FGA = field_goals_attempted,\n    TPM = three_point_field_goals_made,\n    TPA = three_point_field_goals_attempted,\n    FTM = free_throws_made, \n    FTA = free_throws_attempted) |&gt;\n2  mutate(FGM = ifelse(is.na(minutes), 0, FGM),\n         FGA = ifelse(is.na(minutes), 0, FGA),\n         TPM = ifelse(is.na(minutes), 0, TPM),\n         TPA = ifelse(is.na(minutes), 0, TPA),\n         FTM = ifelse(is.na(minutes), 0, FTM),\n         FTA = ifelse(is.na(minutes), 0, FTA)) |&gt;\n3  replace_na(list(minutes = 0))\n\n\n1\n\nRename several variables\n\n2\n\nFor those rows where minutes is NA, set the numbers of makes and attempts to 0\n\n3\n\nReplace missing minutes values with 0\n\n\n\n\nAt this point, every row of reg_box corresponds to a player-game combination. We ultimately wish to sum up the number of makes and misses of each shot type across an entire season for each player. To illustrate this, let’s focus on Dirk Nowitzki’s performance in the 2006-07 season when he won the league MVP award. Conceptually, we can accomplish this by first dividing the full data table into several smaller tables, one for each combination of player and season. Then, we can sum the number of field goals, three point shots, and free throws attempted and made by each player in each of their season. This is an example of the split-apply-combine strategy in which you “break up a big problem into manageable pieces, operate on each piece independently, and then put all the pieces back together.” (Wickham 2011). This functionality is implemented in dplyr using group_by()\n\nseason_box &lt;-\n  reg_box |&gt;\n  group_by(Player, season) %&gt;%\n  summarise(\n    FGM = sum(FGM),\n    FGA = sum(FGA),\n    TPM = sum(TPM),\n    TPA = sum(TPA),\n    FTM = sum(FTM),\n    FTA = sum(FTA),\n    minutes = sum(minutes),\n    n_games = n(),\n    .groups = \"drop\")\n\nThe data table season_box contains 11920 rows, each of corresponds to a single player-season combination. Here is a quick snapshot of some of the data for Dirk Nowitzki\n\nseason_box |&gt;\n  filter(Player == \"Dirk Nowitzki\") |&gt;\n  select(season, FGM, FGA, TPM, TPA, FTM, FTA)\n\n# A tibble: 18 × 7\n   season   FGM   FGA   TPM   TPA   FTM   FTA\n    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   2002   600  1258   139   350   440   516\n 2   2003   690  1489   148   390   483   548\n 3   2004   605  1310    99   290   371   423\n 4   2005   663  1445    91   228   615   708\n 5   2006   751  1564   110   271   539   598\n 6   2007   673  1341    72   173   498   551\n 7   2008   630  1314    79   220   478   544\n 8   2009   774  1616    61   170   485   545\n 9   2010   720  1496    51   121   536   586\n10   2011   610  1179    66   168   395   443\n11   2012   473  1034    78   212   318   355\n12   2013   332   707    63   151   164   191\n13   2014   633  1273   131   329   338   376\n14   2015   487  1062   104   274   255   289\n15   2016   498  1112   126   342   250   280\n16   2017   296   678    79   209    98   112\n17   2018   346   758   138   337    97   108\n18   2019   135   376    64   205    39    50",
    "crumbs": [
      "Lecture 1: Boxscore Metrics"
    ]
  },
  {
    "objectID": "lectures/lecture1.html#more-nuanced-metrics",
    "href": "lectures/lecture1.html#more-nuanced-metrics",
    "title": "Lecture 1: Boxscore Metrics",
    "section": "More nuanced metrics",
    "text": "More nuanced metrics\n\nEffective Field Goal Percentage\nOne criticism of FGP is that it treats 2-point shots the same as 3-point shots. As a result, the league leader in FGP is usually a center whose shots mostly come from near the rim. Effective Field Goal Percentage (eFGP) adjusts FGP to account for the fact that a made 3-point shots is worth 50% more than a made 2-point shot. The formula for eFGP is \\[\n\\textrm{eFGP} = \\frac{\\textrm{FGM} + 0.5 \\times \\textrm{TPM}}{\\textrm{FGA}}\n\\]\nWe can create a column for in our data table using mutate\n\nseason_box \n\n# A tibble: 11,766 × 13\n   Player      season   FGM   FGA   TPM   TPA   FTM   FTA minutes n_games    FGP\n   &lt;chr&gt;        &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt;\n 1 A.J. Guyton   2002    22   244    46   123    22    27     607      45 0.0902\n 2 A.J. Guyton   2003     0     4     0     1     0     0       9       2 0     \n 3 A.J. Lawson   2023     2    44    10    25     2     8     109      15 0.0455\n 4 A.J. Lawson   2024    15   121    13    50    15    23     314      42 0.124 \n 5 A.J. Lawson   2025    43   190    33   101    43    63     485      26 0.226 \n 6 A.J. Price    2010    60   354    60   174    60    75     863      56 0.169 \n 7 A.J. Price    2011    54   320    41   149    54    81     799      50 0.169 \n 8 A.J. Price    2012    28   174    26    88    28    35     567      43 0.161 \n 9 A.J. Price    2013    49   413    70   200    49    62    1276      57 0.119 \n10 A.J. Price    2014     0    46     6    22     0     2      99      28 0     \n# ℹ 11,756 more rows\n# ℹ 2 more variables: TPP &lt;dbl&gt;, FTP &lt;dbl&gt;\n\n\n\n\nTrue Shooting Percentage\nBoth field goal percentage and effective field goal percentage totally ignore free throws. One metric that accounts for all field goals, three pointers, and free throws is true shooting percentage (\\(\\textrm{TSP}\\)), whose formula is given by \\[\n\\textrm{TSP} = \\frac{\\textrm{PTS}}{2 \\times \\left(\\textrm{FGA} + (0.44 \\times \\textrm{FTA})\\right)},\n\\] where \\(\\textrm{PTS} =  \\textrm{FTM} + 2 \\times \\textrm{FGM} + \\textrm{TPM}\\) is the total number of points scored.",
    "crumbs": [
      "Lecture 1: Boxscore Metrics"
    ]
  },
  {
    "objectID": "guides/getting_started.html",
    "href": "guides/getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "This course will make extensive use of the R programming language through the RStudio integrated development environment (IDE). Because the formal pre-requisites for this course are STAT 333 or 340, you are expected to have previous experience using the R programming language.\nThe course will also use version control (using git and GitHub) and Quarto for publishing the results of your analyses. This page contains information",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "guides/getting_started.html#computing-r-rstudio",
    "href": "guides/getting_started.html#computing-r-rstudio",
    "title": "Getting Started",
    "section": "Computing (R & RStudio)",
    "text": "Computing (R & RStudio)\n\n\n\n\n\n\nWarning\n\n\n\nI will assume fluency with basic R functionality (e.g., assignment, writing and executing scripts, saving data objects, setting environments, installing and loading packages), data manipulation with dplyr and other tidyverse packages, and visualization using either base R graphics or ggplot2. I will additionally assume some familiarity with fitting statistical models in R and interpreting their output (e.g., using lm and glm).\nIf you do not meet the formal course prerequisites and/or have not used R in a previous course, this is not the right course for you.\n\n\n\nAdditional R resources\nHaving issued that warning @prereq-warning, you will see some new R functionality in the course. As the focus is on answer sports problems, we will not spend significant classtime going over new functions, packages, or techniques. If you find that there are gaps in your R knowledge, you are expected to fill them on your own time. Here are some helpful resources\n\nR for Data Science\nData Science: A first introduction\n\n\n\nInstallation\nWhile you are expected to have used R in previous courses (see warning), I strongly recommend installing the latest version of both R and RStudio at the beginning of the course. As of the time of this writing, that is R version 4.5 and RStudio version 2025.05.\nYou can download a version of R specific to for your operating system from this website. After install R, you should download and re-install RStudio from this website.\n\n\n\n\n\n\nTip\n\n\n\nWhenever you update your version of R, you need to re-install the packages; this is a perennial source of frustration for many R users] and some good-natured humor from others (who also manually re-installs packages after every update!)\n\n\n\n\nRequired Packages\nThroughout the course, we will make extensive use of several packages in the tidyverse, primarily for data loading, pre-processing, and manipulation. We will also make extensive use of the packages glmnet, ranger, and xgboost for model fitting. We will occasionally also use ggplot2 for creating visualizations.\nAs the course progresses, we will introduce and install new package as required. For the most part, these packages will be specific to a particular sport. Every package that we will use in this class is available through either (i) the Comprehensive R Archive Network (CRAN) or (ii) a public GitHub repository maintained by the packager developer. We typically install CRAN packages using the install.packages() command. To install packages hosted on GitHub, we will use the install_github function in the devtools package (which itself is available on CRAN)\n\n\n\n\n\n\nBase packages\n\n\n\nPrior to Lecture 2, please make sure you have installed the tidyverse packages as well as devtools, ggplot2, glmnet, ranger, and xgboost.\n\ninstall.packages(c(\"devtools\", \"tidyverse\", \"ggplot2\", \"glmnet\", \"ranger\", \"xgboost\"))\n\n\n\n\n\nColorblind-friendly graphics\nI am especially partial to the Okabe-Ito color palette. Throughout the course notes, you will see snippets like\n\noi_colors &lt;-\n  palette.colors(palette = \"Okabe-Ito\")\n\nin which we explicitly create a vector holding colors from this color palette.  ## Version control (Git & GitHub)\n\n\n\nAdditional Resources",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "guides/getting_started.html#quarto",
    "href": "guides/getting_started.html#quarto",
    "title": "Getting Started",
    "section": "Quarto",
    "text": "Quarto\n\nInstallation\n\n\nPublishing",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "exercises/exercises1_boxscore.html",
    "href": "exercises/exercises1_boxscore.html",
    "title": "Constructing Advanced Metrics Using Box Score Data",
    "section": "",
    "text": "We will rely on data from the Lahman Database.\n\n\n\nif(!\"Lahman\" %in% rownames(installed.packages())){\n  message(\"Package `Lahman' not already installed. Installing now\")\n  install.packages(\"Lahman\")\n} else{\n  library(Lahman)\n}",
    "crumbs": [
      "Constructing Advanced Metrics Using Box Score Data"
    ]
  },
  {
    "objectID": "exercises/exercises1_boxscore.html#setup-installing-the-lahman-package",
    "href": "exercises/exercises1_boxscore.html#setup-installing-the-lahman-package",
    "title": "Constructing Advanced Metrics Using Box Score Data",
    "section": "",
    "text": "if(!\"Lahman\" %in% rownames(installed.packages())){\n  message(\"Package `Lahman' not already installed. Installing now\")\n  install.packages(\"Lahman\")\n} else{\n  library(Lahman)\n}",
    "crumbs": [
      "Constructing Advanced Metrics Using Box Score Data"
    ]
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Contains additional exercises to reproduce and extend analyses shown in lecture."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 479 (Fall 2025): Sports Analytics",
    "section": "",
    "text": "Welcome to STAT 479 (Special Topics in Statistics)! This iteration of the course will focus on sports analytics.\nLectures notes, instructions for the course project, and additional tutorials and exercises will be posted to this website. So, please bookmark this page and check it regularly throughout the course."
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "STAT 479 (Fall 2025): Sports Analytics",
    "section": "Course information",
    "text": "Course information\nDescription: Illustrates the use of statistical modeling and data science techniques to derive actionable insights from sports data. Emphasizes not only technical calculation of advanced metrics but also on written and oral communication to other data scientists and to non-technical audience. Topics may include: deriving team rankings from paired competitions; measuring an individual player’s contribution to their team’s overall success; assessing player performance and team strategy in terms of expected outcomes; forecasting the impact of new rule changes using simulation; and creating new metrics using high-resolution player tracking data.\nLearning Outcomes: Throughout the course you will\n\nImplement appropriate statistical methods to assess player and team performance\nWork with play-by-play and high-resolution tracking data\nProvide constructive and actionable feedback on your peers’ analytic reports\nBuild a personal portfolio of sports data analyses\n\nLocation & Schedule: Tuesdays & Thursdays, 11:00am-12:15pm, 1524 Morgridge Hall\nInstructor & Office Hours: Sameer Deshpande (sameer.deshpande@wisc.edu). Office Hours TBA."
  },
  {
    "objectID": "guides.html",
    "href": "guides.html",
    "title": "Guides",
    "section": "",
    "text": "In this section, you will find pages containing additional background information about the methods and datasets introduced in Lecture. You will also find much more comprehensive code and guides for fitting the relevant models."
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lecture Notes",
    "section": "",
    "text": "Lecture notes will be posted here."
  },
  {
    "objectID": "guides/plot_vertical_statsbomb.html",
    "href": "guides/plot_vertical_statsbomb.html",
    "title": "Plotting StatsBomb Data Vertically",
    "section": "",
    "text": "In Lectures 2 and 3, we built several expected goals (xg) models using data provided by StatsBomb. StatsBomb pre-processes their raw tracking data so that attacking play is oriented from left to right. I find it somewhat more aesthetically pleasing to visualize shot data vertically with the goal line on top and the half-line at the bottom.\nThis page defines a function to transform StatsBomb shot location data so that it can be plotted vertically instead of horizontally. As you continue to work with StatsBomb data, feel free to use these functions.",
    "crumbs": [
      "Plotting StatsBomb Data Vertically"
    ]
  },
  {
    "objectID": "guides/plot_vertical_statsbomb.html#overview",
    "href": "guides/plot_vertical_statsbomb.html#overview",
    "title": "Plotting StatsBomb Data Vertically",
    "section": "",
    "text": "In Lectures 2 and 3, we built several expected goals (xg) models using data provided by StatsBomb. StatsBomb pre-processes their raw tracking data so that attacking play is oriented from left to right. I find it somewhat more aesthetically pleasing to visualize shot data vertically with the goal line on top and the half-line at the bottom.\nThis page defines a function to transform StatsBomb shot location data so that it can be plotted vertically instead of horizontally. As you continue to work with StatsBomb data, feel free to use these functions.",
    "crumbs": [
      "Plotting StatsBomb Data Vertically"
    ]
  },
  {
    "objectID": "guides/plot_vertical_statsbomb.html#a-digression-on-coordinate-systems",
    "href": "guides/plot_vertical_statsbomb.html#a-digression-on-coordinate-systems",
    "title": "Plotting StatsBomb Data Vertically",
    "section": "A digression on coordinate systems",
    "text": "A digression on coordinate systems\nStatsBomb converts their raw location data to a standardized pitch of dimensions 120y x 80y. Appendix 2 of their Open Data Specification document shows the standardized pitch along with several landmarks like the penalty area and goalkeeper’s box.\n\n\n\nStatsBomb Coordinate System\n\n\nNotice that the origin (i.e., the point with coordinates c(0,0)) is in the top-left corner so that the \\(x\\) coordinate increases as you more from left to right and the \\(y\\) coordinate increases as you move from top to bottom. This coordinate system is standard for 2D computer graphics1 and is often referred to as the “left-handed” coordinate system.\nWhen we build R graphics, we typically use the more conventional “right-handed” coordinate system in which the \\(y\\) coordinates increases when we move from bottom. For instance, to create a plot region with \\(0 \\leq x \\leq 120\\) and \\(0 \\leq y \\leq 80,\\) we might use something like the following code\n\npar(mar = c(3,3,2,1), mgp = c(1.8, 0.5, 0)) # sets up margins for plot\nplot(1, type = \"n\", # signals that we want an empty plot\n     xlab = \"x\", ylab = \"y\", # labels axes\n     xlim = c(0,120), ylim = c(0,80))\n\n\n\n\n\n\n\n\nLuckily, there is a quick “fix”2 that allows us to generate plots in R using the StatsBomb coordinate system: instead of specifying ylim = c(0,80), we simply specify ylim = c(80,0). This new specification tells R that when we move from bottom-to-top, the \\(y\\) coordinate should go from 80 to 0.\n\npar(mar = c(3,3,2,1), mgp = c(1.8, 0.5, 0))\nplot(1, type = \"n\",\n     xlim = c(0, 120), ylim = c(80, 0),\n     xlab = \"x\", ylab = \"y\")\n\n\n\n\n\n\n\n\nNow that we have the coordinate system sorted, we will hard-code the coordinates several landmarks on the pitch. Doing so will help us determine an appropriate transformation of coordinates to produce a vertically oriented pitch. The main landmarks are the corners of the pitch; the corners of the left and right penalty boxes; the corners of the left and right goalkeepers’ areas; the corners of the left and right nets; the locations of the goal posts; and the half-circle.\n\n# corners of pitch\ntop_left_corner &lt;- c(0,0)\nbot_left_corner &lt;- c(0,80)\ntop_right_corner &lt;- c(120,0)\nbot_right_corner &lt;- c(120, 80)\n\n# endpoints of half-line\ntop_halfline &lt;- c(60,0)\nbot_halfline &lt;- c(60, 80)\n\n# corners of left penalty area\ntop_left_penl &lt;- c(0, 18)\nbot_left_penl &lt;- c(0,62)\ntop_right_penl &lt;- c(18,18)\nbot_right_penl &lt;- c(18,62)\n\n# corners of left goalkeeper area\ntop_left_gkl &lt;- c(0,30)\nbot_left_gkl &lt;- c(0,50)\ntop_right_gkl &lt;- c(6,30)\nbot_right_gkl &lt;- c(6,50)\n\n# left goal posts\ntop_postl &lt;- c(0,36)\nbot_postl &lt;- c(0,44)\n\n# corners of left net\ntop_left_netl &lt;- c(-2,36)\nbot_left_netl &lt;- c(-2, 44)\ntop_right_netl &lt;- c(0, 36)\nbot_right_netl &lt;- c(0,44)\n\n# corners of right penalty area\ntop_left_penr &lt;- c(102,18)\nbot_left_penr &lt;- c(102,62)\ntop_right_penr &lt;- c(120,18)\nbot_right_penr &lt;- c(120,62)\n# corners of right goal keeper's area\ntop_left_gkr &lt;- c(114,30)\nbot_left_gkr &lt;- c(114,50)\ntop_right_gkr &lt;- c(120,30)\nbot_right_gkr &lt;- c(120,50)\n# right goal posts\ntop_postl &lt;- c(120,36)\nbot_postl &lt;- c(120,44)\n# corners of left net\ntop_left_netr &lt;- c(120,36)\nbot_left_netr &lt;- c(120, 44)\ntop_right_netr &lt;- c(122, 36)\nbot_right_netr &lt;- c(122,44)\n\n# half-circles\nleft_halfcirc &lt;-\n  data.frame(x = 60 + 10*cos(seq(from = pi/2, to = 3*pi/2, length = 100)),\n             y = 40 - 10 * sin(seq(from = pi/2, to = 3*pi/2, length = 100)))\n\nright_halfcirc &lt;-\n  data.frame(x = 60 + 10*cos(seq(from =-pi/2, to = pi/2, length = 100)),\n             y = 40 - 10 * sin(seq(from = -pi/2, to = pi/2, length = 100)))\n\nWe can now add in the penalty and goalkeepers’ areas to the pitch using the rect function. This function draws a rectangle whose bottom left coordinate is c(xleft, ybottom) and whose top right coordinate is c(xright, ytop). We also add in the half line and circle\n\npar(mar = c(3,3,2,1), \n    mgp = c(1.8, 0.5, 0), \n    xpd = TRUE) # xpd allows plotting in margins\nplot(1, type = \"n\",\n     xlab = \"x\", ylab = \"y\",\n     xlim = c(0,120), ylim = c(80,0))\n# boundaries of pitch\nrect(xleft = bot_left_corner[1], ybottom = bot_left_corner[2], \n     xright = top_right_corner[1], ytop = top_right_corner[2])\n# left penalty area\nrect(xleft = bot_left_penl[1], ybottom = bot_left_penl[2],\n     xright = top_right_penl[1], ytop = top_right_penl[2])\n# left goalkeeper's area\nrect(xleft = bot_left_gkl[1], ybottom = bot_left_gkl[2],\n     xright = top_right_gkl[1], ytop = top_right_gkl[2])\n# left net\nrect(xleft = bot_left_netl[1], ybottom = bot_left_netl[2],\n     xright = top_right_netl[1], ytop = top_right_netl[2])\n\n# right penalty area\nrect(xleft = bot_left_penr[1], ybottom = bot_left_penr[2],\n     xright = top_right_penr[1], ytop = top_right_penr[2])\n# right goalkeeper's area\nrect(xleft = bot_left_gkr[1], ybottom = bot_left_gkr[2],\n     xright = top_right_gkr[1], ytop = top_right_gkr[2])\n# right net\nrect(xleft = bot_left_netr[1], ybottom = bot_left_netr[2],\n     xright = top_right_netr[1], ytop = top_right_netr[2])\n# half-line\nlines(x = c(top_halfline[1], bot_halfline[1]),\n      y = c(top_halfline[2], bot_halfline[2]))\n# left half-circle \nlines(x = left_halfcirc$x, y = left_halfcirc$y)\n# right half-circle\nlines(x = right_halfcirc$x, y = right_halfcirc$y)",
    "crumbs": [
      "Plotting StatsBomb Data Vertically"
    ]
  },
  {
    "objectID": "guides/plot_vertical_statsbomb.html#translation-and-rotation",
    "href": "guides/plot_vertical_statsbomb.html#translation-and-rotation",
    "title": "Plotting StatsBomb Data Vertically",
    "section": "Translation and Rotation",
    "text": "Translation and Rotation\nWe will form a vertical pitch layout by composing the following three transformations:\n\nTranslate the pitch so the origin is at mid-field, which is located at \\((60,40).\\) Mathematically, the transformation is \\((x,y) \\rightarrow (x-60, y - 40)\\)\nRotate the pitch so that (i) the bottom right corner goes to the top right; (ii) the top right corner goes to the top left; (iii) the top left corner goes to the bottom left; and (iv) the bottom left corner goes to the bottom right. Mathematically, the transformation is \\((x,y) \\rightarrow (y, -x)\\)3.\nTranslate the rotated frame so that the origin is in the top left corner. Mathematically, the transformation is \\((x,y) \\rightarrow (x+40,y+60).\\)\n\nPutting these steps together, we have the transformation \\[\n(x,y) \\rightarrow (x-60, y-40) \\rightarrow (y-40, 60-x) \\rightarrow (y,120-x)\n\\] It will be useful to define functions for these transformations\n\ntransform_x &lt;- function(x,y){return(y)}\ntransform_y &lt;- function(x,y){return(120-x)}\n\nRecall that the function rect draws a rectangle using the coordinates of its bottom left and top right corners. We can compute the coordinates of the bottom left (resp. top right) corner of a rectangle in a vertical orientation by transforming the coordinates of the top left (resp. bottom right) corners of a rectangle in the original horizontal orientation.\n\npar(mar = c(3,3,2,1), mgp = c(1.8, 0.5, 0))\nplot(1, type = \"n\",\n     xlim = c(0, 80), ylim = c(120,0), # note the different limits!\n     xlab = \"x\", ylab = \"y\")\n# boundaries of pitch\nrect(xleft = transform_x(top_left_corner[1], top_left_corner[2]),\n     ybottom = transform_y(top_left_corner[1], top_left_corner[2]),\n     xright = transform_x(bot_right_corner[1], bot_right_corner[2]),\n     ytop = transform_y(bot_right_corner[1], bot_right_corner[2]))\n# original left penalty area now on bottom\nrect(xleft = transform_x(top_left_penl[1], top_left_penl[2]),\n     ybottom = transform_y(top_left_penl[1], top_left_penl[2]),\n     xright = transform_x(bot_right_penl[1], bot_right_penl[2]),\n     ytop = transform_y(bot_right_penl[1], bot_right_penl[2]))\n# original left goalkeeper's area now on bottom\nrect(xleft = transform_x(top_left_gkl[1], top_left_gkl[2]),\n     ybottom = transform_y(top_left_gkl[1], top_left_gkl[2]),\n     xright = transform_x(bot_right_gkl[1], bot_right_gkl[2]),\n     ytop = transform_y(bot_right_gkl[1], bot_right_gkl[2]))\n# original left net now on bottom\nrect(xleft = transform_x(top_left_netl[1], top_left_netl[2]),\n     ybottom = transform_y(top_left_netl[1], top_left_netl[2]),\n     xright = transform_x(bot_right_netl[1], bot_right_netl[2]),\n     ytop = transform_y(bot_right_netl[1], bot_right_netl[2]))\n\n# original right penalty area now on top\nrect(xleft = transform_x(top_left_penr[1], top_left_penr[2]),\n     ybottom = transform_y(top_left_penr[1], top_left_penr[2]),\n     xright = transform_x(bot_right_penr[1], bot_right_penr[2]),\n     ytop = transform_y(bot_right_penr[1], bot_right_penr[2]))\n# original right goalkeeper's area now on top\nrect(xleft = transform_x(top_left_gkr[1], top_left_gkr[2]),\n     ybottom = transform_y(top_left_gkr[1], top_left_gkr[2]),\n     xright = transform_x(bot_right_gkr[1], bot_right_gkr[2]),\n     ytop = transform_y(bot_right_gkr[1], bot_right_gkr[2]))\n# original right net now on bottom\nrect(xleft = transform_x(top_left_netr[1], top_left_netr[2]),\n     ybottom = transform_y(top_left_netr[1], top_left_netr[2]),\n     xright = transform_x(bot_right_netr[1], bot_right_netr[2]),\n     ytop = transform_y(bot_right_netr[1], bot_right_netr[2]))\n\n# half-line\nlines(x = transform_x( c(top_halfline[1], bot_halfline[1]), c(top_halfline[2], bot_halfline[2])),\n      y = transform_y( c(top_halfline[1], bot_halfline[1]), c(top_halfline[2], bot_halfline[2])))\n# original left half-circle now on bottom\nlines(x = transform_x(left_halfcirc$x, left_halfcirc$y),\n      y = transform_y(left_halfcirc$x, left_halfcirc$y))\n# original right half-circle now on top\nlines(x = transform_x(right_halfcirc$x, right_halfcirc$y),\n      y = transform_y(right_halfcirc$x, right_halfcirc$y))\n\n\n\n\n\n\n\n\nFor convenience, we can write a function that plots either the full pitch or the attacking in either the horizontal or vertical orientation. The function plot_pitch has two arguments:\n\nhalf: Set half = TRUE to plot the attacking half and half = FALSE to plot the full pitch. Default is TRUE\nvertical: Set vertical = TRUE to plot in a vertical orientation and vertical = FALSE to plot in a horizontal orientation. Default is TRUE\n\nYou can download an R script implementing this function from this link. If you save that script in your course or project repository, you can source it as needed. You can also unfold the next code block to see how the function plot_pitch is implemented.\n\n\nCode\nplot_pitch &lt;- function(half = TRUE, vertical = TRUE){\n  par(mar = c(2,1,4,1), # lower left & right margins but increase top margin\n      mgp = c(1.8, 0.5, 0), \n      xpd = TRUE) # allows plotting in the margin\n  if(vertical){\n    # plot vertical pitch\n    if(half){\n      # only plot the attacking half\n      plot(1, type = \"n\",\n           xlim = c(0,80), ylim = c(60,0),\n           xaxt = \"n\", yaxt = \"n\", # suppresses axis marks\n           xlab = NA, ylab = NA, # suppress labels\n           bty = \"n\") # suppresses the bounding box\n      # pitch\n      rect(xleft = transform_x(top_halfline[1], top_halfline[2]),\n           ybottom = transform_y(top_halfline[1], top_halfline[2]),\n           xright = transform_x(bot_right_corner[1], bot_right_corner[2]),\n           ytop = transform_y(bot_right_corner[1], bot_right_corner[2]))\n      # original right penalty area now on top\n      rect(xleft = transform_x(top_left_penr[1], top_left_penr[2]),\n           ybottom = transform_y(top_left_penr[1], top_left_penr[2]),\n           xright = transform_x(bot_right_penr[1], bot_right_penr[2]),\n           ytop = transform_y(bot_right_penr[1], bot_right_penr[2]))\n      # original right goalkeeper's area now on top\n      rect(xleft = transform_x(top_left_gkr[1], top_left_gkr[2]),\n           ybottom = transform_y(top_left_gkr[1], top_left_gkr[2]),\n           xright = transform_x(bot_right_gkr[1], bot_right_gkr[2]),\n           ytop = transform_y(bot_right_gkr[1], bot_right_gkr[2]))\n      # original right net now on top\n      rect(xleft = transform_x(top_left_netr[1], top_left_netr[2]),\n           ybottom = transform_y(top_left_netr[1], top_left_netr[2]),\n           xright = transform_x(bot_right_netr[1], bot_right_netr[2]),\n           ytop = transform_y(bot_right_netr[1], bot_right_netr[2]))\n      # half-circle\n      lines(x = transform_x(right_halfcirc$x, right_halfcirc$y),\n            y = transform_y(right_halfcirc$x, right_halfcirc$y))\n    } else{\n      # plot the full field\n      plot(1, type = \"n\",\n           xlim = c(0, 80), ylim = c(120,0), \n           xaxt = \"n\", yaxt = \"n\", # suppresses axis marks\n           xlab = NA, ylab = NA, # suppress labels\n           bty = \"n\") # suppresses the bounding box\n      # boundaries of pitch\n      rect(xleft = transform_x(top_left_corner[1], top_left_corner[2]),\n           ybottom = transform_y(top_left_corner[1], top_left_corner[2]),\n           xright = transform_x(bot_right_corner[1], bot_right_corner[2]),\n           ytop = transform_y(bot_right_corner[1], bot_right_corner[2]))\n      # original left penalty area now on bottom\n      rect(xleft = transform_x(top_left_penl[1], top_left_penl[2]),\n           ybottom = transform_y(top_left_penl[1], top_left_penl[2]),\n           xright = transform_x(bot_right_penl[1], bot_right_penl[2]),\n           ytop = transform_y(bot_right_penl[1], bot_right_penl[2]))\n      # original left goalkeeper's area now on bottom\n      rect(xleft = transform_x(top_left_gkl[1], top_left_gkl[2]),\n           ybottom = transform_y(top_left_gkl[1], top_left_gkl[2]),\n           xright = transform_x(bot_right_gkl[1], bot_right_gkl[2]),\n           ytop = transform_y(bot_right_gkl[1], bot_right_gkl[2]))\n      # original left net now on bottom\n      rect(xleft = transform_x(top_left_netl[1], top_left_netl[2]),\n           ybottom = transform_y(top_left_netl[1], top_left_netl[2]),\n           xright = transform_x(bot_right_netl[1], bot_right_netl[2]),\n           ytop = transform_y(bot_right_netl[1], bot_right_netl[2]))\n      # original right penalty area now on top\n      rect(xleft = transform_x(top_left_penr[1], top_left_penr[2]),\n           ybottom = transform_y(top_left_penr[1], top_left_penr[2]),\n           xright = transform_x(bot_right_penr[1], bot_right_penr[2]),\n           ytop = transform_y(bot_right_penr[1], bot_right_penr[2]))\n\n      # original right goalkeeper's area now on top\n      rect(xleft = transform_x(top_left_gkr[1], top_left_gkr[2]),\n           ybottom = transform_y(top_left_gkr[1], top_left_gkr[2]),\n           xright = transform_x(bot_right_gkr[1], bot_right_gkr[2]),\n           ytop = transform_y(bot_right_gkr[1], bot_right_gkr[2]))\n      # original right net now on bottom\n      rect(xleft = transform_x(top_left_netr[1], top_left_netr[2]),\n           ybottom = transform_y(top_left_netr[1], top_left_netr[2]),\n           xright = transform_x(bot_right_netr[1], bot_right_netr[2]),\n           ytop = transform_y(bot_right_netr[1], bot_right_netr[2]))\n      # half-line\n      lines(x = transform_x( c(top_halfline[1], bot_halfline[1]), c(top_halfline[2],bot_halfline[2])),\n            y = transform_y( c(top_halfline[1], bot_halfline[1]), c(top_halfline[2], bot_halfline[2])))\n      # original left half-circle now on bottom\n      lines(x = transform_x(left_halfcirc$x, left_halfcirc$y),\n            y = transform_y(left_halfcirc$x, left_halfcirc$y))\n      # original right half-circle now on top\n      lines(x = transform_x(right_halfcirc$x, right_halfcirc$y),\n            y = transform_y(right_halfcirc$x, right_halfcirc$y))\n    }# closes if/else checking whether to plot attacking half\n  } else{\n    # plot horizontal pitch\n    if(half){\n      plot(1, type = \"n\",\n           xlim = c(60,120), ylim = c(80, 0),\n           xaxt = \"n\", yaxt = \"n\", # suppresses axis marks\n           xlab = NA, ylab = NA,# suppresses labels\n           bty = \"n\") # suppresses the bounding box\n      # boundaries of attacking half\n      rect(xleft = bot_halfline[1], ybottom = bot_halfline[2], \n           xright = top_right_corner[1], ytop = top_right_corner[2])\n      # right penalty area\n      rect(xleft = bot_left_penr[1], ybottom = bot_left_penr[2],\n           xright = top_right_penr[1], ytop = top_right_penr[2])\n      # right goalkeeper's area\n      rect(xleft = bot_left_gkr[1], ybottom = bot_left_gkr[2],\n           xright = top_right_gkr[1], ytop = top_right_gkr[2])\n      # right net\n      rect(xleft = bot_left_netr[1], ybottom = bot_left_netr[2],\n           xright = top_right_netr[1], ytop = top_right_netr[2])\n      # right half-circle\n      lines(x = right_halfcirc$x, y = right_halfcirc$y)\n    } else{\n      plot(1, type = \"n\",\n           xlim = c(0,120), ylim = c(80,0),\n           xaxt = \"n\", yaxt = \"n\", # suppresses axis marks\n           xlab = NA, ylab = NA, # suppress labels\n           bty = \"n\") # suppresses the bounding box\n      # boundaries of pitch\n      rect(xleft = bot_left_corner[1], ybottom = bot_left_corner[2], \n           xright = top_right_corner[1], ytop = top_right_corner[2])\n      # left penalty area\n      rect(xleft = bot_left_penl[1], ybottom = bot_left_penl[2],\n           xright = top_right_penl[1], ytop = top_right_penl[2])\n      # left goalkeeper's area\n      rect(xleft = bot_left_gkl[1], ybottom = bot_left_gkl[2],\n           xright = top_right_gkl[1], ytop = top_right_gkl[2])\n      # left net\n      rect(xleft = bot_left_netl[1], ybottom = bot_left_netl[2],\n           xright = top_right_netl[1], ytop = top_right_netl[2])\n      # right penalty area\n      rect(xleft = bot_left_penr[1], ybottom = bot_left_penr[2],\n           xright = top_right_penr[1], ytop = top_right_penr[2])\n      # right goalkeeper's area\n      rect(xleft = bot_left_gkr[1], ybottom = bot_left_gkr[2],\n           xright = top_right_gkr[1], ytop = top_right_gkr[2])\n      # right net\n      rect(xleft = bot_left_netr[1], ybottom = bot_left_netr[2],\n           xright = top_right_netr[1], ytop = top_right_netr[2])\n      # half-line\n      lines(x = c(top_halfline[1], bot_halfline[1]),\n            y = c(top_halfline[2], bot_halfline[2]))\n      # left half-circle \n      lines(x = left_halfcirc$x, y = left_halfcirc$y)\n      # right half-circle\n      lines(x = right_halfcirc$x, y = right_halfcirc$y)\n    }\n  } # closes if/else checking whether to plot horizontally or vertically\n  \n}",
    "crumbs": [
      "Plotting StatsBomb Data Vertically"
    ]
  },
  {
    "objectID": "guides/plot_vertical_statsbomb.html#example-visualizing-beth-meads-goals-at-euro-2022",
    "href": "guides/plot_vertical_statsbomb.html#example-visualizing-beth-meads-goals-at-euro-2022",
    "title": "Plotting StatsBomb Data Vertically",
    "section": "Example: Visualizing Beth Mead’s goals at EURO 2022",
    "text": "Example: Visualizing Beth Mead’s goals at EURO 2022\nWe’ll use our new function plot_pitch() to illustrate all 5 of Beth Mead’s goals at EURO 2022.\n\nlibrary(tidyverse)\noi_colors &lt;- \n  palette.colors(palette = \"Okabe-Ito\")\n\nThe code in the next block, which is very similar to that used in Lecture 2, does the following things:\n\nLoads & preprocesses the event data from EURO 2022 (competition_id = 53 and season_id = 106)\nFilters to all goals scored by Beth Mead.\nSelects only the starting and ending locations of the shots (in the horizontal orientation)\nComputes the starting and ending coordinates in the vertical orientation of each shot\n\nWe will first plot the goals on the full horizontal pitch\n\nplot_pitch(half = FALSE, vertical = FALSE)\nfor(i in 1:nrow(mead_goals)){\n  lines(x = c(mead_goals$location.x[i], mead_goals$shot.end_location.x[i]),\n        y = c(mead_goals$location.y[i], mead_goals$shot.end_location.y[i]),\n         col = oi_colors[i+1])\n}\nmtext(\"Beth Mead Goals (EURO 2022)\", side = 3, line = 1)\nmtext(\"Created with free data from StatsBomb\\n https://github.com/statsbomb/open-data\",\n      side = 1, line = 1)\n\n\n\n\n\n\n\n\nAnd here are the same goals but in the attacking half in a vertical orientation\n\nplot_pitch(half = TRUE, vertical = TRUE)\nfor(i in 1:nrow(mead_goals)){\n  lines(x = c(mead_goals$vert_location.x[i], mead_goals$vert_shot.end_location.x[i]),\n        y = c(mead_goals$vert_location.y[i], mead_goals$vert_shot.end_location.y[i]),\n         col = oi_colors[i+1])\n}\nmtext(\"Beth Mead Goals (EURO 2022)\", side = 3, line = 1)\nmtext(\"Created with free data from StatsBomb\\n https://github.com/statsbomb/open-data\",\n      side = 1, line = 1)",
    "crumbs": [
      "Plotting StatsBomb Data Vertically"
    ]
  },
  {
    "objectID": "guides/plot_vertical_statsbomb.html#footnotes",
    "href": "guides/plot_vertical_statsbomb.html#footnotes",
    "title": "Plotting StatsBomb Data Vertically",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee here for the gory details or check out the Wikipedia entry on 2D graphics.↩︎\nI found this solution here after Googling “R change origin top left”.↩︎\nCounter-clockwise rotations in the usual right-handed coordinate system (with \\(y\\) increasing from bottom-to-top) are clockwise rotations in the left-handed coordinate system we are using, in which \\(y\\) increases from top-to-bottom. We want to rotate 90 degrees counter-clockwise in the right-handed system, which is equivalent to a 270 degree clockwise rotation in the left-handed system. See this Wikipedia entry for more details.↩︎",
    "crumbs": [
      "Plotting StatsBomb Data Vertically"
    ]
  },
  {
    "objectID": "lectures/lecture8.html",
    "href": "lectures/lecture8.html",
    "title": "Lecture 8: Pitch Framing & Multi-level modeling",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Lecture 8: Pitch Framing & Multi-level modeling"
    ]
  },
  {
    "objectID": "lectures/lecture3.html",
    "href": "lectures/lecture3.html",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "",
    "text": "Over the next several lectures, we will work with pitch-tracking data from Major League Baseball, with the ultimate goal of allocating credit or blame to players based at a play-by-play level and to quantify the value of each player provides his team.\nBut before doing any of that, let’s consider two hypothetical scenarios in which a batter comes up to the plate when there are (i) 2 outs and no runners on base and when there are (ii) 1 out and runners on first and second. Which scenario do you think will result in more runs for the batting team?\nIntuitively, we might expect the second scenario to lead to more runs; after all, the batting team will score at least one run if the batter gets a hit while there is no guarantee of scoring a run in the first scenario even if the batter gets on base. We can more precisely quantify this intuition using expected runs, which is a key tool used in sabermetrics. The expected runs \\(\\rho(\\textrm{o}, \\textrm{br})\\) is the average number of runs scored in the remainder of the half-inning following at-bats beginning with \\(\\textrm{o}\\) outs and baserunner configuration \\(\\textrm{br}.\\) Like expected goals (XG) from Lecture 2, expected runs is a conditional expectation.\nDuring the March 20, 2024 game between the Dodgers and Padres, Shohei Ohtani actually faced both of the scenarios mentioned above and singled in both at-bats. In the 3rd inning, he hit a 2-out single with no runners and in the 8th inning, he hit a 1-out single with runners on first and second base.\nSince the second single resulted in a run scoring and the first did not, it is tempting to say that the second single is more valuable. However, although the first single did not directly lead to a run, it did put the Dodgers in a more favorable position, with a runner on first1 By the end of this lecture, we will be able to quantify exactly how valuable each of those singles using run values, which combine changes in the number of a team can expect to score and the number of runs actually scored in an at-bat.",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#overview",
    "href": "lectures/lecture3.html#overview",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "",
    "text": "Over the next several lectures, we will work with pitch-tracking data from Major League Baseball, with the ultimate goal of allocating credit or blame to players based at a play-by-play level and to quantify the value of each player provides his team.\nBut before doing any of that, let’s consider two hypothetical scenarios in which a batter comes up to the plate when there are (i) 2 outs and no runners on base and when there are (ii) 1 out and runners on first and second. Which scenario do you think will result in more runs for the batting team?\nIntuitively, we might expect the second scenario to lead to more runs; after all, the batting team will score at least one run if the batter gets a hit while there is no guarantee of scoring a run in the first scenario even if the batter gets on base. We can more precisely quantify this intuition using expected runs, which is a key tool used in sabermetrics. The expected runs \\(\\rho(\\textrm{o}, \\textrm{br})\\) is the average number of runs scored in the remainder of the half-inning following at-bats beginning with \\(\\textrm{o}\\) outs and baserunner configuration \\(\\textrm{br}.\\) Like expected goals (XG) from Lecture 2, expected runs is a conditional expectation.\nDuring the March 20, 2024 game between the Dodgers and Padres, Shohei Ohtani actually faced both of the scenarios mentioned above and singled in both at-bats. In the 3rd inning, he hit a 2-out single with no runners and in the 8th inning, he hit a 1-out single with runners on first and second base.\nSince the second single resulted in a run scoring and the first did not, it is tempting to say that the second single is more valuable. However, although the first single did not directly lead to a run, it did put the Dodgers in a more favorable position, with a runner on first1 By the end of this lecture, we will be able to quantify exactly how valuable each of those singles using run values, which combine changes in the number of a team can expect to score and the number of runs actually scored in an at-bat.",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#an-initial-xg-model",
    "href": "lectures/lecture3.html#an-initial-xg-model",
    "title": "Lecture 3: Building our own XG model",
    "section": "An initial XG model",
    "text": "An initial XG model\nIntuitively, we expect shots taken very close to the goal to have larger xG than shots taken very far from the goal\n\nHandcrafting features\n\n\nAdding interactions\nIt may not just be distance and body part but their interaction;",
    "crumbs": [
      "Lecture 3: Building our own XG model"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#tree-based-models",
    "href": "lectures/lecture3.html#tree-based-models",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "Tree-based models",
    "text": "Tree-based models\nAdding more covariates and interactions becomes extremely tricky. Methods based on regression trees are a convenient way to overcome this limitation.\n\nIllustration",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#gk-metrics",
    "href": "lectures/lecture3.html#gk-metrics",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "GK metrics",
    "text": "GK metrics\nTo what extent does a keeper affect XG? To answer this this, we can fit two XG models. One with keeper information and one without. We can then compare the two different XG values Consider a model that includes goal keeper position one without.",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#the-probability-of-making-an-out",
    "href": "lectures/lecture5.html#the-probability-of-making-an-out",
    "title": "Lecture 5: Wins Above Replacement II",
    "section": "The probability of making an out",
    "text": "The probability of making an out\nHow difficult is a ball-in-play (BIP) to field? Intuitively, if the pitcher gives up a home run, the remaining fielders should not get any blame. And if a fielder makes an error, the pitcher should not get any blame.\nOf the total \\(-\\delta_{i}\\) we need to",
    "crumbs": [
      "Lecture 5: Wins Above Replacement II"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#fielding-run-values",
    "href": "lectures/lecture5.html#fielding-run-values",
    "title": "Lecture 5: Wins Above Replacement II",
    "section": "Fielding run values",
    "text": "Fielding run values\n\n\nPitching run values",
    "crumbs": [
      "Lecture 5: Wins Above Replacement II"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#replacement-level",
    "href": "lectures/lecture5.html#replacement-level",
    "title": "Lecture 5: Wins Above Replacement II",
    "section": "Replacement Level",
    "text": "Replacement Level\nMost teams carry 13 position players and 12 pitchers, we designate the \\(30 \\times 13 = 390\\) position players with the most PAs to be the non-replacement players. Everyone else is replacement level\nWe can compute the average RAA for all replacement level players. Then we look at (RAA_p - RAA_shadow)/10 to be WAR",
    "crumbs": [
      "Lecture 5: Wins Above Replacement II"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#working-with-soccer-event-data",
    "href": "lectures/lecture2.html#working-with-soccer-event-data",
    "title": "Lecture 2: Expected Value-based Evaluation",
    "section": "Working with soccer event data",
    "text": "Working with soccer event data\nWe will make use of high-resolution tracking data provided by the company Huddle StatsBomb. As a bit of background, StatsBomb extracts player locations using  To their great credit, StatsBomb releases a small snapshot of their data for public use. We can access this data directly in R using the StatsBombR package.\nYou can check if the package is installed using the code \"StatsBombR\" %in% rownames(installed.packages()). If that code returns FALSE, then you can install the package using the code devtools::install_github(\"statsbomb/StatsBombR\").\n\nlibrary(tidyverse)\n# save a nice color-blind friednly color palette into our environment\noi_colors &lt;- palette.colors(palette = \"Okabe-Ito\") \n\nStatsBomb organizes its free data by competition/tournament. The screenshot below shows a table of all the available competitions. We can load this table into our R environment using the function StatsBombR::FreeCompetitions()  Each competition and season have unique id and we can also see whether it was a men’s or women’s competition. To see which matches from selected competitions have publicy available data, we can pass the corresponding rows of this table to the function StatsBombR::FreeMatches(). Figure 2 shows the table of matches from the 2022 EURO Competition; StatsBomb graciously provided data for all matches from the tournament, which can be obtained using the code below.\n\nStatsBombR::FreeCompetitions() %&gt;%\n  filter(competition_id == 53 & season_id == 106) %&gt;% # Finds competition corresponding to EURO 2022\n  StatsBombR::FreeMatches() \n\nFinally, to get raw-event level data for certain matches, we need to pass the corresponding rows to the function StatsBombR::free_allevents(). StatsBomb also recommends running some basic pre-processing, all of which is nicely packaged together in the functions StatsBombR::allclean() and StatsBombR::get.opposingteam().\nAs an example, the code chunk below pulls out publicly available event data for every women’s international match.\n\nwi_events &lt;-\n  StatsBombR::FreeCompetitions() %&gt;% # get table of available competitions\n  filter(competition_gender == \"female\" & \n           competition_international) %&gt;% # filter to women's internationals\n  StatsBombR::FreeMatches() %&gt;% # Gets match data for all women's internationals\n  StatsBombR::free_allevents() %&gt;% # Gets all events for all matches\n  StatsBombR::allclean() %&gt;% # Apply StatsBomb's pre-processing\n  StatsBombR::get.opposingteam()\n\n\n\n\n\n\n\nNavigating complex code\n\n\n\nIt is not easy to code complicated pipelines like the above in a single attempt. In fact, I had to build the code line-by-line. For instance, I initially ran just the first line and manually inspected the table of free competitions (using View()) to figure out which variables I needed to filter() on in the second line. It is very helpful to develop pipelines incrementally and to check intermediate results before putting everything together in one block of code.",
    "crumbs": [
      "Lecture 2: Expected Value-based Evaluation"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#an-initial-expected-goals-model",
    "href": "lectures/lecture2.html#an-initial-expected-goals-model",
    "title": "Lecture 2: Expected Value-based Evaluation",
    "section": "An initial expected goals model",
    "text": "An initial expected goals model\nSuppose we observe a dataset consisting of \\(n\\) shots. For each shot \\(i = 1, \\ldots, n,\\) let \\(Y_{i}\\) be a binary indicator of whether the shot resulted in a goal (\\(Y_{i} = 1\\)) or not (\\(Y_{i} = 0\\)). From the high-resolution tracking data, we can extract a potentially huge number of features about the shot at the moment of it was taken. Possible features include, but are certainly not limited to, the player taking the shot, the body part and side of the body used, the positions of the defenders and goal keepers, and contextual information like the score. Mathematically, we can collect all these features into a (potentially large) vector \\(\\boldsymbol{\\mathbf{X}}_{i}.\\)\nExpected goals (XG) models work by (i) positing an infinite super-population of shots represented by pairs \\((\\boldsymbol{\\mathbf{X}}, Y)\\) of feature vector \\(\\boldsymbol{\\mathbf{X}}\\) and binary outcome \\(Y\\); and (ii) assuming that the shots in our dataset constitute a random sample \\((\\boldsymbol{\\mathbf{X}}_{1}, Y_{1}), \\ldots, (\\boldsymbol{\\mathbf{X}}_{n}, Y_{n})\\) from that population. ::: {.callout-note icon=false} ## Conditional Expectations\nFor each combination of features \\(\\boldsymbol{\\mathbf{x}}\\), the expect goals given \\(\\boldsymbol{\\mathbf{x}},\\) which we will denote by \\(\\textrm{XG}(\\boldsymbol{\\mathbf{X}})\\) is just the average value of \\(Y\\) among the (assumed infinite) sub-population of shots with features \\(\\boldsymbol{\\mathbf{X}} = \\boldsymbol{\\mathbf{x}}.\\) Mathematically, XG is conditional expectation: \\[\n\\textrm{XG}(\\boldsymbol{\\mathbf{x}}) = \\mathbb{E}[Y \\vert \\boldsymbol{\\mathbf{X}} = \\boldsymbol{\\mathbf{x}}],\n\\] :::\nBecause the shot outcome \\(Y\\) is binary, \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) is the proportion of goals scored within the sub-population of shots defined by the feature combinations \\(\\boldsymbol{\\mathbf{x}}.\\) In other words, it is the conditional probability of a goal given the shot features \\(\\boldsymbol{\\mathbf{x}}.\\) On this view, \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) provides a quantitative answer to our motivating question “If we were to replay a particular shot over and over again, what fraction of the time does it result in a goal?”\nThe StatsBomb variable shot.body_part.name records the body part with which each shot was taken. Within our dataset of women’s international matches, we can see the breakdown of these body parts\n\ntable(wi_events$shot.body_part.name)\n\n\n      Head  Left Foot      Other Right Foot \n       769       1024         23       2059 \n\n\nFor this analysis, we will focus on fitting XG models using data from shots taken with a player’s feet or head.\n\nwi_shots &lt;-\n  wi_events %&gt;% # Adds opposing team information\n  filter(type.name == \"Shot\" & shot.body_part.name != \"Other\") %&gt;%  # Subsets only shot event data\n  mutate(Y = ifelse(shot.outcome.name == \"Goal\", 1, 0))\n\nLater, it will be useful for us to focus only on the shots from EURO2022, so we will also create a table euro2022_shots of all shots from that competition using similar code.\n\n\nCode\neuro2022_shots &lt;-\n  StatsBombR::FreeCompetitions() %&gt;% # get table of available competitions\n  filter(competition_id == 53 & season_id == 106) %&gt;% # Finds competition corresponding to EURO 2022\n  StatsBombR::FreeMatches() %&gt;% # Gets match data for all EURO 2022\n  StatsBombR::free_allevents() %&gt;% # Gets all events for all matches\n  StatsBombR::allclean() %&gt;% # Apply StatsBomb's pre-processing\n  StatsBombR::get.opposingteam() %&gt;%\n  filter(type.name == \"Shot\" & shot.body_part.name != \"Other\") %&gt;%\n  mutate(Y = ifelse(shot.outcome.name == \"Goal\", 1, 0))\n\n\nNow suppose we only include the body part in \\(\\boldsymbol{\\mathbf{X}}\\). If we had full access to the infinite super-population of women’s international shots, then we could compute \\[\\textrm{XG}(\\text{right-footed shot}) = \\mathbb{P}(\\text{goal} \\vert \\text{right-footed shot})\\] by (i) forming a sub-group containing only those right-footed shots and then (ii) calculating the proportion of goals scored within that sub-group. We could similarly compute \\(\\textrm{XG}(\\text{left-footed shot})\\) and \\(\\textrm{XG}(\\text{header})\\) by calcuating the proportion of goals scored within the sub-groups containing, resptively, only left-footed shots and only headers.\nOf course, we don’t have access to the infinite super-population of shots. However, on the assumption that our observed data constitute a sample from that super-population, we can estimate \\(\\textrm{XG}\\) by mimicking the idealized calculations described above:\n\nBreak the dataset of all observed shots in women’s international matches into several groups based on the body part\nWithin these two groups, compute the proportion of goals\n\nTo keep things simple, we dropped the 23 shots that were taken with a body part other than the feet or the head.\n\nxg_model1 &lt;-\n  wi_shots %&gt;%\n  group_by(shot.body_part.name) %&gt;%\n  summarize(XG1 = mean(Y),\n            n = n())\nxg_model1\n\n# A tibble: 3 × 3\n  shot.body_part.name   XG1     n\n  &lt;chr&gt;               &lt;dbl&gt; &lt;int&gt;\n1 Head                0.112   769\n2 Left Foot           0.113  1024\n3 Right Foot          0.102  2059\n\n\n\n\n\n\n\n\nGeneralizing our model results\n\n\n\nA key assumption of all XG models is that the observed data is a random sample drawn from the super-population. The only women’s internationals matches for which StatsBomb data were from the 2019 and 2023 World Cup and the 2022 EURO tournaments. These matches are arguably not highly representative of all women’s international matches, meaning that we should exercise some caution when using models fitted to these data to analyze matches from other competitions (e.g., an international friendly or a match in a domestic league).\n\n\n\nAccounting for additional features\nWe can now create a table of just Beth Mead’s shots from EURO 2022 and add a column with the XG for each shot. To do this, we first filter our table wi_shots using the player name (note, StatsBomb uses her full name!). Then, for every left-footed shot Mead attempted, we want to copy over the corresponding value from the table xg_model1, which in this cse is 0.113. Similarly, we want to copy over the corresponding values for right-footed shots and headers from xg_model1 into our table for Mead’s shots. We can do this using an left join. In the code below, we actually create a temporary version of xg_model1 that drops the column recording the overall counts of the body part used for the shots in wi_shots. This way, when we perform the join, we don’t create a new column with these counts.\n\ntmp_xg1 &lt;- xg_model1 %&gt;% select(!n) # temporary copy of the table without sample size column\n\nmead_shots &lt;-\n  euro2022_shots %&gt;%\n  filter(player.name == \"Bethany Mead\") %&gt;%\n  left_join(y = tmp_xg1, by = c(\"shot.body_part.name\"))\nrm(tmp_xg1) # delete temporary copy\n\nWe can now look at the what our model says about the three goals from above. The first, against Austria in the 15th minute; the second, against Norway in the 37th minute, and the third against Sweden in the 33rd minute When These turn out to be in rows 1, 4, and 14 of the table mead_shots\n\nmead_shots %&gt;%\n  select(OpposingTeam, minute, shot.body_part.name, Y, XG1) %&gt;%\n  slice(c(1, 4, 14))\n\n# A tibble: 3 × 5\n  OpposingTeam    minute shot.body_part.name     Y   XG1\n  &lt;chr&gt;            &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 Austria Women's     15 Right Foot              1 0.102\n2 Norway Women's      37 Left Foot               1 0.113\n3 Sweden Women's      33 Right Foot              1 0.102\n\n\nAccording to our first model, these three goals appear equally impressive: our model put the respective chances of each shot resulting in a goal at about 10%, 11%, and 10%. But, watching the videos a bit more closely, this conclusions is not especially satisfying: Mead scored the first goal in a one-on-one situation but had to shoot through several defenders on the second and third goal The discrepancy between our qualitative comparisons and our quantitative modeling results stems from the fact that we only conditioned on the body part and did not account for the other ways that the shots are different. In other words, our initial XG model is much too coarse to quantify the differences between the three chances that we believe are important.\nTo better compare the three goals, we need to build a a finer XG model that conditions on more features, including ones that differ between the two shots. To this end, notice that Mead uses a different technique on the three shots: she lobs the ball into the net on the first goal, shoots the ball from the ground on the second goal, and scores the third goal off of a half volley, striking the ball as it bounced up off the ground. The StatsBomb variable shot.technique.name records the technique of each shot type\n\ntable(wi_shots$shot.technique.name)\n\n\n     Backheel Diving Header   Half Volley           Lob        Normal \n           25            10           529            15          3015 \nOverhead Kick        Volley \n           14           244 \n\n\nBy conditioning on both body part and technique, we can begin to build a more refined XG model. The code to do this is almost identical to the code used in our first model. The only difference is that we now group by two variables shot.body_part.name and shot.technique_name. Because we are grouping by two variables, specify the argument .groups=\"drop\" argument when calling summarize; this prevents a (mostly innocuous) warning message1. We additionally append our new XG estimates to the table containing all of Mead’s shots.\n\nxg_model2 &lt;-\n  wi_shots %&gt;%\n  group_by(shot.body_part.name, shot.technique.name) %&gt;%\n  summarize(XG2 = mean(Y),\n            n = n(), .groups = \"drop\")\n\ntmp_xg2 &lt;- xg_model2 %&gt;% select(-n)\nmead_shots &lt;-\n  mead_shots %&gt;%\n  inner_join(y = xg_model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))\nrm(tmp_xg2)\n\nmead_shots %&gt;%\n  select(OpposingTeam, minute, shot.body_part.name, shot.technique.name, Y, XG2) %&gt;%\n  slice(c(1, 4, 14))\n\n# A tibble: 3 × 6\n  OpposingTeam    minute shot.body_part.name shot.technique.name     Y    XG2\n  &lt;chr&gt;            &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt;\n1 Austria Women's     15 Right Foot          Lob                     1 0.333 \n2 Norway Women's      37 Left Foot           Normal                  1 0.121 \n3 Sweden Women's      33 Right Foot          Half Volley             1 0.0801",
    "crumbs": [
      "Lecture 2: Expected Value-based Evaluation"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#conditioning-on-even-more-features",
    "href": "lectures/lecture2.html#conditioning-on-even-more-features",
    "title": "Lecture 2: Expected Value-based Evaluation",
    "section": "Conditioning on even more features",
    "text": "Conditioning on even more features\nAt least for these three goals, our new XG estimates seem more reasonable: the one-on-one lob against Austria has a much higher XG than the shots through traffic against Norway and Sweden. But are we fully satisfied with this model? One could credibly argue that even though our model returns somewhat more sensible XG estimates, it is still too coarse for to meaningfully compare the shots above. After all, because it does not condition on distance, our model would return exactly the same XG for right-footed volleys taken one meter and 15 meters away from the goal. Similarly, we could try to account for the number of defenders between the shot and the goal and the position of the keeper.\nIf we had access to the infinite super-population of shots, conditioning on more features is conceptually straightforward: we look at the corresponding sub-group of the super-population defined by a particular combination of features and compute the average \\(Y.\\) Unfortunately, with finite data, trying to “bin-and-average” using lots of features can lead to erratic estimates. For instance, here are the five largest and five smallest XG estimates based on body-part and shot technique.\n\nxg_model2 %&gt;% arrange(desc(XG2)) %&gt;% filter(row_number() %in% c(1:5, (n()-4):n()))\n\n# A tibble: 10 × 4\n   shot.body_part.name shot.technique.name    XG2     n\n   &lt;chr&gt;               &lt;chr&gt;                &lt;dbl&gt; &lt;int&gt;\n 1 Right Foot          Lob                 0.333     12\n 2 Left Foot           Volley              0.162     74\n 3 Right Foot          Backheel            0.136     22\n 4 Left Foot           Normal              0.121    750\n 5 Head                Normal              0.113    759\n 6 Right Foot          Volley              0.0412   170\n 7 Head                Diving Header       0         10\n 8 Left Foot           Backheel            0          3\n 9 Left Foot           Lob                 0          3\n10 Left Foot           Overhead Kick       0          2\n\n\nBecause none of the 3 left-footed lobs in our dataset led to goals, our model estimates \\(\\textrm{XG}(\\text{left-footed lob})\\) as 0. Similarly, the rather large \\(\\textrm{XG}(\\text{right-footed lob})\\) estimate of around 33% is based on only 12 shots. Attempting to condition on even more variables would result in estimates based on even smaller sample sizes!\nSo, it would appear that we’re stuck between a rock and a hard place. On the one hand, our XG model with two features is too coarse to quantify important differences between the motivating shots. But on the other hand, binning and averaging with even more features carries the risk of producing highly erratic, extreme, and somewhat nonsensical estimates2 To overcome this challenge, we can build a statistical model.\nLater in the course, we will discuss how to estimate more granular XG models with loads more features. But for today, we’ll use XG estimates from StatsBomb LLC (Huddl?). Although this is a proprietary model, StatsBomb has published a lot of information about what all goes into it. In addition to the body part and technique, they also construct several features based on location of the players (in 2 dimensions) and the ball (in 3 dimensions).\n\n\nmead_shots %&gt;%\n  filter(Y == 1) %&gt;%\n  select(OpposingTeam, minute, shot.body_part.name, shot.technique.name, Y, shot.statsbomb_xg)\n\n# A tibble: 6 × 6\n  OpposingTeam     minute shot.body_part.name shot.technique.name     Y\n  &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;               &lt;dbl&gt;\n1 Austria Women's      15 Right Foot          Lob                     1\n2 Norway Women's       33 Head                Normal                  1\n3 Norway Women's       37 Left Foot           Normal                  1\n4 Norway Women's       80 Left Foot           Volley                  1\n5 Northern Ireland     43 Left Foot           Normal                  1\n6 Sweden Women's       33 Right Foot          Half Volley             1\n# ℹ 1 more variable: shot.statsbomb_xg &lt;dbl&gt;\n\n\nRecall that XG quantifies a certain hypothetical long-term frequency of scoring a goal: if the shot was replayed under exactly the conditions quantified by the feature vector \\(\\boldsymbol{\\mathbf{x}}\\), \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) is the proportion of times a goal is scored. So, we should be fairly impressed when a player scores a goal on a shot with very low XG. We can quantify the degree to which players under- or over-perform the model expectations by comparing the In the case of Beth Mead, we want to sum the difference \\(Y_{i} = \\textrm{XG}_{i}\\) where \\(\\textrm{XG}_{i}\\) is the StatsBomb XG estimate.\n\nsum(mead_shots$Y - mead_shots$shot.statsbomb_xg)\n\n[1] 2.896323\n\n\nDuring Euro 2022, Beth Mead scored a total of 6 goals, which was about 2.9 goals more than what the StatsBomb XG model expected, based on the contexts in which she attempted shots. We can repeat this calculation – summing over the difference between shot outcome \\(Y\\) and \\(\\textrm{XG}\\) — for all players in EURO 2022 to find the players that most over-performed and most under-performed the model expectations.\n\ngoe &lt;- \n  euro2022_shots %&gt;%\n  mutate(diff = Y - shot.statsbomb_xg) %&gt;%\n  group_by(player.name) %&gt;%\n  summarise(GOE = sum(diff),\n            n = n()) %&gt;%\n  arrange(desc(GOE))\n\ngoe\n\n# A tibble: 200 × 3\n   player.name               GOE     n\n   &lt;chr&gt;                   &lt;dbl&gt; &lt;int&gt;\n 1 Alexandra Popp          3.34     16\n 2 Bethany Mead            2.90     15\n 3 Alessia Russo           1.79     12\n 4 Francesca Kirby         1.79      5\n 5 Lina Magull             1.70     14\n 6 Ingrid Filippa Angeldal 1.37     10\n 7 Romée Leuchter          1.19      2\n 8 Hanna Ulrika Bennison   0.952     1\n 9 Nicole Anyomi           0.896     1\n10 Julie Blakstad          0.879     1\n# ℹ 190 more rows\n\n\nIt turns out that Alexandra Popp, the German captain, outperformed StatsBomb’s XG model expectations, by an even wider margin than Beth Mead. Like Mead, Popp scored 6 goals during the tournament off a similar number of shots (16 for Popp and 15 for Mead). Interestingly, Mead won the Golden Boot because she had one more assist…",
    "crumbs": [
      "Lecture 2: Expected Value-based Evaluation"
    ]
  },
  {
    "objectID": "lectures/lecture2.html#footnotes",
    "href": "lectures/lecture2.html#footnotes",
    "title": "Lecture 2: Expected Value-based Evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee this StackOverflow post and the documentation for summarise for details.↩︎\nIndeed, it seems absurd to claim that, at least in women’s international soccer, players will never score off left-footed lobs! As the statistician Dennis Lindley put it we must “never believe in anything absolutely” and should “leave a little probability for the moon being made of green cheese; it can be as small as 1 in a million, but have it there since otherwise an army of astronauts returning with samples of the said cheese will leave you unmoved” ( source). Lindley termed this principle “Cromwell’s Rule”, a reference to a Oliver Cromwell’s famous quote “I beesech you, in the bowels of Christ, think it possible that you may be mistaken.”↩︎",
    "crumbs": [
      "Lecture 2: Expected Value-based Evaluation"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#overview-allocation-of-credit-in-baseball",
    "href": "lectures/lecture4.html#overview-allocation-of-credit-in-baseball",
    "title": "Lecture 4: Wins above Replacement I",
    "section": "",
    "text": "Expected runs framework",
    "crumbs": [
      "Lecture 4: Wins above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#obtaining-pitch-by-pitch-data",
    "href": "lectures/lecture4.html#obtaining-pitch-by-pitch-data",
    "title": "Lecture 4: Wins above Replacement I",
    "section": "Obtaining pitch-by-pitch data",
    "text": "Obtaining pitch-by-pitch data\n\nPitchF/X and StatCast\n\n\n\nAccessing data from StatCast\nMajor League Baseball hosts a public-facing web interface for accessing StatCast data. Using that interface, users can pull up data for individual players or about all pitches of a certain type. Powering this website is an application programming interface (API), which allows software applications to connect to the underlying StatCast database. It is through this API that the baseballR package acquires data. If you have not yet installed that package, you can do so using the following code\n\ndevtools::install_github(repo = \"BillPetti/baseballr\")\n\nThe baseballR package provides a function baseballr::statcast_search() that allows users query all StatCast data by date, player, or player type. One of the original StatCast authors, Bill Petti, wrote a wrapper function that uses baseballr::statcast_search() to pull down an entire season’s worth of pitch-by-pitch data; see this blog post for more the wrapper function code and this earlier post for details about its design. Since he published his original function, StatCast has added some new fields, necessitating a few changes. The code below defines a new scraper, which we will use in the course. An R script containing this code is available at this link. At a high level, the scraping function pulls data from StatCast on a week-by-week basis.\n\n\nShow the code\nannual_statcast_query &lt;- function(season) {\n  \n  data_base_column_types &lt;- \n    read_csv(\"https://app.box.com/shared/static/q326nuker938n2nduy81au67s2pf9a3j.csv\")\n  \n  dates &lt;- \n    seq.Date(as.Date(paste0(season, '-03-01')),\n             as.Date(paste0(season, '-12-01')), \n             by = '4 days')\n  \n  date_grid &lt;- \n    tibble::tibble(start_date = dates, \n                   end_date = dates + 3)\n  \n  safe_savant &lt;- \n    purrr::safely(scrape_statcast_savant)\n  \n  payload &lt;- \n    purrr::map(.x = seq_along(date_grid$start_date),\n               ~{message(paste0('\\nScraping week of ', date_grid$start_date[.x], '...\\n'))\n                 payload &lt;- \n                   safe_savant(start_date = date_grid$start_date[.x], \n                               end_date = date_grid$end_date[.x], \n                               type = 'pitcher')\n                 return(payload)\n                 })\n  \n  payload_df &lt;- purrr::map(payload, 'result')\n  \n  number_rows &lt;- \n    purrr::map_df(.x = seq_along(payload_df),\n                  ~{number_rows &lt;- \n                    tibble::tibble(week = .x, \n                                   number_rows = length(payload_df[[.x]]$game_date))\n                  }) %&gt;%\n    dplyr::filter(number_rows &gt; 0) %&gt;%\n    dplyr::pull(week)\n  \n  payload_df_reduced &lt;- payload_df[number_rows]\n  \n  payload_df_reduced_formatted &lt;- \n    purrr::map(.x = seq_along(payload_df_reduced), \n               ~{cols_to_transform &lt;- \n                 c(\"pitcher\", \"fielder_2\", \"fielder_3\",\n                   \"fielder_4\", \"fielder_5\", \"fielder_6\", \"fielder_7\",\n                   \"fielder_8\", \"fielder_9\")\n               df &lt;- \n                 purrr::pluck(payload_df_reduced, .x) %&gt;%\n                 dplyr::mutate_at(.vars = cols_to_transform, as.numeric) %&gt;%\n                 dplyr::mutate_at(.vars = cols_to_transform, function(x) {ifelse(is.na(x), 999999999, x)})\n               character_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"character\") %&gt;%\n                 dplyr::pull(variable)\n               numeric_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"numeric\") %&gt;%\n                 dplyr::pull(variable)\n               integer_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"integer\") %&gt;%\n                 dplyr::pull(variable)\n               df &lt;- \n                 df %&gt;%\n                 dplyr::mutate_if(names(df) %in% character_columns, as.character) %&gt;%\n                 dplyr::mutate_if(names(df) %in% numeric_columns, as.numeric) %&gt;%\n                 dplyr::mutate_if(names(df) %in% integer_columns, as.integer)\n               return(df)\n               })\n  \n  combined &lt;- payload_df_reduced_formatted %&gt;%\n    dplyr::bind_rows()\n  \n  return(combined)\n}\n\n\nTo use this function, it is enough to run something like.\n\nstatcast2024 &lt;- annual_statcast_query(2024)\n\n\n\n\n\n\n\nLong run time\n\n\n\nScraping a single season of StatCast data can take on the order of 10’s of minutes. If you do scrape the data yourself, I highly recommend saving the data table in an .RData file that can be loaded into future R sessions. For instance,\n\nlibrary(tidyverse)\nstatcast2024 &lt;- annual_statcast_query(2024)\nsave(statcast2024, file = \"statcast2024.RData\")\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nload(\"~/Dropbox/Teaching/2025-26/stat479_f25_sports/lecture_planning/pitchFraming/statcast2024.RData\")\nload(\"~/Dropbox/Teaching/2025-26/stat479_f25_sports/lecture_planning/pitchFraming/statcast2023.RData\")\nload(\"~/Dropbox/Teaching/2025-26/stat479_f25_sports/lecture_planning/pitchFraming/statcast2022.RData\")\n\nIn the 2024 season, we have StatCast data for 784,978 pitches. The dataset records 118 different variables for each pitch. Some of them are contextual variables like game_pk, which is the unique identifier for a game, and game_date, which is the date of the game, while others like batter, pitcher, and fielder_2 list the players involved in the pitch. The dataset also includes information about the pitch trajectory like plate_x and plate_z, which record the horizontal and vertical coordinates of the pitch as it crosses the front edge of home plate, and the pitch outcome The data table also contains 118 variables, many of which are defined in the StatCast documentation. The function annual_statcast_query actually scrapes data not only from the regular season but also from the pre-season and the play-offs. For our analysis, we will focus only on the regular season data. The variable game_type records the type of game in which each pitch was thrown.\n\ntable(statcast2024$game_type, useNA = 'always')\n\n\n     D      F      L      R      S      W   &lt;NA&gt; \n  5182   2488   3540 695136  77056   1576      0 \n\n\nLooking at the StatCast documentation, we see that regular season pitches have game_type==\"R\". We additionally filter out any pitches with nonsensical values like 4 balls or 3 strikes (for 2024, this turns out to be only 1 pitch).\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;% \n  filter(game_type == \"R\") %&gt;%\n  filter(strikes &gt;= 0 & strikes &lt; 3 & \n           balls &gt;= 0 & balls &lt; 4 & \n           outs_when_up &gt;= 0 & outs_when_up &lt; 3) %&gt;%\n  arrange(game_pk, inning, desc(inning_topbot), at_bat_number, pitch_number)\n\nWe’re now left with 695,135 regular season pitches.",
    "crumbs": [
      "Lecture 4: Wins above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#adjusting-re24-for-platoon-advantage-ballpark",
    "href": "lectures/lecture4.html#adjusting-re24-for-platoon-advantage-ballpark",
    "title": "Lecture 4: Wins above Replacement I",
    "section": "Adjusting RE24 for platoon advantage & ballpark",
    "text": "Adjusting RE24 for platoon advantage & ballpark",
    "crumbs": [
      "Lecture 4: Wins above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#footnotes",
    "href": "lectures/lecture4.html#footnotes",
    "title": "Flexible regression: Building our own XG model",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ntry to convince yourself why!↩︎",
    "crumbs": [
      "Flexible regression: Building our own XG model"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#expected-runs-in-baseball",
    "href": "lectures/lecture3.html#expected-runs-in-baseball",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "Expected Runs in Baseball",
    "text": "Expected Runs in Baseball\nLong history of statistical analyses in baseball. This is partly due to its discrete nature; this permits analyses at the game-, inning-, at-bat-, and pitch-level.\n\nAccessing StatCast Data",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#building-our-own-expected-goals-model",
    "href": "lectures/lecture3.html#building-our-own-expected-goals-model",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "Building our own expected goals model",
    "text": "Building our own expected goals model\nRecall the interpretation of conditional expectation \\(\\mathbb{E}[Y \\vert X = x]\\): we look at all possible combinations of \\((X,Y)\\) where \\(X = x\\) and take the In the context of expected runs, \\(Y\\) is the number of runs scored in the half-inning. And to estimate expected runs, we mirroed this definition: we looked\nWe only conditioned on a handful of variables. You might (credibly!) argue that we can get a more nuanced\nUnforutnately, we can’t just “bin and average” anymore. Expected goals in soccer is a good example of this.\n\nFormally, for every shot attempt let \\(Y\\) be an indicator that the shot was made and let \\(\\mathbf{X}\\) be the conditioning information. Depending on what we include in \\(\\mathbf{X}\\), XG can be very fine-grained\nYou might argue that the va\nIntuitively, we expect shots taken very close to the goal to have larger xG than shots taken very far from the goal\n\nHandcrafting features\n\n\nAdding interactions\nIt may not just be distance and body part but their interaction;",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#working-with-baseball-tracking-data",
    "href": "lectures/lecture3.html#working-with-baseball-tracking-data",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "Working with baseball tracking data",
    "text": "Working with baseball tracking data\n\nHistory of tracking data\n\n\n\nAccessing StatCast Data\nMajor League Baseball hosts a public-facing web interface for accessing StatCast data. Using that interface, users can pull up data for individual players or about all pitches of a certain type. Powering this website is an application programming interface (API), which allows software applications to connect to the underlying StatCast database. It is through this API that the baseballR package acquires data. If you have not yet installed that package, you can do so using the code devtools::install_github(repo = \"BillPetti/baseballr\")\nThe baseballR package provides a function baseballr::statcast_search() that allows users query all StatCast data by date, player, or player type. One of the original baseballr authors, Bill Petti, wrote a wrapper function that uses baseballr::statcast_search() to pull down an entire season’s worth of pitch-by-pitch data; see this blog post for more the wrapper function code and this earlier post for details about its design. Since he published his original function, StatCast has added some new fields, necessitating a few changes to the original script. The code below defines a new scraper, which we will use in the course. An R script containing this code is available at this link. At a high level, the scraping function pulls data from StatCast on a week-by-week basis.\n\n\nShow the code\nannual_statcast_query &lt;- function(season) {\n  \n  data_base_column_types &lt;- \n    read_csv(\"https://app.box.com/shared/static/q326nuker938n2nduy81au67s2pf9a3j.csv\")\n  \n  dates &lt;- \n    seq.Date(as.Date(paste0(season, '-03-01')),\n             as.Date(paste0(season, '-12-01')), \n             by = '4 days')\n  \n  date_grid &lt;- \n    tibble::tibble(start_date = dates, \n                   end_date = dates + 3)\n  \n  safe_savant &lt;- \n    purrr::safely(scrape_statcast_savant)\n  \n  payload &lt;- \n    purrr::map(.x = seq_along(date_grid$start_date),\n               ~{message(paste0('\\nScraping week of ', date_grid$start_date[.x], '...\\n'))\n                 payload &lt;- \n                   safe_savant(start_date = date_grid$start_date[.x], \n                               end_date = date_grid$end_date[.x], \n                               type = 'pitcher')\n                 return(payload)\n                 })\n  \n  payload_df &lt;- purrr::map(payload, 'result')\n  \n  number_rows &lt;- \n    purrr::map_df(.x = seq_along(payload_df),\n                  ~{number_rows &lt;- \n                    tibble::tibble(week = .x, \n                                   number_rows = length(payload_df[[.x]]$game_date))\n                  }) %&gt;%\n    dplyr::filter(number_rows &gt; 0) %&gt;%\n    dplyr::pull(week)\n  \n  payload_df_reduced &lt;- payload_df[number_rows]\n  \n  payload_df_reduced_formatted &lt;- \n    purrr::map(.x = seq_along(payload_df_reduced), \n               ~{cols_to_transform &lt;- \n                 c(\"pitcher\", \"fielder_2\", \"fielder_3\",\n                   \"fielder_4\", \"fielder_5\", \"fielder_6\", \"fielder_7\",\n                   \"fielder_8\", \"fielder_9\")\n               df &lt;- \n                 purrr::pluck(payload_df_reduced, .x) %&gt;%\n                 dplyr::mutate_at(.vars = cols_to_transform, as.numeric) %&gt;%\n                 dplyr::mutate_at(.vars = cols_to_transform, function(x) {ifelse(is.na(x), 999999999, x)})\n               character_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"character\") %&gt;%\n                 dplyr::pull(variable)\n               numeric_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"numeric\") %&gt;%\n                 dplyr::pull(variable)\n               integer_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"integer\") %&gt;%\n                 dplyr::pull(variable)\n               df &lt;- \n                 df %&gt;%\n                 dplyr::mutate_if(names(df) %in% character_columns, as.character) %&gt;%\n                 dplyr::mutate_if(names(df) %in% numeric_columns, as.numeric) %&gt;%\n                 dplyr::mutate_if(names(df) %in% integer_columns, as.integer)\n               return(df)\n               })\n  \n  combined &lt;- payload_df_reduced_formatted %&gt;%\n    dplyr::bind_rows()\n  \n  return(combined)\n}\n\n\nTo use this function, it is enough to run something like.\n\nstatcast2024 &lt;- annual_statcast_query(2024)\n\n\n\n\n\n\n\nTime and disk space requirements\n\n\n\nScraping a single season of StatCast data can take between 30 and 45 minutes. I highly recommend scraping the data for any season only once and saving the resulting data table in an .RData file that can be loaded into future R sessions.\n\nlibrary(tidyverse)\nstatcast2024 &lt;- annual_statcast_query(2024)\nsave(statcast2024, file = \"statcast2024.RData\")\n\nThese .RData files take between 75MB and 150MB of space. So, if you want to work with several seasons (e.g., going back all the way to 2008, the first season for which pitch tracking data is available), you will need about 2.5GB of storage space on your computer.\n\n\n\n\nWorking with StatCast data\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nIn the 2024 season, we have StatCast data for 784,978 pitches. The dataset records 118 different variables for each pitch. Some of them are contextual variables like game_pk, which is the unique identifier for a game, and game_date, which is the date of the game, while others like batter, pitcher, and fielder_2 list the players involved in the pitch. The dataset also includes information about the pitch trajectory like plate_x and plate_z, which record the horizontal and vertical coordinates of the pitch as it crosses the front edge of home plate, and the pitch outcome The data table also contains 118 variables, many of which are defined in the StatCast documentation. The function annual_statcast_query actually scrapes data not only from the regular season but also from the pre-season and the play-offs. For our analysis, we will focus only on the regular season data. The variable game_type records the type of game in which each pitch was thrown.\n\ntable(statcast2024$game_type, useNA = 'always')\n\n\n     D      F      L      R      S      W   &lt;NA&gt; \n  5182   2488   3540 695136  77056   1576      0 \n\n\nLooking at the StatCast documentation, we see that regular season pitches have game_type==\"R\". We additionally filter out any pitches with nonsensical values like 4 balls or 3 strikes (for 2024, this turns out to be only 1 pitch).\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;% \n  filter(game_type == \"R\") %&gt;%\n  filter(strikes &gt;= 0 & strikes &lt; 3 & \n           balls &gt;= 0 & balls &lt; 4 & \n           outs_when_up &gt;= 0 & outs_when_up &lt; 3) %&gt;%\n  arrange(game_pk, inning, desc(inning_topbot), at_bat_number, pitch_number)\n\nWe’re now left with 695,135 regular season pitches.\nFor every pitch, the StatCast dataset records the identities of the batter (batter), pitcher (pitcher), and the other fielders (fielders_2, …, fielders_9). However, it does not identify them by name, instead using an ID number, which is assigned by MLB Advanced Media. We can look up the corresponding player names using a database maintained by the Chadwick Register. The function baseballr::chadwick_player_lu downloads the Chadwick database and stores it as a data table in R. Like with the raw pitch-by-pitch data, I recommend that you download this player identity database once and save the table as an .RData object for future use.\n\nplayer_lookup &lt;-\n  baseballr::chadwick_player_lu() %&gt;%\n  mutate(Name = paste(name_first, name_last)) %&gt;%\n  select(key_mlbam, Name)\n\nIn the data, it does n",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#expected-runs",
    "href": "lectures/lecture3.html#expected-runs",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "Expected Runs",
    "text": "Expected Runs\nWe will encode baserunner configuration using a binary string of length 3. If there is a runner on first base, the first digit will be a 1 and if there is not a runner on first base, the first digit will be a 0. Similarly, the second and third digits respectively indicate whether there are runners on second and third base. So if \\(\\textrm{br} = \"011\"\\) that means that there are runners on second and third base at the beginning of the at-bat but not on first base. The raw StatCast data contains variables on_1b, on_2b, and on_3b. From a quick visual inspection of the dataset (e.g., with statcast2024$on_1b[1:100]), we find many NA values. These correspond to pitches when there is nobody on that particular base. When the value is not NA, it is the numeric id of the batting team player who is on that base. To create the 3-digit binary string encoding baserunner configuration, notice that 1*(!is.na(on_1b)) will return a 1 if there is somone on first base and 0 otherwise. So by pasting together the results of 1*(!is.na(on_1b)), 1*(!is.na(on_2b)), and 1*(!is.na(on_3b)), we can form the 3-digit binary string described above. In the codeblock below, we also rename the column outs_when_up to Outs.\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  mutate(\n    BaseRunner = \n      paste0(1*(!is.na(on_1b)),\n             1*(!is.na(on_2b)),\n             1*(!is.na(on_3b)))) %&gt;%\n  rename(Outs = outs_when_up)\n\nThere are 3 possible values for the number of outs (\\(\\textrm{o} \\in \\{0,1,2\\}\\)) and 8 possible values for the baserunner configuration (\\(\\textrm{br} \\in \\{\"000\", \"100\", \"010\", \"001\", \"110\", \"101\", \"011\", \"111\"\\}\\)). So, there are 24 different values of run expectancy, which is often presented in a table with rows corresponding to baserunner configuration and columns corresponding to outs.\n\nComputing \\(\\rho(\\textrm{o}, \\textrm{br})\\)\nComputing \\(\\rho(\\textrm{o}, \\textrm{br})\\) is conceptually straightforward: we need to divide our observed at-bats into 24 bins, one for each combination of \\((\\textrm{o}, \\textrm{br})\\) and then compute the average value of \\(R\\) within each bin. This is exactly the same “binning-and-averaging” procedure we used to fit our initial XG models in Lecture 2. We will do this using at-bats taken in the first 8 innings of played in the 2021, 2022, and 2023 regular seasons. We focus only on the first 8 innings because the 9th and extra innings are fundamentally different than the others. Specifically, the bottom half of the 9th (or later) innings is only played if the game is tied or the home team is trailing after the top of the 9th inning concludes. In those half-innings, if played, the game stops as soon as a winning run is scored. For instance, say that the home team is trailing by 1 runs in the bottom of the 9th and that there are runners on first and second base. If the batter hits a home run, the at-bat is recorded as resulting in only two runs (the tying run from second and the winning run from first). But the exact same scenario would result in 3 runs in an earlier inning.\n\nComputing runs scored in the half-inning\nSuppose that in a given at-bat \\(a\\) that there are \\(n_{a}\\) pitches. Within at-bat \\(a,\\) for each \\(i = 1, \\ldots, n_{a},\\) let \\(R_{i,a}\\) be the number of runs scored in the half-inning after that pitch (including any runs scored as a result of pitch \\(i\\)). So \\(R_{1,a}\\) is the number of runs scored in the half-inning after the first pitch, \\(R_{2,a}\\) is the number of runs scored subsequent to the second pitch, etc. Our first step towards building the necessary at-bat-level data set will be to append a column of \\(R_{i,a}\\) values to each season’s StatCast data.\nWe start by illustrating the computation using a single half-inning from the Dodgers-Padres game introduced earlier. The code below pulls out all pitches thrown in the top of the 8th inning of the game. During this inning, the Dodgers scored 4 runs.\n\ndodgers_inning &lt;-\n  statcast2024 %&gt;%\n  filter(game_pk == 745444 & inning == 8 & inning_topbot == \"Top\") %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner,\n         bat_score, post_bat_score, events, description, des,\n         type, \n         on_1b, on_2b, on_3b, hc_x, hc_y, hit_location) %&gt;%\n  arrange(at_bat_number, pitch_number)\n\nThe column bat_score records the batting team’s score before each pitch is thrown. The column post_bat_score records the batting team’s score after the the outcome of the pitch. For most of the 25 pitches, we find that bat_score is equal to post_bat_score; this is because only a few pitches result in scoring events.\n\nrbind(bat_score = dodgers_inning$bat_score, post_bat_score = dodgers_inning$post_bat_score)\n\n               [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\nbat_score         1    1    1    1    1    1    1    1    1     1     1     1\npost_bat_score    1    1    1    1    1    1    1    1    1     1     1     1\n               [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\nbat_score          1     1     2     3     3     3     4     5     5     5\npost_bat_score     1     2     3     3     3     4     5     5     5     5\n               [,23] [,24] [,25]\nbat_score          5     5     5\npost_bat_score     5     5     5\n\n\nCross-referencing the table above with the play-by-play data, we see that the Dodgers score their second run after the 14th pitch of the half-inning (on a Enrique Hernández sacrifice fly); their third run on the very next pitch (Gavin Lux grounding into a fielder’s choice); and their fourth and fifth runs on consecutive pitches (on singles by Mookie Betts and Shohei Ohtani).\n\n\n\nDodgers-Padres Play-by-Play\n\n\nWe can verify this by looking at the variable des, which stores a narrative description about what happened during the at-bat.\n\ndodgers_inning$des[c(14,15, 18, 19)]\n\n[1] \"Enrique Hernández out on a sacrifice fly to left fielder José Azocar. Max Muncy scores.\"                                                                                             \n[2] \"Gavin Lux reaches on a fielder's choice, fielded by first baseman Jake Cronenworth. Teoscar Hernández scores. James Outman to 2nd. Fielding error by first baseman Jake Cronenworth.\"\n[3] \"Mookie Betts singles on a ground ball to left fielder José Azocar. James Outman scores. Gavin Lux to 2nd.\"                                                                           \n[4] \"Shohei Ohtani singles on a line drive to left fielder José Azocar. Gavin Lux scores. Mookie Betts to 2nd.\"                                                                           \n\n\nNotice that the maximum value of post_bat_score is the batting team’s score at the end of the inning2. Thus, to compute \\(R_{i,a}\\) for all pitches in this inning, it is enough to subtract the corresponding bat_score value from the maximum value of post_bat_score across the whole half-inning.\n\nmax(dodgers_inning$post_bat_score) - dodgers_inning$bat_score\n\n [1] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 1 0 0 0 0 0 0\n\n\nWe now append a column with these values to our data table dodgers_inning\n\ndodgers_inning &lt;-\n  dodgers_inning %&gt;%\n  mutate(RunsRemaining = max(post_bat_score) - bat_score)\n\nWe’re now ready to extend these calculation to every half-inning of every game in the season. To do this, we will take advantage of the group_by() command in dplyr to apply the same calculation to small groups defined by game and half-inning.\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  group_by(game_pk, inning, inning_topbot) %&gt;% # divide up by game and half-inning\n  mutate(RunsRemaining = max(post_bat_score) - bat_score) %&gt;%\n  ungroup()\n\n\n\nFrom pitches to at-bats\nWe now have the number of runs scored in the half-inning after each pitch. But to compute run expectancy, we need this quantity at the at-bat level and not at the pitch-level. Using our notation from before, note that \\(R_{1,a}\\) is the number of runs scored after the first pitch of at-bat \\(a.\\) So, to compute run expectancy, it is enough to pull out the first pitch from each at-bat (i.e., those pitches with pitch_number == 1) using the filter() function. For instance, here is what that looks like in the top of the 8th inni\n\n\nPutting it all together\nWe can loop over the pitch-by-pitch data from multiple seasons, append \\(R_{i,a}\\) values to each one, and the number of outs, baserunner configuration, and \\(R_{1,a}\\) for each at-bat in that season. In the code below, we loop over each season and save the at-bat level run expectancy data in a list. Then we stack the data frames on top over each other using the bind_rows() command.\n\ner_data_list &lt;- list() # list of save at-bat level data for previous seasons\nfor(year in 2021:2023){\n  ix &lt;- year-2020\n  er_data &lt;-\n    get(paste0(\"statcast\", year)) %&gt;%\n    filter(game_type == \"R\" & inning &lt;= 8) %&gt;%\n    filter(strikes &gt;= 0 & strikes &lt; 3 & \n           balls &gt;= 0 & balls &lt; 4 & \n           outs_when_up &gt;= 0 & outs_when_up &lt; 3) %&gt;%\n    group_by(game_pk, inning, inning_topbot) %&gt;%\n    mutate(RunsRemaining = max(post_bat_score) - bat_score) %&gt;%\n    ungroup() %&gt;%\n    mutate(BaseRunner = \n             paste0(1*(!is.na(on_1b)), # 1st digit of string for baserunner\n                    1*(!is.na(on_2b)), # 2nd digit of string for baserunner\n                    1*(!is.na(on_3b)))) %&gt;% # 3rd digit of string for baserunner\n    arrange(game_pk, \n            inning, \n            desc(inning_topbot), # show bottom of innings before top\n            at_bat_number, pitch_number) %&gt;%\n    filter(pitch_number == 1) %&gt;%\n    rename(Outs = outs_when_up) %&gt;%\n    select(Outs, BaseRunner, RunsRemaining)\n er_data_list[[ix]] &lt;- er_data\n rm(er_data)\n}\n# stack data from all previous seasons into one bit dataframe\ner_data_all &lt;- dplyr::bind_rows(er_data_list)\n\nWe can now group the rows of er_data_all by combinations of baserunner and outs to compute \\(\\rho(\\textrm{o}, \\textrm{br}).\\)\n\nexpected_runs &lt;-\n  er_data_all %&gt;%\n  group_by(Outs, BaseRunner) %&gt;%\n  summarize(rho = mean(RunsRemaining), .groups = \"drop\")\n\nThe table expected_runs contains one row for every combination of outs and base-runner configuration. Traditionally, expected runs is reported using an \\(8\\times 3\\) matrix, with rows corresponding to base-runner configurations and columns corresponding to outs. We can re-format expected_runs to this matrix format using the pivot_wider() function\n\nexpected_runs %&gt;% \n  pivot_wider(names_from = Outs,\n              values_from = rho,\n              names_prefix=\"Outs: \")\n\n# A tibble: 8 × 4\n  BaseRunner `Outs: 0` `Outs: 1` `Outs: 2`\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 000            0.505     0.266     0.102\n2 001            1.34      0.987     0.384\n3 010            1.15      0.704     0.324\n4 011            2.04      1.41      0.575\n5 100            0.913     0.533     0.227\n6 101            1.80      1.17      0.512\n7 110            1.53      0.942     0.464\n8 111            2.42      1.65      0.824",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#run-value",
    "href": "lectures/lecture3.html#run-value",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "Run value",
    "text": "Run value\nSuppose a batter comes up to the plate when there 2 outs and no runners on base . Based on the game state at the start of the at-bat (i.e., Outs=2 and BaseRunners='000'), his team can expect to score 0.101 runs in the remainder of the half-inning. Now suppose the batter his a double, advancing to second base and changing the game state to Outs=2 and BaseRunners='010' According to our expected runs matrix, from this updated state, the batting team expects to score 0.320 runs in the remaining of the half-inning. If, however, the batter had struck out in this plate appearance, then he would have ended the half-inning, from which point his team can expect to score no runs in the remainder of the half-inning. So, on average, the batter earns his team about 0.2 runs, on average, by hitting a double and advancing to second, and loses his team about 0.1 runs, on average, by striking out from the game state Outs=2 and BaseRunners='000'.\n\n\n\n\n\n\nRun value\n\n\n\nThe run value of an at-bat is defined as the the number of runs scored in the at-bat plus the difference in expected runs from the starting to ending state. That is, denoting the number of runs scored in the at-bat as \\(\\textrm{RunsScored}\\) and the starting and ending states as \\((\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\\) and \\((\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}),\\) then \\[\n\\textrm{RunValue} = \\textrm{RunsScored} + \\rho(\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}) - \\rho(\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\n\\]\n\n\nIn a sense, run value rewards batter credits for two things, actually scoring runs and putting their team in positions to score more runs. At the same time, it penalizes batters who do not hit home runs or drive in runs and/or move their team to a less-favorable run expectancy.\nTo do compute the run value of each at-bat in the 2024 season, we must compute\n\nThe number of runs scored during each at-bat\nThe game state (i.e., the number of outs and the base-runner configuration) at the start and end of each at-bat\nThe change in expected runs during the at-bat (i.e., \\(\\rho(\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}) - \\rho(\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\\)).\n\nWe will first develop the necessary code using the data from Dodger’s 8th inning from their game against the Padres. Then, we will deploy that code to the whole statcast2024 table by grouping by game_pk and at_bat_number.\n\n\nCalculating RunsScored\nStatCast numbers every at-bat within the game and every pitch within each at-bat. To compute the number of runs scored within each at-bat, we will:\n\nSort the pitches by at-bat number and then by pitch number in ascending order\nTake the different between the last value of post_bat_score and first value of bat_score within each at-bat.\n\nLet’s try to verify this by looking at pitches from the third, fourth, and fifth at-bats of Dodgers’ 8th inning against the Padres3\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 61:63) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, bat_score, description, post_bat_score)\n\n── MLB Baseball Savant Statcast Search data from baseballsavant.mlb.com ────────\n\n\nℹ Data updated: 2025-06-21 09:37:16 CDT\n\n\n# A tibble: 7 × 5\n  at_bat_number pitch_number bat_score description   post_bat_score\n          &lt;int&gt;        &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1            61            1         1 ball                       1\n2            61            2         1 ball                       1\n3            61            3         1 ball                       1\n4            61            4         1 ball                       1\n5            62            1         1 foul                       1\n6            62            2         1 hit_into_play              2\n7            63            1         2 hit_into_play              3\n\n\nBased on the description column, we see that the first pitch of at-bat 62 was a foul ball and the second pitch was hit into play. When we look at the corresponding row (row 6) of the table, we see that that Dodgers’ pre-pitch score was 1 (bar_score = 1) and that they scored 1 run as a result of the hit (post_bat_score = 2). Reassuringly, the difference between the value of post_bat_score in row 6 (the last row for at-bat 62) and the value of bat_score in row 5 (the first row for at-bat 62) is 1. We can similarly verify our procedure works in at-bat 61: the fourth value of post_bat_score and the first value of bat_score are equal and the Dodgers did not score in this at-bat.\nWe can apply our procedure to the entirety of the Dodgers’ half-inning\n\ndodgers_inning &lt;-\n  dodgers_inning %&gt;%\n  group_by(at_bat_number) %&gt;%\n  arrange(pitch_number) %&gt;%\n  mutate(RunsScored = last(post_bat_score) - first(bat_score)) %&gt;%\n  ungroup()\n\nWe can now apply this formula to all pitches in statcast2024 by grouping by game_pk and at_bat_number\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  group_by(game_pk, at_bat_number) %&gt;%\n  arrange(pitch_number) %&gt;%\n  mutate(RunsScored = last(post_bat_score) - first(bat_score)) %&gt;%\n  ungroup()\n\n\n\nComputing the starting and ending states\nExcept for the very last pitch in a team’s innings, the ending state of that pitch is, by definition, the starting state of the next pitch. In order to compute \\(\\rho(\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}),\\) and \\(\\rho(\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\\) for each at-bat, we will first create a columns in statcast2024 that encode the game state at the beginning and end of the at-bat.\nTo build up our code, let’s continue with our running example of the Dodgers’ 8th inning, focusing on the at the second through fourth at-bats of the inning.\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 60:62) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner)\n\n# A tibble: 9 × 4\n  at_bat_number pitch_number  Outs BaseRunner\n          &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;chr&gt;     \n1            60            1     0 100       \n2            60            2     0 100       \n3            60            3     0 100       \n4            61            1     0 110       \n5            61            2     0 110       \n6            61            3     0 110       \n7            61            4     0 110       \n8            62            1     0 111       \n9            62            2     0 111       \n\n\nWe start by creating new columns recording the Outs and BaseRunner values of the next pitch using the lead function. 4.\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 60:62) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner) %&gt;%\n  mutate(next_Outs = lead(Outs),\n         next_BaseRunner = lead(BaseRunner))\n\n# A tibble: 9 × 6\n  at_bat_number pitch_number  Outs BaseRunner next_Outs next_BaseRunner\n          &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;          \n1            60            1     0 100                0 100            \n2            60            2     0 100                0 100            \n3            60            3     0 100                0 110            \n4            61            1     0 110                0 110            \n5            61            2     0 110                0 110            \n6            61            3     0 110                0 110            \n7            61            4     0 110                0 111            \n8            62            1     0 111                0 111            \n9            62            2     0 111               NA &lt;NA&gt;           \n\n\nNow, within each at-bat, we can look at the last values of next_Outs and next_BaseRunner to figure out the ending state of the at-bat.\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 60:62) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner) %&gt;%\n  mutate(next_Outs = lead(Outs),\n         next_BaseRunner = lead(BaseRunner)) %&gt;%\n  group_by(at_bat_number) %&gt;%\n  mutate(endOuts = last(next_Outs),\n         endBaseRunner = last(next_BaseRunner)) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner, endOuts, endBaseRunner) %&gt;%\n  ungroup()\n\n# A tibble: 9 × 6\n  at_bat_number pitch_number  Outs BaseRunner endOuts endBaseRunner\n          &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;        \n1            60            1     0 100              0 110          \n2            60            2     0 100              0 110          \n3            60            3     0 100              0 110          \n4            61            1     0 110              0 111          \n5            61            2     0 110              0 111          \n6            61            3     0 110              0 111          \n7            61            4     0 110              0 111          \n8            62            1     0 111             NA &lt;NA&gt;         \n9            62            2     0 111             NA &lt;NA&gt;         \n\n\nIn Lecture 4 and Lecture 5, we will work not only with the game-state (i.e., the values of Outs and BaseRunner) at the end of every at-bat but also with the actual identities of the base-runners and the location where a ball-in-play was fielded (if the batter hit the ball) at the end of every at-bat. We can following an essentially identical strategy of (i) sorting pitches by at-bat and pitch numbers; (ii) computing the leading value of several columns within each half-inning; (iii) grouping by at-bat number; and (iv) taking the lats of those leading values.\nThe code below performs this calculation and also pulls out the rows corresponding to just the first pitch of every at-bat.\n\natbat2024 &lt;-\n  statcast2024 %&gt;%\n  group_by(game_pk, inning, inning_topbot) %&gt;% # divide into half-innings\n  arrange(at_bat_number, pitch_number) %&gt;%\n  mutate(next_Outs = lead(Outs),\n         next_BaseRunner = lead(BaseRunner),\n         next_on_1b = lead(on_1b),\n         next_on_2b = lead(on_2b),\n         next_on_3b = lead(on_3b),\n         next_hc_x = lead(hc_x),\n         next_hc_y = lead(hc_y),\n         next_hit_location = lead(hit_location)) %&gt;%\n  ungroup() %&gt;%\n  group_by(game_pk, at_bat_number) %&gt;%\n  arrange(pitch_number) %&gt;%\n  mutate(end_Outs = last(next_Outs),\n         end_BaseRunner = last(next_BaseRunner),\n         end_on_1b = last(next_on_1b),\n         end_on_2b = last(next_on_2b),\n         end_on_3b = last(next_on_3b),\n         end_hc_x = last(next_hc_x),\n         end_hc_y = last(next_hc_y),\n         end_hit_location = last(next_hit_location)) %&gt;%\n  ungroup() %&gt;%\n  filter(pitch_number == 1) %&gt;%\n  mutate(end_bat_score = bat_score + RunsScored, end_fld_score = fld_score) %&gt;%\n  select(game_pk, at_bat_number,inning, inning_topbot, \n         batter, pitcher, \n         fielder_2, fielder_3, fielder_4, fielder_5, fielder_6, fielder_7, fielder_8,\n          Outs, BaseRunner, on_1b, on_2b, on_3b, \n         bat_score, fld_score, \n         RunsScored, RunsRemaining,\n         end_Outs, end_BaseRunner, end_on_1b, end_on_2b, end_on_3b,\n         end_hc_x, end_hc_y, end_hit_location) %&gt;%\n  arrange(game_pk, at_bat_number)\n\n\n\nComputing run-values\nNow that we have a table atbat2024 containing information about the starting and ending states of each at-bat, we are ready to compute run-values. In particular, we can use a join (just like we did with XG in Lecture 2) to add in the values of the starting and ending expected runs.\nBefore doing that, though, we need to deal with the NA’s introduced by lead(). Looking at the at-bats from the Dodger’s 8th inning from our running example, we see that those NA’s correspond to the very last at-bat of the half-inning.\nBefore doing that, though, let’s take a quick look at the rows in the table corresponding to the Dodgers’ 8th inning from our running example\n\natbat2024 %&gt;%\n  filter(game_pk == 745444 & inning == 8 & inning_topbot == \"Top\") %&gt;%\n  select(at_bat_number, Outs, BaseRunner, end_Outs, end_BaseRunner)\n\n# A tibble: 8 × 5\n  at_bat_number  Outs BaseRunner end_Outs end_BaseRunner\n          &lt;int&gt; &lt;int&gt; &lt;chr&gt;         &lt;int&gt; &lt;chr&gt;         \n1            59     0 000               0 100           \n2            60     0 100               0 110           \n3            61     0 110               0 111           \n4            62     0 111               1 110           \n5            63     1 110               1 110           \n6            64     1 110               1 110           \n7            65     1 110               1 110           \n8            66     1 110              NA &lt;NA&gt;          \n\n\nBecause the “end of the inning” state is not one of the 24 combinations of outs and baserunner configurations in the expected_runs table, we’re going to row to that table with Outs=3, BaseRunners='000', and rho = 0 (since the team cannot score any more runs in the inning once it is over!).\n\nexpected_runs &lt;-\n  expected_runs %&gt;%\n  add_row(Outs=3, BaseRunner=\"000\", rho = 0)\n\natbat2024 &lt;-\n  atbat2024 %&gt;%\n  mutate(end_Outs = ifelse(is.na(end_Outs), 3, end_Outs),\n         end_BaseRunner = ifelse(is.na(end_BaseRunner), '000', end_BaseRunner))\n\nWe’re now ready to use a join to append the starting and ending expected runs.\n\nend_expected_runs &lt;- \n  expected_runs %&gt;%\n  rename(end_Outs = Outs,\n         end_BaseRunner = BaseRunner,\n         end_rho = rho)\n\natbat2024 &lt;-\n  atbat2024 %&gt;%\n  left_join(y = expected_runs, by = c(\"Outs\", \"BaseRunner\")) %&gt;%\n  left_join(y = end_expected_runs, by = c(\"end_Outs\", \"end_BaseRunner\"))\nrm(end_expected_runs)\n\nWe can now finally compute run values\n\natbat2024 &lt;-\n  atbat2024 %&gt;%\n  mutate(RunValue = RunsScored + end_rho - rho)\n\nWe can use the lead() function to take the next starting state and ending state of at-bat a is the starting state of at-bat a+1 If we arrange the at-bats in increasing order of at-bat, then we want to copy over the starting state from row (a+1) into new columns of (a) for the ending state. We can do this using the\nOnce we have those, .\nTo do this, it will be useful to introduce one more game state, which corresponds to the end of a half-inning.",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#aggregate-run-value-leaders",
    "href": "lectures/lecture3.html#aggregate-run-value-leaders",
    "title": "Lecture 3: Estimating the Expected Value of a Game State",
    "section": "Aggregate run value leaders",
    "text": "Aggregate run value leaders\nNow that we have the run values for every at-bat, we can compute the total run value produced by every batter across the season.\n\nre24 &lt;- \n  atbat2024 %&gt;%\n  group_by(batter) %&gt;%\n  summarise(RE24 = sum(RunValue),\n            N = n()) %&gt;%\n  rename(key_mlbam = batter) %&gt;%\n  inner_join(y = player_lookup) %&gt;%\n  select(Name, RE24, N) %&gt;%\n  arrange(desc(RE24))\n\nre24\n\n# A tibble: 649 × 3\n   Name               RE24     N\n   &lt;chr&gt;             &lt;dbl&gt; &lt;int&gt;\n 1 Aaron Judge        87.1   675\n 2 Juan Soto          71.9   693\n 3 Shohei Ohtani      71.9   708\n 4 Bobby Witt         64.4   694\n 5 Brent Rooker       46.6   599\n 6 Vladimir Guerrero  41.8   671\n 7 Kyle Schwarber     38.5   672\n 8 Ketel Marte        38.4   562\n 9 Joc Pederson       36.9   433\n10 José Ramírez       36.0   657\n# ℹ 639 more rows\n\n\nWhen we compare our top-10 to FanGraph’s leaderboard for RE24, we see a lot of overlap. But there are some differences, especially with regards to the number of plate appearances and actual RE24 values. For the latter, FanGraph likely used a different expected run matrix. And the StatCast data is not complete; for instance, it is missing 3 games in which Judge played.",
    "crumbs": [
      "Lecture 3: Estimating the Expected Value of a Game State"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#footnotes",
    "href": "lectures/lecture3.html#footnotes",
    "title": "Actual and Expected Performance",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee this StackOverflow post and the documentation for summarise for details.↩︎\nIndeed, it seems absurd to claim that, at least in women’s international soccer, players will never score off left-footed lobs! As the statistician Dennis Lindley put it we must “never believe in anything absolutely” and should “leave a little probability for the moon being made of green cheese; it can be as small as 1 in a million, but have it there since otherwise an army of astronauts returning with samples of the said cheese will leave you unmoved” ( source). Lindley termed this principle “Cromwell’s Rule”, a reference to a Oliver Cromwell’s famous quote “I beesech you, in the bowels of Christ, think it possible that you may be mistaken.”↩︎",
    "crumbs": [
      "Actual and Expected Performance"
    ]
  },
  {
    "objectID": "lectures/lecture6.html#parametric-statistical-models",
    "href": "lectures/lecture6.html#parametric-statistical-models",
    "title": "Flexible Regression Methods",
    "section": "Parametric Statistical Models",
    "text": "Parametric Statistical Models\n\nLinear Regression\n\n\n\nLogistic Regression\n\n\n\nGeneralized Additive Models",
    "crumbs": [
      "Flexible Regression Methods"
    ]
  },
  {
    "objectID": "lectures/lecture6.html#nonparametric-metrics",
    "href": "lectures/lecture6.html#nonparametric-metrics",
    "title": "Flexible Regression Methods",
    "section": "Nonparametric Metrics",
    "text": "Nonparametric Metrics\n\nRegression Trees\n\n\nRandom Forests\n\n\nXGBoost",
    "crumbs": [
      "Flexible Regression Methods"
    ]
  },
  {
    "objectID": "lectures/lecture1.html#motivation-the-best-shooting-season-in-the-nba",
    "href": "lectures/lecture1.html#motivation-the-best-shooting-season-in-the-nba",
    "title": "Lecture 1: Boxscore Metrics",
    "section": "",
    "text": "Who is the best shooter in the NBA? How do we determine this using data? \nIn this lecture, we will practice using functions from the tidyverse suite of packages (especially dplyr) to manipulate tables of NBA box score data. Hopefully, much of the functionality we encounter in this lecture will be familiar to you. But, if you need a high-level refresher, I highly recommend the following resources:\n\nChapter 3 and Chapter 5 of R for Data Science.\nSection 1.9 and Chapter 3 of *Data Science: A First Introduction.\n\nWe will use the package hoopR to scrape NBA boxscore data. You should install the package using the code install.packages(\"hoopR\").",
    "crumbs": [
      "Lecture 1: Boxscore Metrics"
    ]
  },
  {
    "objectID": "lectures/lecture1.html#from-totals-to-percentages",
    "href": "lectures/lecture1.html#from-totals-to-percentages",
    "title": "Lecture 1: Boxscore Metrics",
    "section": "From totals to percentages",
    "text": "From totals to percentages\nIn order to determine which player-season was the best in terms of shooting, we need to first define “best”. Perhaps the simplest definition is to find the player-season with the most made shots. We can identify this player-season by sorting the data in season_box by FGM in descending order with the arrange() function\n\nseason_box %&gt;%\n  arrange(desc(FGM))\n\n# A tibble: 11,766 × 10\n   Player            season   FGM   FGA   TPM   TPA   FTM   FTA minutes n_games\n   &lt;chr&gt;              &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;int&gt;\n 1 Kevin Durant        2010   756  1668   128   351   756   840    3241      82\n 2 James Harden        2019   754  1922   382  1041   754   858    2896      79\n 3 James Harden        2017   746  1542   266   765   746   881    2985      82\n 4 James Harden        2016   720  1631   243   669   720   837    3142      83\n 5 James Harden        2015   715  1486   215   567   715   824    3006      82\n 6 Russell Westbrook   2017   712  1967   207   596   712   842    2822      82\n 7 Kevin Durant        2014   707  1715   198   508   707   809    3153      82\n 8 James Harden        2020   694  1523   302   852   694   804    2496      69\n 9 Kobe Bryant         2006   675  2109   179   506   675   788    3184      78\n10 James Harden        2013   674  1350   182   494   674   792    3006      79\n# ℹ 11,756 more rows\n\n\nWhen we look at the ten “best” shooting seasons, we immediately recognize a lot of superstar players! On this basis, we might be satisfied evaluating shooting performances based only on the total number of shots. But taking a closer look, should we really consider Kobe Bryant’s 2002-03 and Shai Gilgeous-Alexander’s 2024-25 seasons to be equally impressive when Kobe took attempted 242 more shots than Shai in order to make 868 shots? Arguably, Shai’s 2024-25 season should rank higher than Kobe’s 2002-03 season because Shai was more efficient.\nThis motivates us to refine our definition of “best” by focusing on the percentage of field goals made rather than total number of field goals made.\n\nseason_box &lt;-\n  season_box |&gt;\n1  mutate(FGP = ifelse(FGA &gt; 0, FGM/FGA, NA_real_))\nseason_box |&gt; \n  arrange(desc(FGP)) |&gt;\n  select(Player, season, FGP)\n\n\n1\n\nFor players who attempted no field goals (i.e., FGA = 0), their field goal percentage is undefined.\n\n\n\n\n# A tibble: 11,920 × 3\n   Player           season   FGP\n   &lt;chr&gt;             &lt;int&gt; &lt;dbl&gt;\n 1 Ahmad Caver        2022     1\n 2 Alondes Williams   2025     1\n 3 Andris Biedrins    2014     1\n 4 Anthony Brown      2018     1\n 5 Braxton Key        2023     1\n 6 Chris Silva        2023     1\n 7 Dajuan Wagner      2007     1\n 8 DeAndre Liggins    2014     1\n 9 Donnell Harvey     2005     1\n10 Eddy Curry         2009     1\n# ℹ 11,910 more rows\n\n\nSorting the players by their \\(\\textrm{FGP},\\) we find that several players made 100% of their field goals. But very few of these players are immediately recognizable — and, indeed, none of them have been in the MVP conversation, despite the fact that they made all their shots!\nTo understand what’s going on, let’s take a look at the number of attempts.\n\nseason_box %&gt;% \n  arrange(desc(FGP)) %&gt;%\n  select(Player, season, FGP, FGA)\n\n# A tibble: 11,920 × 4\n   Player           season   FGP   FGA\n   &lt;chr&gt;             &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Ahmad Caver        2022     1     1\n 2 Alondes Williams   2025     1     2\n 3 Andris Biedrins    2014     1     1\n 4 Anthony Brown      2018     1     1\n 5 Braxton Key        2023     1     1\n 6 Chris Silva        2023     1     1\n 7 Dajuan Wagner      2007     1     1\n 8 DeAndre Liggins    2014     1     1\n 9 Donnell Harvey     2005     1     2\n10 Eddy Curry         2009     1     2\n# ℹ 11,910 more rows\n\n\nGiven the very low number of shots attempted in any of these player-season, claiming that any of these player-seasons are among the best ever would strain credulity! So, in order to determine the best shooting performance, we will need to threshold our data to players who took a minimum number of shots. For simplicity, let’s focus our attention on those players who attempted at least 400 field goals in a season (i.e., they attempted, on average, at least 5 shots per game).\n\n\n\nseason_box |&gt;\n  filter(FGA &gt;= 400) |&gt;\n  arrange(desc(FGP)) |&gt;\n  select(Player, season, FGP,FGA)\n\n# A tibble: 4,987 × 4\n   Player         season   FGP   FGA\n   &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Daniel Gafford   2024 0.725   480\n 2 Walker Kessler   2023 0.720   414\n 3 DeAndre Jordan   2017 0.714   577\n 4 Rudy Gobert      2022 0.713   508\n 5 DeAndre Jordan   2015 0.710   534\n 6 Jarrett Allen    2025 0.706   640\n 7 Nic Claxton      2023 0.705   587\n 8 DeAndre Jordan   2016 0.703   508\n 9 Daniel Gafford   2025 0.702   403\n10 Daniel Gafford   2022 0.693   411\n# ℹ 4,977 more rows\n\n\nDo we really believe that these performances, all of which were made centers who mostly shoot at or near the rim, represent some of the best shooting performances of all time?\n\nEffective Field Goal Percentage\nA major limitation of FGP is that it treats 2-point shots the same as 3-point shots. As a result, the league-leader in FGP every season is usually a center whose shots mostly come from near the rim. Effective Field Goal Percentage (eFGP) adjusts FGP to account for the fact that a made 3-point shots is worth 50% more than a made 2-point shot. The formula for eFGP is \\[\n\\textrm{eFGP} = \\frac{\\textrm{FGM} + 0.5 \\times \\textrm{TPM}}{\\textrm{FGA}}\n\\]\n\nseason_box &lt;-\n  season_box |&gt;\n  mutate(\n    TPP = ifelse(TPA &gt; 0, TPM/TPA,NA_real_),\n    eFGP = (FGM + 0.5 * TPM)/FGA) \nseason_box %&gt;%\n  filter(FGA &gt;= 400) %&gt;%\n  arrange(desc(eFGP), desc(FGP)) %&gt;%\n  select(Player, season, eFGP, FGP, TPP, TPA, n_games)\n\n# A tibble: 4,987 × 7\n   Player         season  eFGP   FGP    TPP   TPA n_games\n   &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 Daniel Gafford   2024 0.725 0.725 NA         0      74\n 2 Walker Kessler   2023 0.721 0.720  0.333     3      74\n 3 DeAndre Jordan   2017 0.714 0.714  0         2      81\n 4 Rudy Gobert      2022 0.713 0.713  0         4      66\n 5 DeAndre Jordan   2015 0.711 0.710  0.25      4      82\n 6 Jarrett Allen    2025 0.706 0.706  0         5      82\n 7 Nic Claxton      2023 0.705 0.705  0         2      76\n 8 DeAndre Jordan   2016 0.703 0.703  0         1      77\n 9 Daniel Gafford   2025 0.702 0.702 NA         0      57\n10 Daniel Gafford   2022 0.693 0.693  0         1      72\n# ℹ 4,977 more rows\n\n\nWe see again that some of the best seasons, according to eFGP, were from centers, many of whom attempt few few three point shots. When filter out players who took at least 100 three point shots, we start to see other positions in the top-10.\n\nseason_box %&gt;%\n  filter(FGA &gt;= 400 & TPA &gt;= 100) %&gt;%\n  arrange(desc(eFGP), desc(FGP)) %&gt;%\n  select(Player, season, eFGP, FGP, TPP, TPA, n_games)\n\n# A tibble: 3,658 × 7\n   Player             season  eFGP   FGP   TPP   TPA n_games\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 Kyle Korver          2015 0.671 0.487 0.492   449      75\n 2 Duncan Robinson      2020 0.667 0.470 0.446   606      73\n 3 Obi Toppin           2024 0.660 0.571 0.404   260      83\n 4 Nikola Jokic         2023 0.660 0.632 0.383   149      69\n 5 Joe Harris           2021 0.655 0.502 0.478   427      69\n 6 Joe Ingles           2021 0.652 0.489 0.451   406      67\n 7 Grayson Allen        2024 0.649 0.499 0.461   445      75\n 8 Michael Porter Jr.   2021 0.646 0.541 0.447   374      61\n 9 Mikal Bridges        2021 0.643 0.543 0.425   315      72\n10 Al Horford           2024 0.640 0.511 0.419   258      65\n# ℹ 3,648 more rows\n\n\n\n\nTrue Shooting Percentage\nBoth FGP and eFGP totally ignore free throws. Intuitively, we should expect the best shooter to be proficient at making two-and three-point shots as well as their free throws. One metric that accounts for all field goals, three pointers, and free throws is true shooting percentage (\\(\\textrm{TSP}\\)), whose formula is given by \\[\n\\textrm{TSP} = \\frac{\\textrm{PTS}}{2 \\times \\left(\\textrm{FGA} + (0.44 \\times \\textrm{FTA})\\right)},\n\\] where \\(\\textrm{PTS} =  \\textrm{FTM} + 2 \\times \\textrm{FGM} + \\textrm{TPM}\\) is the total number of points scored.\n\nseason_box &lt;-\n  season_box |&gt;\n  mutate(PTS = FTM + 2 * FGM + TPM,\n         TSP = PTS/(2 * (FGA + 0.44 * FTA)))\nseason_box %&gt;%\n  filter(FGA &gt;= 400 & TPA &gt;= 100) %&gt;%\n  arrange(desc(TSP), desc(eFGP), desc(FGP)) %&gt;%\n  select(Player, season, TSP, eFGP, FGP, TPP, n_games)\n\n# A tibble: 3,658 × 7\n   Player          season   TSP  eFGP   FGP   TPP n_games\n   &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 Nikola Jokic      2023 0.701 0.660 0.632 0.383      69\n 2 Kyle Korver       2015 0.699 0.671 0.487 0.492      75\n 3 Austin Reaves     2023 0.687 0.616 0.529 0.398      64\n 4 Duncan Robinson   2020 0.684 0.667 0.470 0.446      73\n 5 Dwight Powell     2019 0.682 0.637 0.597 0.307      77\n 6 Grayson Allen     2024 0.679 0.649 0.499 0.461      75\n 7 Kevin Durant      2023 0.677 0.614 0.560 0.404      47\n 8 Moritz Wagner     2024 0.676 0.636 0.601 0.330      80\n 9 Stephen Curry     2018 0.675 0.618 0.495 0.423      51\n10 Obi Toppin        2024 0.675 0.660 0.571 0.404      83\n# ℹ 3,648 more rows",
    "crumbs": [
      "Lecture 1: Boxscore Metrics"
    ]
  },
  {
    "objectID": "lectures/lecture1.html#recap-and-a-look-ahead",
    "href": "lectures/lecture1.html#recap-and-a-look-ahead",
    "title": "Lecture 1: Boxscore Metrics",
    "section": "Recap and a look ahead",
    "text": "Recap and a look ahead\n\n\nsave(sesason_box, file = \"nba_box_scores.RData\")",
    "crumbs": [
      "Lecture 1: Boxscore Metrics"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#working-with-soccer-event-data",
    "href": "lectures/lecture3.html#working-with-soccer-event-data",
    "title": "Actual and Expected Performance",
    "section": "Working with soccer event data",
    "text": "Working with soccer event data\nWe will make use of high-resolution tracking data provided by the company Huddle StatsBomb. As a bit of background, StatsBomb extracts player locations using  To their great credit, StatsBomb releases a small snapshot of their data for public use. We can access this data directly in R using the StatsBombR package.\nYou can check if the package is installed using the code \"StatsBombR\" %in% rownames(installed.packages()). If that code returns FALSE, then you can install the package using the code devtools::install_github(\"statsbomb/StatsBombR\").\n\nlibrary(tidyverse)\n# save a nice color-blind friednly color palette into our environment\noi_colors &lt;- palette.colors(palette = \"Okabe-Ito\") \n\nStatsBomb organizes its free data by competition/tournament. The screenshot below shows a table of all the available competitions. We can load this table into our R environment using the function StatsBombR::FreeCompetitions()  Each competition and season have unique id and we can also see whether it was a men’s or women’s competition. To see which matches from selected competitions have publicy available data, we can pass the corresponding rows of this table to the function StatsBombR::FreeMatches(). Figure 2 shows the table of matches from the 2022 EURO Competition; StatsBomb graciously provided data for all matches from the tournament, which can be obtained using the code below.\n\nStatsBombR::FreeCompetitions() %&gt;%\n  filter(competition_id == 53 & season_id == 106) %&gt;% # Finds competition corresponding to EURO 2022\n  StatsBombR::FreeMatches() \n\nFinally, to get raw-event level data for certain matches, we need to pass the corresponding rows to the function StatsBombR::free_allevents(). StatsBomb also recommends running some basic pre-processing, all of which is nicely packaged together in the functions StatsBombR::allclean() and StatsBombR::get.opposingteam().\nAs an example, the code chunk below pulls out publicly available event data for every women’s international match.\n\nwi_events &lt;-\n  StatsBombR::FreeCompetitions() %&gt;% # get table of available competitions\n  filter(competition_gender == \"female\" & \n           competition_international) %&gt;% # filter to women's internationals\n  StatsBombR::FreeMatches() %&gt;% # Gets match data for all women's internationals\n  StatsBombR::free_allevents() %&gt;% # Gets all events for all matches\n  StatsBombR::allclean() %&gt;% # Apply StatsBomb's pre-processing\n  StatsBombR::get.opposingteam()\n\n\n\n\n\n\n\nNavigating complex code\n\n\n\nIt is not easy to code complicated pipelines like the above in a single attempt. In fact, I had to build the code line-by-line. For instance, I initially ran just the first line and manually inspected the table of free competitions (using View()) to figure out which variables I needed to filter() on in the second line. It is very helpful to develop pipelines incrementally and to check intermediate results before putting everything together in one block of code.",
    "crumbs": [
      "Actual and Expected Performance"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#an-initial-expected-goals-model",
    "href": "lectures/lecture3.html#an-initial-expected-goals-model",
    "title": "Actual and Expected Performance",
    "section": "An initial expected goals model",
    "text": "An initial expected goals model\nSuppose we observe a dataset consisting of \\(n\\) shots. For each shot \\(i = 1, \\ldots, n,\\) let \\(Y_{i}\\) be a binary indicator of whether the shot resulted in a goal (\\(Y_{i} = 1\\)) or not (\\(Y_{i} = 0\\)). From the high-resolution tracking data, we can extract a potentially huge number of features about the shot at the moment of it was taken. Possible features include, but are certainly not limited to, the player taking the shot, the body part and side of the body used, the positions of the defenders and goal keepers, and contextual information like the score. Mathematically, we can collect all these features into a (potentially large) vector \\(\\boldsymbol{\\mathbf{X}}_{i}.\\)\nExpected goals (XG) models work by (i) positing an infinite super-population of shots represented by pairs \\((\\boldsymbol{\\mathbf{X}}, Y)\\) of feature vector \\(\\boldsymbol{\\mathbf{X}}\\) and binary outcome \\(Y\\); and (ii) assuming that the shots in our dataset constitute a random sample \\((\\boldsymbol{\\mathbf{X}}_{1}, Y_{1}), \\ldots, (\\boldsymbol{\\mathbf{X}}_{n}, Y_{n})\\) from that population.\n\n\n\n\n\n\nConditional Expectations\n\n\n\nFor each combination of features \\(\\boldsymbol{\\mathbf{x}}\\), the expect goals given \\(\\boldsymbol{\\mathbf{x}},\\) which we will denote by \\(\\textrm{XG}(\\boldsymbol{\\mathbf{X}})\\) is just the average value of \\(Y\\) among the (assumed infinite) sub-population of shots with features \\(\\boldsymbol{\\mathbf{X}} = \\boldsymbol{\\mathbf{x}}.\\) Mathematically, XG is conditional expectation: \\[\n\\textrm{XG}(\\boldsymbol{\\mathbf{x}}) = \\mathbb{E}[Y \\vert \\boldsymbol{\\mathbf{X}} = \\boldsymbol{\\mathbf{x}}],\n\\]\n\n\nBecause the shot outcome \\(Y\\) is binary, \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) is the proportion of goals scored within the sub-population of shots defined by the feature combinations \\(\\boldsymbol{\\mathbf{x}}.\\) In other words, it is the conditional probability of a goal given the shot features \\(\\boldsymbol{\\mathbf{x}}.\\) On this view, \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) provides a quantitative answer to our motivating question “If we were to replay a particular shot over and over again, what fraction of the time does it result in a goal?”\nThe StatsBomb variable shot.body_part.name records the body part with which each shot was taken. Within our dataset of women’s international matches, we can see the breakdown of these body parts\n\ntable(wi_events$shot.body_part.name)\n\n\n      Head  Left Foot      Other Right Foot \n       769       1024         23       2059 \n\n\nFor this analysis, we will focus on fitting XG models using data from shots taken with a player’s feet or head.\n\nwi_shots &lt;-\n  wi_events %&gt;% # Adds opposing team information\n  filter(type.name == \"Shot\" & shot.body_part.name != \"Other\") %&gt;%  # Subsets only shot event data\n  mutate(Y = ifelse(shot.outcome.name == \"Goal\", 1, 0))\n\nLater, it will be useful for us to focus only on the shots from EURO2022, so we will also create a table euro2022_shots of all shots from that competition using similar code.\n\n\nCode\neuro2022_shots &lt;-\n  StatsBombR::FreeCompetitions() %&gt;% # get table of available competitions\n  filter(competition_id == 53 & season_id == 106) %&gt;% # Finds competition corresponding to EURO 2022\n  StatsBombR::FreeMatches() %&gt;% # Gets match data for all EURO 2022\n  StatsBombR::free_allevents() %&gt;% # Gets all events for all matches\n  StatsBombR::allclean() %&gt;% # Apply StatsBomb's pre-processing\n  StatsBombR::get.opposingteam() %&gt;%\n  filter(type.name == \"Shot\" & shot.body_part.name != \"Other\") %&gt;%\n  mutate(Y = ifelse(shot.outcome.name == \"Goal\", 1, 0))\n\n\nNow suppose we only include the body part in \\(\\boldsymbol{\\mathbf{X}}\\). If we had full access to the infinite super-population of women’s international shots, then we could compute \\[\\textrm{XG}(\\text{right-footed shot}) = \\mathbb{P}(\\text{goal} \\vert \\text{right-footed shot})\\] by (i) forming a sub-group containing only those right-footed shots and then (ii) calculating the proportion of goals scored within that sub-group. We could similarly compute \\(\\textrm{XG}(\\text{left-footed shot})\\) and \\(\\textrm{XG}(\\text{header})\\) by calcuating the proportion of goals scored within the sub-groups containing, resptively, only left-footed shots and only headers.\nOf course, we don’t have access to the infinite super-population of shots. However, on the assumption that our observed data constitute a sample from that super-population, we can estimate \\(\\textrm{XG}\\) by mimicking the idealized calculations described above:\n\nBreak the dataset of all observed shots in women’s international matches into several groups based on the body part\nWithin these two groups, compute the proportion of goals\n\nTo keep things simple, we dropped the 23 shots that were taken with a body part other than the feet or the head.\n\nxg_model1 &lt;-\n  wi_shots %&gt;%\n  group_by(shot.body_part.name) %&gt;%\n  summarize(XG1 = mean(Y),\n            n = n())\nxg_model1\n\n# A tibble: 3 × 3\n  shot.body_part.name   XG1     n\n  &lt;chr&gt;               &lt;dbl&gt; &lt;int&gt;\n1 Head                0.112   769\n2 Left Foot           0.113  1024\n3 Right Foot          0.102  2059\n\n\n\n\n\n\n\n\nGeneralizing our model results\n\n\n\nA key assumption of all XG models is that the observed data is a random sample drawn from the super-population. The only women’s internationals matches for which StatsBomb data were from the 2019 and 2023 World Cup and the 2022 EURO tournaments. These matches are arguably not highly representative of all women’s international matches, meaning that we should exercise some caution when using models fitted to these data to analyze matches from other competitions (e.g., an international friendly or a match in a domestic league).\n\n\n\nAccounting for additional features\nWe can now create a table of just Beth Mead’s shots from EURO 2022 and add a column with the XG for each shot. To do this, we first filter our table wi_shots using the player name (note, StatsBomb uses her full name!). Then, for every left-footed shot Mead attempted, we want to copy over the corresponding value from the table xg_model1, which in this cse is 0.113. Similarly, we want to copy over the corresponding values for right-footed shots and headers from xg_model1 into our table for Mead’s shots. We can do this using an left join. In the code below, we actually create a temporary version of xg_model1 that drops the column recording the overall counts of the body part used for the shots in wi_shots. This way, when we perform the join, we don’t create a new column with these counts.\n\ntmp_xg1 &lt;- xg_model1 %&gt;% select(!n) # temporary copy of the table without sample size column\n\nmead_shots &lt;-\n  euro2022_shots %&gt;%\n  filter(player.name == \"Bethany Mead\") %&gt;%\n  left_join(y = tmp_xg1, by = c(\"shot.body_part.name\"))\nrm(tmp_xg1) # delete temporary copy\n\nWe can now look at the what our model says about the three goals from above. The first, against Austria in the 15th minute; the second, against Norway in the 37th minute, and the third against Sweden in the 33rd minute When These turn out to be in rows 1, 4, and 14 of the table mead_shots\n\nmead_shots %&gt;%\n  select(OpposingTeam, minute, shot.body_part.name, Y, XG1) %&gt;%\n  slice(c(1, 4, 14))\n\n# A tibble: 3 × 5\n  OpposingTeam    minute shot.body_part.name     Y   XG1\n  &lt;chr&gt;            &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 Austria Women's     15 Right Foot              1 0.102\n2 Norway Women's      37 Left Foot               1 0.113\n3 Sweden Women's      33 Right Foot              1 0.102\n\n\nAccording to our first model, these three goals appear equally impressive: our model put the respective chances of each shot resulting in a goal at about 10%, 11%, and 10%. But, watching the videos a bit more closely, this conclusions is not especially satisfying: Mead scored the first goal in a one-on-one situation but had to shoot through several defenders on the second and third goal The discrepancy between our qualitative comparisons and our quantitative modeling results stems from the fact that we only conditioned on the body part and did not account for the other ways that the shots are different. In other words, our initial XG model is much too coarse to quantify the differences between the three chances that we believe are important.\nTo better compare the three goals, we need to build a a finer XG model that conditions on more features, including ones that differ between the two shots. To this end, notice that Mead uses a different technique on the three shots: she lobs the ball into the net on the first goal, shoots the ball from the ground on the second goal, and scores the third goal off of a half volley, striking the ball as it bounced up off the ground. The StatsBomb variable shot.technique.name records the technique of each shot type\n\ntable(wi_shots$shot.technique.name)\n\n\n     Backheel Diving Header   Half Volley           Lob        Normal \n           25            10           529            15          3015 \nOverhead Kick        Volley \n           14           244 \n\n\nBy conditioning on both body part and technique, we can begin to build a more refined XG model. The code to do this is almost identical to the code used in our first model. The only difference is that we now group by two variables shot.body_part.name and shot.technique_name. Because we are grouping by two variables, specify the argument .groups=\"drop\" argument when calling summarize; this prevents a (mostly innocuous) warning message1. We additionally append our new XG estimates to the table containing all of Mead’s shots.\n\nxg_model2 &lt;-\n  wi_shots %&gt;%\n  group_by(shot.body_part.name, shot.technique.name) %&gt;%\n  summarize(XG2 = mean(Y),\n            n = n(), .groups = \"drop\")\n\ntmp_xg2 &lt;- xg_model2 %&gt;% select(-n)\nmead_shots &lt;-\n  mead_shots %&gt;%\n  inner_join(y = xg_model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))\nrm(tmp_xg2)\n\nmead_shots %&gt;%\n  select(OpposingTeam, minute, shot.body_part.name, shot.technique.name, Y, XG2) %&gt;%\n  slice(c(1, 4, 14))\n\n# A tibble: 3 × 6\n  OpposingTeam    minute shot.body_part.name shot.technique.name     Y    XG2\n  &lt;chr&gt;            &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt;\n1 Austria Women's     15 Right Foot          Lob                     1 0.333 \n2 Norway Women's      37 Left Foot           Normal                  1 0.121 \n3 Sweden Women's      33 Right Foot          Half Volley             1 0.0801",
    "crumbs": [
      "Actual and Expected Performance"
    ]
  },
  {
    "objectID": "lectures/lecture3.html#conditioning-on-even-more-features",
    "href": "lectures/lecture3.html#conditioning-on-even-more-features",
    "title": "Actual and Expected Performance",
    "section": "Conditioning on even more features",
    "text": "Conditioning on even more features\nAt least for these three goals, our new XG estimates seem more reasonable: the one-on-one lob against Austria has a much higher XG than the shots through traffic against Norway and Sweden. But are we fully satisfied with this model? One could credibly argue that even though our model returns somewhat more sensible XG estimates, it is still too coarse for to meaningfully compare the shots above. After all, because it does not condition on distance, our model would return exactly the same XG for right-footed volleys taken one meter and 15 meters away from the goal. Similarly, we could try to account for the number of defenders between the shot and the goal and the position of the keeper.\nIf we had access to the infinite super-population of shots, conditioning on more features is conceptually straightforward: we look at the corresponding sub-group of the super-population defined by a particular combination of features and compute the average \\(Y.\\) Unfortunately, with finite data, trying to “bin-and-average” using lots of features can lead to erratic estimates. For instance, here are the five largest and five smallest XG estimates based on body-part and shot technique.\n\nxg_model2 %&gt;% arrange(desc(XG2)) %&gt;% filter(row_number() %in% c(1:5, (n()-4):n()))\n\n# A tibble: 10 × 4\n   shot.body_part.name shot.technique.name    XG2     n\n   &lt;chr&gt;               &lt;chr&gt;                &lt;dbl&gt; &lt;int&gt;\n 1 Right Foot          Lob                 0.333     12\n 2 Left Foot           Volley              0.162     74\n 3 Right Foot          Backheel            0.136     22\n 4 Left Foot           Normal              0.121    750\n 5 Head                Normal              0.113    759\n 6 Right Foot          Volley              0.0412   170\n 7 Head                Diving Header       0         10\n 8 Left Foot           Backheel            0          3\n 9 Left Foot           Lob                 0          3\n10 Left Foot           Overhead Kick       0          2\n\n\nBecause none of the 3 left-footed lobs in our dataset led to goals, our model estimates \\(\\textrm{XG}(\\text{left-footed lob})\\) as 0. Similarly, the rather large \\(\\textrm{XG}(\\text{right-footed lob})\\) estimate of around 33% is based on only 12 shots. Attempting to condition on even more variables would result in estimates based on even smaller sample sizes!\nSo, it would appear that we’re stuck between a rock and a hard place. On the one hand, our XG model with two features is too coarse to quantify important differences between the motivating shots. But on the other hand, binning and averaging with even more features carries the risk of producing highly erratic, extreme, and somewhat nonsensical estimates2 To overcome this challenge, we can build a statistical model.\nLater in the course, we will discuss how to estimate more granular XG models with loads more features. But for today, we’ll use XG estimates from StatsBomb LLC (Huddl?). Although this is a proprietary model, StatsBomb has published a lot of information about what all goes into it. In addition to the body part and technique, they also construct several features based on location of the players (in 2 dimensions) and the ball (in 3 dimensions).\n\n\nmead_shots %&gt;%\n  filter(Y == 1) %&gt;%\n  select(OpposingTeam, minute, shot.body_part.name, shot.technique.name, Y, shot.statsbomb_xg)\n\n# A tibble: 6 × 6\n  OpposingTeam     minute shot.body_part.name shot.technique.name     Y\n  &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;               &lt;dbl&gt;\n1 Austria Women's      15 Right Foot          Lob                     1\n2 Norway Women's       33 Head                Normal                  1\n3 Norway Women's       37 Left Foot           Normal                  1\n4 Norway Women's       80 Left Foot           Volley                  1\n5 Northern Ireland     43 Left Foot           Normal                  1\n6 Sweden Women's       33 Right Foot          Half Volley             1\n# ℹ 1 more variable: shot.statsbomb_xg &lt;dbl&gt;\n\n\nRecall that XG quantifies a certain hypothetical long-term frequency of scoring a goal: if the shot was replayed under exactly the conditions quantified by the feature vector \\(\\boldsymbol{\\mathbf{x}}\\), \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) is the proportion of times a goal is scored. So, we should be fairly impressed when a player scores a goal on a shot with very low XG. We can quantify the degree to which players under- or over-perform the model expectations by comparing the In the case of Beth Mead, we want to sum the difference \\(Y_{i} = \\textrm{XG}_{i}\\) where \\(\\textrm{XG}_{i}\\) is the StatsBomb XG estimate.\n\nsum(mead_shots$Y - mead_shots$shot.statsbomb_xg)\n\n[1] 2.896323\n\n\nDuring Euro 2022, Beth Mead scored a total of 6 goals, which was about 2.9 goals more than what the StatsBomb XG model expected, based on the contexts in which she attempted shots. We can repeat this calculation – summing over the difference between shot outcome \\(Y\\) and \\(\\textrm{XG}\\) — for all players in EURO 2022 to find the players that most over-performed and most under-performed the model expectations.\n\ngoe &lt;- \n  euro2022_shots %&gt;%\n  mutate(diff = Y - shot.statsbomb_xg) %&gt;%\n  group_by(player.name) %&gt;%\n  summarise(GOE = sum(diff),\n            n = n()) %&gt;%\n  arrange(desc(GOE))\n\ngoe\n\n# A tibble: 200 × 3\n   player.name               GOE     n\n   &lt;chr&gt;                   &lt;dbl&gt; &lt;int&gt;\n 1 Alexandra Popp          3.34     16\n 2 Bethany Mead            2.90     15\n 3 Alessia Russo           1.79     12\n 4 Francesca Kirby         1.79      5\n 5 Lina Magull             1.70     14\n 6 Ingrid Filippa Angeldal 1.37     10\n 7 Romée Leuchter          1.19      2\n 8 Hanna Ulrika Bennison   0.952     1\n 9 Nicole Anyomi           0.896     1\n10 Julie Blakstad          0.879     1\n# ℹ 190 more rows\n\n\nIt turns out that Alexandra Popp, the German captain, outperformed StatsBomb’s XG model expectations, by an even wider margin than Beth Mead. Like Mead, Popp scored 6 goals during the tournament off a similar number of shots (16 for Popp and 15 for Mead). Interestingly, Mead won the Golden Boot because she had one more assist…",
    "crumbs": [
      "Actual and Expected Performance"
    ]
  },
  {
    "objectID": "lectures/lecture5.html",
    "href": "lectures/lecture5.html",
    "title": "Lecture 5: Run values in baseball",
    "section": "",
    "text": "Over the next several lectures, we will work with pitch-tracking data from Major League Baseball, with the ultimate goal of allocating credit or blame to players based at a play-by-play level and to quantify the value of each player provides his team.\nBut before doing any of that, let’s consider two hypothetical scenarios in which a batter comes up to the plate when there are (i) 2 outs and no runners on base and when there are (ii) 1 out and runners on first and second. Which scenario do you think will result in more runs for the batting team?\nIntuitively, we might expect the second scenario to lead to more runs; after all, the batting team will score at least one run if the batter gets a hit while there is no guarantee of scoring a run in the first scenario even if the batter gets on base. We can more precisely quantify this intuition using expected runs, which is a key tool used in sabermetrics. The expected runs \\(\\rho(\\textrm{o}, \\textrm{br})\\) is the average number of runs scored in the remainder of the half-inning following at-bats beginning with \\(\\textrm{o}\\) outs and baserunner configuration \\(\\textrm{br}.\\) Like expected goals (XG) from Lecture 2, expected runs is a conditional expectation.\nDuring the March 20, 2024 game between the Dodgers and Padres, Shohei Ohtani actually faced both of the scenarios mentioned above and singled in both at-bats. In the 3rd inning, he hit a 2-out single with no runners and in the 8th inning, he hit a 1-out single with runners on first and second base.\nSince the second single resulted in a run scoring and the first did not, it is tempting to say that the second single is more valuable. However, although the first single did not directly lead to a run, it did put the Dodgers in a more favorable position, with a runner on first1 By the end of this lecture, we will be able to quantify exactly how valuable each of those singles using run values, which combine changes in the number of a team can expect to score and the number of runs actually scored in an at-bat.",
    "crumbs": [
      "Lecture 5: Run values in baseball"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#overview-allocation-of-credit-in-baseball",
    "href": "lectures/lecture5.html#overview-allocation-of-credit-in-baseball",
    "title": "Lecture 5: Run values in baseball",
    "section": "",
    "text": "Over the next several lectures, we will work with pitch-tracking data from Major League Baseball, with the ultimate goal of allocating credit or blame to players based at a play-by-play level and to quantify the value of each player provides his team.\nBut before doing any of that, let’s consider two hypothetical scenarios in which a batter comes up to the plate when there are (i) 2 outs and no runners on base and when there are (ii) 1 out and runners on first and second. Which scenario do you think will result in more runs for the batting team?\nIntuitively, we might expect the second scenario to lead to more runs; after all, the batting team will score at least one run if the batter gets a hit while there is no guarantee of scoring a run in the first scenario even if the batter gets on base. We can more precisely quantify this intuition using expected runs, which is a key tool used in sabermetrics. The expected runs \\(\\rho(\\textrm{o}, \\textrm{br})\\) is the average number of runs scored in the remainder of the half-inning following at-bats beginning with \\(\\textrm{o}\\) outs and baserunner configuration \\(\\textrm{br}.\\) Like expected goals (XG) from Lecture 2, expected runs is a conditional expectation.\nDuring the March 20, 2024 game between the Dodgers and Padres, Shohei Ohtani actually faced both of the scenarios mentioned above and singled in both at-bats. In the 3rd inning, he hit a 2-out single with no runners and in the 8th inning, he hit a 1-out single with runners on first and second base.\nSince the second single resulted in a run scoring and the first did not, it is tempting to say that the second single is more valuable. However, although the first single did not directly lead to a run, it did put the Dodgers in a more favorable position, with a runner on first1 By the end of this lecture, we will be able to quantify exactly how valuable each of those singles using run values, which combine changes in the number of a team can expect to score and the number of runs actually scored in an at-bat.",
    "crumbs": [
      "Lecture 5: Run values in baseball"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#working-with-baseball-tracking-data",
    "href": "lectures/lecture5.html#working-with-baseball-tracking-data",
    "title": "Lecture 5: Run values in baseball",
    "section": "Working with baseball tracking data",
    "text": "Working with baseball tracking data\n\nHistory of tracking data\n\n\n\nAccessing StatCast Data\nMajor League Baseball hosts a public-facing web interface for accessing StatCast data. Using that interface, users can pull up data for individual players or about all pitches of a certain type. Powering this website is an application programming interface (API), which allows software applications to connect to the underlying StatCast database. It is through this API that the baseballR package acquires data. If you have not yet installed that package, you can do so using the code devtools::install_github(repo = \"BillPetti/baseballr\")\nThe baseballR package provides a function baseballr::statcast_search() that allows users query all StatCast data by date, player, or player type. One of the original baseballr authors, Bill Petti, wrote a wrapper function that uses baseballr::statcast_search() to pull down an entire season’s worth of pitch-by-pitch data; see this blog post for more the wrapper function code and this earlier post for details about its design. Since he published his original function, StatCast has added some new fields, necessitating a few changes to the original script. The code below defines a new scraper, which we will use in the course. An R script containing this code is available at this link. At a high level, the scraping function pulls data from StatCast on a week-by-week basis.\n\n\nShow the code\nannual_statcast_query &lt;- function(season) {\n  \n  data_base_column_types &lt;- \n    read_csv(\"https://app.box.com/shared/static/q326nuker938n2nduy81au67s2pf9a3j.csv\")\n  \n  dates &lt;- \n    seq.Date(as.Date(paste0(season, '-03-01')),\n             as.Date(paste0(season, '-12-01')), \n             by = '4 days')\n  \n  date_grid &lt;- \n    tibble::tibble(start_date = dates, \n                   end_date = dates + 3)\n  \n  safe_savant &lt;- \n    purrr::safely(scrape_statcast_savant)\n  \n  payload &lt;- \n    purrr::map(.x = seq_along(date_grid$start_date),\n               ~{message(paste0('\\nScraping week of ', date_grid$start_date[.x], '...\\n'))\n                 payload &lt;- \n                   safe_savant(start_date = date_grid$start_date[.x], \n                               end_date = date_grid$end_date[.x], \n                               type = 'pitcher')\n                 return(payload)\n                 })\n  \n  payload_df &lt;- purrr::map(payload, 'result')\n  \n  number_rows &lt;- \n    purrr::map_df(.x = seq_along(payload_df),\n                  ~{number_rows &lt;- \n                    tibble::tibble(week = .x, \n                                   number_rows = length(payload_df[[.x]]$game_date))\n                  }) %&gt;%\n    dplyr::filter(number_rows &gt; 0) %&gt;%\n    dplyr::pull(week)\n  \n  payload_df_reduced &lt;- payload_df[number_rows]\n  \n  payload_df_reduced_formatted &lt;- \n    purrr::map(.x = seq_along(payload_df_reduced), \n               ~{cols_to_transform &lt;- \n                 c(\"pitcher\", \"fielder_2\", \"fielder_3\",\n                   \"fielder_4\", \"fielder_5\", \"fielder_6\", \"fielder_7\",\n                   \"fielder_8\", \"fielder_9\")\n               df &lt;- \n                 purrr::pluck(payload_df_reduced, .x) %&gt;%\n                 dplyr::mutate_at(.vars = cols_to_transform, as.numeric) %&gt;%\n                 dplyr::mutate_at(.vars = cols_to_transform, function(x) {ifelse(is.na(x), 999999999, x)})\n               character_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"character\") %&gt;%\n                 dplyr::pull(variable)\n               numeric_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"numeric\") %&gt;%\n                 dplyr::pull(variable)\n               integer_columns &lt;- \n                 data_base_column_types %&gt;%\n                 dplyr::filter(class == \"integer\") %&gt;%\n                 dplyr::pull(variable)\n               df &lt;- \n                 df %&gt;%\n                 dplyr::mutate_if(names(df) %in% character_columns, as.character) %&gt;%\n                 dplyr::mutate_if(names(df) %in% numeric_columns, as.numeric) %&gt;%\n                 dplyr::mutate_if(names(df) %in% integer_columns, as.integer)\n               return(df)\n               })\n  \n  combined &lt;- payload_df_reduced_formatted %&gt;%\n    dplyr::bind_rows()\n  \n  return(combined)\n}\n\n\nTo use this function, it is enough to run something like.\n\nstatcast2024 &lt;- annual_statcast_query(2024)\n\n\n\n\n\n\n\nTime and disk space requirements\n\n\n\nScraping a single season of StatCast data can take between 30 and 45 minutes. I highly recommend scraping the data for any season only once and saving the resulting data table in an .RData file that can be loaded into future R sessions.\n\nlibrary(tidyverse)\nstatcast2024 &lt;- annual_statcast_query(2024)\nsave(statcast2024, file = \"statcast2024.RData\")\n\nThese .RData files take between 75MB and 150MB of space. So, if you want to work with several seasons (e.g., going back all the way to 2008, the first season for which pitch tracking data is available), you will need about 2.5GB of storage space on your computer.\n\n\n\n\nWorking with StatCast data\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nIn the 2024 season, we have StatCast data for 784,978 pitches. The dataset records 118 different variables for each pitch. Some of them are contextual variables like game_pk, which is the unique identifier for a game, and game_date, which is the date of the game, while others like batter, pitcher, and fielder_2 list the players involved in the pitch. The dataset also includes information about the pitch trajectory like plate_x and plate_z, which record the horizontal and vertical coordinates of the pitch as it crosses the front edge of home plate, and the pitch outcome The data table also contains 118 variables, many of which are defined in the StatCast documentation. The function annual_statcast_query actually scrapes data not only from the regular season but also from the pre-season and the play-offs. For our analysis, we will focus only on the regular season data. The variable game_type records the type of game in which each pitch was thrown.\n\ntable(statcast2024$game_type, useNA = 'always')\n\n\n     D      F      L      R      S      W   &lt;NA&gt; \n  5182   2488   3540 695136  77056   1576      0 \n\n\nLooking at the StatCast documentation, we see that regular season pitches have game_type==\"R\". We additionally filter out any pitches with nonsensical values like 4 balls or 3 strikes (for 2024, this turns out to be only 1 pitch).\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;% \n  filter(game_type == \"R\") %&gt;%\n  filter(strikes &gt;= 0 & strikes &lt; 3 & \n           balls &gt;= 0 & balls &lt; 4 & \n           outs_when_up &gt;= 0 & outs_when_up &lt; 3) %&gt;%\n  arrange(game_pk, at_bat_number, pitch_number)\n\nWe’re now left with 695,135 regular season pitches.\nFor every pitch, the StatCast dataset records the identities of the batter (batter), pitcher (pitcher), and the other fielders (fielders_2, …, fielders_9). However, it does not identify them by name, instead using an ID number, which is assigned by MLB Advanced Media. We can look up the corresponding player names using a database maintained by the Chadwick Register. The function baseballr::chadwick_player_lu downloads the Chadwick database and stores it as a data table in R. Like with the raw pitch-by-pitch data, I recommend that you download this player identity database once and save the table as an .RData object for future use.\n\nplayer_lookup &lt;-\n  baseballr::chadwick_player_lu() %&gt;%\n  mutate(Name = paste(name_first, name_last))",
    "crumbs": [
      "Lecture 5: Run values in baseball"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#expected-runs",
    "href": "lectures/lecture5.html#expected-runs",
    "title": "Lecture 5: Run values in baseball",
    "section": "Expected Runs",
    "text": "Expected Runs\nWe will encode baserunner configuration using a binary string of length 3. If there is a runner on first base, the first digit will be a 1 and if there is not a runner on first base, the first digit will be a 0. Similarly, the second and third digits respectively indicate whether there are runners on second and third base. So if \\(\\textrm{br} = \"011\"\\) that means that there are runners on second and third base at the beginning of the at-bat but not on first base. The raw StatCast data contains variables on_1b, on_2b, and on_3b. From a quick visual inspection of the dataset (e.g., with statcast2024$on_1b[1:100]), we find many NA values. These correspond to pitches when there is nobody on that particular base. When the value is not NA, it is the numeric id of the batting team player who is on that base. To create the 3-digit binary string encoding baserunner configuration, notice that 1*(!is.na(on_1b)) will return a 1 if there is somone on first base and 0 otherwise. So by pasting together the results of 1*(!is.na(on_1b)), 1*(!is.na(on_2b)), and 1*(!is.na(on_3b)), we can form the 3-digit binary string described above. In the codeblock below, we also rename the column outs_when_up to Outs.\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  mutate(\n    BaseRunner = \n      paste0(1*(!is.na(on_1b)),\n             1*(!is.na(on_2b)),\n             1*(!is.na(on_3b)))) %&gt;%\n  rename(Outs = outs_when_up)\n\nThere are 3 possible values for the number of outs (\\(\\textrm{o} \\in \\{0,1,2\\}\\)) and 8 possible values for the baserunner configuration (\\(\\textrm{br} \\in \\{\"000\", \"100\", \"010\", \"001\", \"110\", \"101\", \"011\", \"111\"\\}\\)). So, there are 24 different values of run expectancy, which is often presented in a table with rows corresponding to baserunner configuration and columns corresponding to outs.\n\nComputing \\(\\rho(\\textrm{o}, \\textrm{br})\\)\nComputing \\(\\rho(\\textrm{o}, \\textrm{br})\\) is conceptually straightforward: we need to divide our observed at-bats into 24 bins, one for each combination of \\((\\textrm{o}, \\textrm{br})\\) and then compute the average value of \\(R\\) within each bin. This is exactly the same “binning-and-averaging” procedure we used to fit our initial XG models in Lecture 2. We will do this using at-bats taken in the first 8 innings of played in the 2021, 2022, and 2023 regular seasons. We focus only on the first 8 innings because the 9th and extra innings are fundamentally different than the others. Specifically, the bottom half of the 9th (or later) innings is only played if the game is tied or the home team is trailing after the top of the 9th inning concludes. In those half-innings, if played, the game stops as soon as a winning run is scored. For instance, say that the home team is trailing by 1 runs in the bottom of the 9th and that there are runners on first and second base. If the batter hits a home run, the at-bat is recorded as resulting in only two runs (the tying run from second and the winning run from first). But the exact same scenario would result in 3 runs in an earlier inning.\n\nComputing runs scored in the half-inning\nSuppose that in a given at-bat \\(a\\) that there are \\(n_{a}\\) pitches. Within at-bat \\(a,\\) for each \\(i = 1, \\ldots, n_{a},\\) let \\(R_{i,a}\\) be the number of runs scored in the half-inning after that pitch (including any runs scored as a result of pitch \\(i\\)). So \\(R_{1,a}\\) is the number of runs scored in the half-inning after the first pitch, \\(R_{2,a}\\) is the number of runs scored subsequent to the second pitch, etc. Our first step towards building the necessary at-bat-level data set will be to append a column of \\(R_{i,a}\\) values to each season’s StatCast data.\nWe start by illustrating the computation using a single half-inning from the Dodgers-Padres game introduced earlier. The code below pulls out all pitches thrown in the top of the 8th inning of the game. During this inning, the Dodgers scored 4 runs.\n\ndodgers_inning &lt;-\n  statcast2024 %&gt;%\n  filter(game_pk == 745444 & inning == 8 & inning_topbot == \"Top\") %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner,\n         bat_score, post_bat_score, events, description, des,\n         type, \n         on_1b, on_2b, on_3b, hc_x, hc_y, hit_location) %&gt;%\n  arrange(at_bat_number, pitch_number)\n\nThe column bat_score records the batting team’s score before each pitch is thrown. The column post_bat_score records the batting team’s score after the the outcome of the pitch. For most of the 25 pitches, we find that bat_score is equal to post_bat_score; this is because only a few pitches result in scoring events.\n\nrbind(bat_score = dodgers_inning$bat_score, post_bat_score = dodgers_inning$post_bat_score)\n\n               [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\nbat_score         1    1    1    1    1    1    1    1    1     1     1     1\npost_bat_score    1    1    1    1    1    1    1    1    1     1     1     1\n               [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\nbat_score          1     1     2     3     3     3     4     5     5     5\npost_bat_score     1     2     3     3     3     4     5     5     5     5\n               [,23] [,24] [,25]\nbat_score          5     5     5\npost_bat_score     5     5     5\n\n\nCross-referencing the table above with the play-by-play data, we see that the Dodgers score their second run after the 14th pitch of the half-inning (on a Enrique Hernández sacrifice fly); their third run on the very next pitch (Gavin Lux grounding into a fielder’s choice); and their fourth and fifth runs on consecutive pitches (on singles by Mookie Betts and Shohei Ohtani).\n\n\n\nDodgers-Padres Play-by-Play\n\n\nWe can verify this by looking at the variable des, which stores a narrative description about what happened during the at-bat.\n\ndodgers_inning$des[c(14,15, 18, 19)]\n\n[1] \"Enrique Hernández out on a sacrifice fly to left fielder José Azocar. Max Muncy scores.\"                                                                                             \n[2] \"Gavin Lux reaches on a fielder's choice, fielded by first baseman Jake Cronenworth. Teoscar Hernández scores. James Outman to 2nd. Fielding error by first baseman Jake Cronenworth.\"\n[3] \"Mookie Betts singles on a ground ball to left fielder José Azocar. James Outman scores. Gavin Lux to 2nd.\"                                                                           \n[4] \"Shohei Ohtani singles on a line drive to left fielder José Azocar. Gavin Lux scores. Mookie Betts to 2nd.\"                                                                           \n\n\nNotice that, because we’ve sorted the pitches in ascending order by at-bat and pitch number, the very last row of the table corresponds to the last pitch of the inning. Accordingly, the last value in the post_bat_score column is the batting team’s score at the end of the inning. Thus, to compute \\(R_{i,a}\\) for all pitches in this inning, it is enough to subtract the bat_score in each row from the last post_bat_score in the table. To access this last value, we use the function last().\n\nlast(dodgers_inning$post_bat_score) - dodgers_inning$bat_score\n\n [1] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 1 0 0 0 0 0 0\n\n\nWe now append a column with these values to our data table dodgers_inning\n\ndodgers_inning &lt;-\n  dodgers_inning %&gt;%\n  mutate(RunsRemaining = last(post_bat_score) - bat_score)\n\n\n\nPutting it all together\nWe’re now ready to extend these calculation to every half-inning of every game in the season. To do this, we will take advantage of the group_by() command in dplyr to apply the same calculation to small groups defined by game and half-inning.\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  group_by(game_pk, inning, inning_topbot) %&gt;% # divide up by game and half-inning\n  arrange(at_bat_number, pitch_number) %&gt;% # arrange pitches by at-bat and pitch-number\n  mutate(RunsRemaining = last(post_bat_score) - bat_score) %&gt;%\n  ungroup()\n\nNow we have the number of runs scored in the half-inning after each pitch. But to compute run expectancy, we need this quantity at the at-bat level and not at the pitch-level. Using our notation from before, note that \\(R_{1,a}\\) is the number of runs scored after the first pitch of at-bat \\(a.\\) So, to compute run expectancy, it is enough to pull out the first pitch from each at-bat (i.e., those pitches with pitch_number == 1) using the filter() function.\n\nexpected_runs &lt;-\n  statcast2024 %&gt;%\n  filter(pitch_number == 1) %&gt;% # get first pitch in every at-bat\n  select(Outs, BaseRunner, RunsRemaining) %&gt;%\n  group_by(Outs, BaseRunner) %&gt;%\n  summarize(rho = mean(RunsRemaining), .groups = \"drop\")\n\nThe table expected_runs contains one row for every combination of outs and base-runner configuration. Traditionally, expected runs is reported using an \\(8\\times 3\\) matrix, with rows corresponding to base-runner configurations and columns corresponding to outs. We can re-format expected_runs to this matrix format using the pivot_wider() function\n\nexpected_runs %&gt;% \n  pivot_wider(names_from = Outs,\n              values_from = rho,\n              names_prefix=\"Outs: \")\n\n# A tibble: 8 × 4\n  BaseRunner `Outs: 0` `Outs: 1` `Outs: 2`\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 000            0.488     0.262    0.0980\n2 001            1.43      0.972    0.352 \n3 010            1.07      0.672    0.347 \n4 011            2.03      1.44     0.612 \n5 100            0.897     0.529    0.228 \n6 101            1.90      1.22     0.502 \n7 110            1.49      0.926    0.449 \n8 111            2.31      1.58     0.815",
    "crumbs": [
      "Lecture 5: Run values in baseball"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#run-value",
    "href": "lectures/lecture5.html#run-value",
    "title": "Lecture 5: Run values in baseball",
    "section": "Run value",
    "text": "Run value\nSuppose a batter comes up to the plate when there 2 outs and no runners on base . Based on the game state at the start of the at-bat (i.e., Outs=2 and BaseRunners='000'), his team can expect to score 0.1 runs in the remainder of the half-inning. Now suppose the batter hits a double, advancing to second base and changing the game state to Outs=2 and BaseRunners='010' According to our expected runs matrix, from this updated state, the batting team expects to score 0.343 runs in the remaining of the half-inning. If, however, the batter had struck out in this plate appearance, then he would have ended the half-inning, from which point his team can expect to score no runs in the remainder of the half-inning. So, on average, the batter earns his team about 0.24 runs, on average, by hitting a double and advancing to second, and loses his team about 0.1 runs, on average, by striking out from the game state Outs=2 and BaseRunners='000'.\n\n\n\n\n\n\nRun value\n\n\n\nThe run value of an at-bat is defined as the the number of runs scored in the at-bat plus the difference in expected runs from the starting to ending state. That is, denoting the number of runs scored in the at-bat as \\(\\textrm{RunsScored}\\) and the starting and ending states as \\((\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\\) and \\((\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}),\\) then \\[\n\\textrm{RunValue} = \\textrm{RunsScored} + \\rho(\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}) - \\rho(\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\n\\]\n\n\nIn a sense, run value rewards batter credits for two things, actually scoring runs and putting their team in positions to score more runs. At the same time, it penalizes batters who do not hit home runs or drive in runs and/or move their team to a less-favorable run expectancy.\nTo do compute the run value of each at-bat in the 2024 season, we must compute\n\nThe number of runs scored during each at-bat\nThe game state (i.e., the number of outs and the base-runner configuration) at the start and end of each at-bat\nThe change in expected runs during the at-bat (i.e., \\(\\rho(\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}) - \\rho(\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\\)).\n\nWe will first develop the necessary code using the data from Dodger’s 8th inning from their game against the Padres. Then, we will deploy that code to the whole statcast2024 table by grouping by game_pk and at_bat_number.\n\nCalculating RunsScored\nStatCast numbers every at-bat within the game and every pitch within each at-bat. To compute the number of runs scored within each at-bat, we will:\n\nSort the pitches by at-bat number and then by pitch number in ascending order\nTake the different between the last value of post_bat_score and first value of bat_score within each at-bat.\n\nLet’s try to verify this by looking at pitches from the third, fourth, and fifth at-bats of Dodgers’ 8th inning against the Padres2\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 61:63) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, bat_score, description, post_bat_score)\n\n── MLB Baseball Savant Statcast Search data from baseballsavant.mlb.com ────────\n\n\nℹ Data updated: 2025-06-21 09:37:16 CDT\n\n\n# A tibble: 7 × 5\n  at_bat_number pitch_number bat_score description   post_bat_score\n          &lt;int&gt;        &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1            61            1         1 ball                       1\n2            61            2         1 ball                       1\n3            61            3         1 ball                       1\n4            61            4         1 ball                       1\n5            62            1         1 foul                       1\n6            62            2         1 hit_into_play              2\n7            63            1         2 hit_into_play              3\n\n\nBased on the description column, we see that the first pitch of at-bat 62 was a foul ball and the second pitch was hit into play. When we look at the corresponding row (row 6) of the table, we see that that Dodgers’ pre-pitch score was 1 (bar_score = 1) and that they scored 1 run as a result of the hit (post_bat_score = 2). Reassuringly, the difference between the value of post_bat_score in row 6 (the last row for at-bat 62) and the value of bat_score in row 5 (the first row for at-bat 62) is 1. We can similarly verify our procedure works in at-bat 61: the fourth value of post_bat_score and the first value of bat_score are equal and the Dodgers did not score in this at-bat.\nWe can apply our procedure to the entirety of the Dodgers’ half-inning\n\ndodgers_inning &lt;-\n  dodgers_inning %&gt;%\n  group_by(at_bat_number) %&gt;%\n  arrange(pitch_number) %&gt;%\n  mutate(RunsScored = last(post_bat_score) - first(bat_score)) %&gt;%\n  ungroup() %&gt;%\n  arrange(at_bat_number, pitch_number)\n\nWe can now apply this formula to all pitches in statcast2024 by grouping by game_pk and at_bat_number\n\nstatcast2024 &lt;-\n  statcast2024 %&gt;%\n  group_by(game_pk, at_bat_number) %&gt;% # divide by at-bats within each game\n  arrange(pitch_number) %&gt;% # sort pitches within at-bat\n  mutate(RunsScored = last(post_bat_score) - first(bat_score)) %&gt;%\n  ungroup() %&gt;% # remove grouping\n  arrange(game_date, game_pk, at_bat_number, pitch_number)\n\n\n\nComputing the starting and ending states\nExcept for the very last pitch in a team’s innings, the ending state of that pitch is, by definition, the starting state of the next pitch. In order to compute \\(\\rho(\\textrm{o}_{\\text{end}}, \\textrm{br}_{\\text{end}}),\\) and \\(\\rho(\\textrm{o}_{\\text{start}}, \\textrm{br}_{\\text{start}})\\) for each at-bat, we will first create a columns in statcast2024 that encode the game state at the beginning and end of the at-bat.\nTo build up our code, let’s continue with our running example of the Dodgers’ 8th inning, focusing on the at the second through fourth at-bats of the inning.\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 60:62) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner)\n\n# A tibble: 9 × 4\n  at_bat_number pitch_number  Outs BaseRunner\n          &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;chr&gt;     \n1            60            1     0 100       \n2            60            2     0 100       \n3            60            3     0 100       \n4            61            1     0 110       \n5            61            2     0 110       \n6            61            3     0 110       \n7            61            4     0 110       \n8            62            1     0 111       \n9            62            2     0 111       \n\n\nWe start by creating new columns recording the Outs and BaseRunner values of the next pitch using the lead function. 3.\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 60:62) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner) %&gt;%\n  mutate(next_Outs = lead(Outs),\n         next_BaseRunner = lead(BaseRunner))\n\n# A tibble: 9 × 6\n  at_bat_number pitch_number  Outs BaseRunner next_Outs next_BaseRunner\n          &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;          \n1            60            1     0 100                0 100            \n2            60            2     0 100                0 100            \n3            60            3     0 100                0 110            \n4            61            1     0 110                0 110            \n5            61            2     0 110                0 110            \n6            61            3     0 110                0 110            \n7            61            4     0 110                0 111            \n8            62            1     0 111                0 111            \n9            62            2     0 111               NA &lt;NA&gt;           \n\n\nNow, within each at-bat, we can look at the last values of next_Outs and next_BaseRunner to figure out the ending state of the at-bat.\n\ndodgers_inning %&gt;%\n  filter(at_bat_number %in% 60:62) %&gt;%\n  arrange(at_bat_number, pitch_number) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner) %&gt;%\n  mutate(next_Outs = lead(Outs),\n         next_BaseRunner = lead(BaseRunner)) %&gt;%\n  group_by(at_bat_number) %&gt;%\n  mutate(endOuts = last(next_Outs),\n         endBaseRunner = last(next_BaseRunner)) %&gt;%\n  select(at_bat_number, pitch_number, Outs, BaseRunner, endOuts, endBaseRunner) %&gt;%\n  ungroup()\n\n# A tibble: 9 × 6\n  at_bat_number pitch_number  Outs BaseRunner endOuts endBaseRunner\n          &lt;int&gt;        &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;        \n1            60            1     0 100              0 110          \n2            60            2     0 100              0 110          \n3            60            3     0 100              0 110          \n4            61            1     0 110              0 111          \n5            61            2     0 110              0 111          \n6            61            3     0 110              0 111          \n7            61            4     0 110              0 111          \n8            62            1     0 111             NA &lt;NA&gt;         \n9            62            2     0 111             NA &lt;NA&gt;         \n\n\nIn Lecture 5 and Lecture 6, we will work not only with the game-state (i.e., the values of Outs and BaseRunner) at the end of every at-bat but also with the actual identities of the base-runners and the location where a ball-in-play was fielded (if the batter hit the ball) at the end of every at-bat. We can following an essentially identical strategy of (i) sorting pitches by at-bat and pitch numbers; (ii) computing the leading value of several columns within each half-inning; (iii) grouping by at-bat number; and (iv) taking the lasts of those leading values.\nThe code below performs this calculation and also pulls out the rows corresponding to just the first pitch of every at-bat.\n\natbat2024 &lt;-\n  statcast2024 |&gt;\n  group_by(game_pk, inning, inning_topbot) |&gt; # divide into half-innings\n  arrange(at_bat_number, pitch_number) |&gt;\n  mutate(next_Outs = lead(Outs), # gets the value from the next pitch in the inning\n         next_BaseRunner = lead(BaseRunner)) |&gt;\n  ungroup() |&gt;\n  group_by(game_pk, at_bat_number) |&gt;\n  arrange(pitch_number) |&gt;\n  mutate(end_Outs = last(next_Outs), # goes to last pitch of each at bat and gets next value of variable\n         end_BaseRunner = last(next_BaseRunner)) |&gt; # that is, the starting value of the first pitch in\n  ungroup() |&gt;\n  arrange(game_date, game_pk, at_bat_number, pitch_number) |&gt;\n  filter(pitch_number == 1) |&gt;\n  mutate(end_bat_score = bat_score + RunsScored, end_fld_score = fld_score) |&gt;\n  select(game_pk, at_bat_number,\n         batter,\n         inning, inning_topbot, Outs, BaseRunner,\n         RunsScored, RunsRemaining,\n         end_Outs, end_BaseRunner,\n         des)\n\n\n\nComputing run-values\nNow that we have a table atbat2024 containing information about the starting and ending states of each at-bat, we are ready to compute run-values. In particular, we can use a join (just like we did with XG in Lecture 2) to add in the values of the starting and ending expected runs.\nBefore doing that, though, we need to deal with the NA’s introduced by lead(). Looking at the at-bats from the Dodger’s 8th inning from our running example, we see that those NA’s correspond to the very last at-bat of the half-inning.\nBefore doing that, though, let’s take a quick look at the rows in the table corresponding to the Dodgers’ 8th inning from our running example\n\natbat2024 %&gt;%\n  filter(game_pk == 745444 & inning == 8 & inning_topbot == \"Top\") %&gt;%\n  select(at_bat_number, Outs, BaseRunner, end_Outs, end_BaseRunner)\n\n# A tibble: 8 × 5\n  at_bat_number  Outs BaseRunner end_Outs end_BaseRunner\n          &lt;int&gt; &lt;int&gt; &lt;chr&gt;         &lt;int&gt; &lt;chr&gt;         \n1            59     0 000               0 100           \n2            60     0 100               0 110           \n3            61     0 110               0 111           \n4            62     0 111               1 110           \n5            63     1 110               1 110           \n6            64     1 110               1 110           \n7            65     1 110               1 110           \n8            66     1 110              NA &lt;NA&gt;          \n\n\nBecause the “end of the inning” state is not one of the 24 combinations of outs and baserunner configurations in the expected_runs table, we’re going to row to that table with Outs=3, BaseRunners='000', and rho = 0 (since the team cannot score any more runs in the inning once it is over!).\n\nexpected_runs &lt;-\n  expected_runs %&gt;%\n  add_row(Outs=3, BaseRunner=\"000\", rho = 0)\n\natbat2024 &lt;-\n  atbat2024 %&gt;%\n  mutate(end_Outs = ifelse(is.na(end_Outs), 3, end_Outs),\n         end_BaseRunner = ifelse(is.na(end_BaseRunner), '000', end_BaseRunner))\n\nWe’re now ready to use a join to append the starting and ending expected runs.\n\nend_expected_runs &lt;- \n  expected_runs %&gt;%\n  rename(end_Outs = Outs,\n         end_BaseRunner = BaseRunner,\n         end_rho = rho)\n\natbat2024 &lt;-\n  atbat2024 %&gt;%\n  left_join(y = expected_runs, by = c(\"Outs\", \"BaseRunner\")) %&gt;%\n  left_join(y = end_expected_runs, by = c(\"end_Outs\", \"end_BaseRunner\"))\nrm(end_expected_runs)\n\nWe can now finally compute run values\n\natbat2024 &lt;-\n  atbat2024 %&gt;%\n  mutate(RunValue = RunsScored + end_rho - rho)",
    "crumbs": [
      "Lecture 5: Run values in baseball"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#aggregate-run-value-leaders",
    "href": "lectures/lecture5.html#aggregate-run-value-leaders",
    "title": "Lecture 5: Run values in baseball",
    "section": "Aggregate run value leaders",
    "text": "Aggregate run value leaders\nNow that we have the run values for every at-bat, we can compute the total run value produced by every batter across the season.\n\ntmp_players &lt;- player_lookup %&gt;% select(key_mlbam, Name)\nre24 &lt;- \n  atbat2024 %&gt;%\n  group_by(batter) %&gt;%\n  summarise(RE24 = sum(RunValue),\n            N = n()) %&gt;%\n  rename(key_mlbam = batter) %&gt;%\n  inner_join(y = tmp_players) %&gt;%\n  select(Name, RE24, N) %&gt;%\n  arrange(desc(RE24))\n\nre24\n\n# A tibble: 649 × 3\n   Name               RE24     N\n   &lt;chr&gt;             &lt;dbl&gt; &lt;int&gt;\n 1 Aaron Judge        89.0   675\n 2 Juan Soto          74.4   693\n 3 Shohei Ohtani      73.1   708\n 4 Bobby Witt         65.9   694\n 5 Brent Rooker       47.9   599\n 6 Vladimir Guerrero  45.0   671\n 7 Ketel Marte        41.2   562\n 8 Kyle Schwarber     40.9   672\n 9 Joc Pederson       39.2   433\n10 José Ramírez       39.1   657\n# ℹ 639 more rows\n\n\nWhen we compare our top-10 to FanGraph’s leaderboard for RE24, we see a lot of overlap. But there are some differences, especially with regards to the number of plate appearances and actual RE24 values. For the latter, FanGraph likely used a different expected run matrix. And the StatCast data is not complete; for instance, it is missing 3 games in which Judge played.",
    "crumbs": [
      "Lecture 5: Run values in baseball"
    ]
  },
  {
    "objectID": "lectures/lecture5.html#footnotes",
    "href": "lectures/lecture5.html#footnotes",
    "title": "Lecture 5: Run values in baseball",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, Ohtani stole second base during the next at-bat, putting his team in an even more favorable position for scoring runs.↩︎\nStatCast assigns each at-bat in a game a unique number. The third, fourth, and fifth at-bats during the Dodger’s 8th inning were the 61st, 62nd, and 63rd at-bats of the game.↩︎\nThe next value of a variable is undefined in the last row of a column, resulting in some NA’s. We’ll deal with those later on.↩︎",
    "crumbs": [
      "Lecture 5: Run values in baseball"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#comparing-xg-models",
    "href": "lectures/lecture4.html#comparing-xg-models",
    "title": "Flexible regression: Building our own XG model",
    "section": "Comparing XG models",
    "text": "Comparing XG models\n\nModel assessment\nTo make this more concrete, suppose we have observed a shots dataset of pairs \\((\\boldsymbol{\\mathbf{x}}_{1}, y_{1}), \\ldots (\\boldsymbol{\\mathbf{x}}_{n}, y_{n})\\) of feature vectors \\(\\boldsymbol{\\mathbf{X}}\\) and binary indicators \\(Y\\) recording whether the shot resulted in a goal or not. Recall from Lecture 3 that a key assumption of XG models is the observed dataset comprises a sample from some infinite super-population of shots. For each feature combination \\(\\boldsymbol{\\mathbf{x}},\\) the corresponding \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) is defined to be the conditional expectation \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}}) := \\mathbb{E}[Y \\vert \\boldsymbol{\\mathbf{X}} = \\boldsymbol{\\mathbf{x}}].\\) Because \\(Y\\) is a binary indicator, \\(\\textrm{XG}(\\boldsymbol{\\mathbf{x}})\\) can be interpretted as the probability that a shot with features \\(\\boldsymbol{\\mathbf{x}}\\) results in a goal.\nNow, suppose we have used our data to fit an XG model. We can go back to every shot \\(i\\) in our dataset and use each fitted model to obtain \\(\\hat{p}_{i}.\\) We would like to assess how close these predictions are to\n\nMisclassification Rate\nGiven a binary observations \\(y_{1}, \\ldots, y_{n}\\) and predicted probabilities \\(\\hat{p}_{1}, \\ldots, \\hat{p}_{n},\\) the misclassification rate is defined as \\[\n\\textrm{MISS} = n^{-1}\\sum_{i = 1}^{n}{\\mathbb{I}(y_{i} \\neq \\mathbb{I}(\\hat{p}_{i} \\geq 0.5))},\n\\] where \\(\\mathbb{I}(\\hat{p}_{i} \\geq 0.5)\\) equals 1 when \\(\\hat{p}_{i} \\geq 0.5\\) and equals 0 otherwise and \\(\\mathbb{I}(y_{i} \\neq \\mathbb{I}(\\hat{p}_{i} \\geq 0.5))\\) equals 1 when \\(y_{i}\\) is not equal to \\(\\mathbb{I}(\\hat{p}_{i} \\geq 0.5)\\) and equals 0 otherwise.\nIn the context of XG, misclassification rate measures the proportion of times we predict an XG higher than 0.5 for. non-goal or an XG lower than 0.5 for a goal. That is, misclassification rate penalizes XG predictions that are on the wrong side of the 50% threshold.\n\nmisclass &lt;- function(y, phat){\n  return( mean( (y != 1*(phat &gt;= 0.5))))\n}\n\ncat(\"BodyPart misclassification\", \n    round(misclass(wi_shots$Y, wi_shots$XG1), digits = 3), \"\\n\")\n\nBodyPart misclassification 0.107 \n\ncat(\"BodyPart+Technique misclassificaiton\", \n    round(misclass(wi_shots$Y, wi_shots$XG2), digits = 3), \"\\n\")\n\nBodyPart+Technique misclassificaiton 0.107 \n\n\nOur two simple models have identical misclassification rates of about 10.7%. At first glance this is a bit surprising because the two models have different predicted XG values\n\ncat(\"Unique XG1 values:\", sort(unique(wi_shots$XG1)), \"\\n\")\n\nUnique XG1 values: 0.1015056 0.1118336 0.1132812 \n\ncat(\"Unique XG2 values:\", sort(unique(wi_shots$XG2)), \"\\n\")\n\nUnique XG2 values: 0 0.04117647 0.06770833 0.08011869 0.08333333 0.1108898 0.113307 0.1213333 0.1363636 0.1621622 0.3333333 \n\n\nNotice that our two simple models output predicted XG values that are all less than 0.5. So, the thresholded values \\(\\mathbb{I}(\\hat{p}_{i} \\geq 0.5)\\) are identical for both models’ \\(\\hat{p}_{i}\\)’s. Just for comparison’s sake, let’s compute the misclassification rate of the proprietary StatsBomb XG model\n\ncat(\"StatsBomb misclassificaiton\", \n    round(misclass(wi_shots$Y, wi_shots$shot.statsbomb_xg), digits = 3), \"\\n\")\n\nStatsBomb misclassificaiton 0.088 \n\n\n\n\nBrier Score & Average log-loss\nOne drawback of misclassification loss is that it only penalizes predictions for being on the wrong side of 50% but does not penalize predictions based on how far away they are from 0 or 1. For instance, if one model predicts that a shot has an XG of 0.999 and another model predicts an XG of 0.501 for the same shot, the misclassification loss is exactly the same.\nThe Brier score is based on the squared error loss, which takes into account how far a predicted probability \\(\\hat{p}\\) is from \\(0\\) and \\(1\\) \\[\n\\text{Brier} = n^{-1}\\sum_{i = 1}^{n}{(y_{i} - \\hat{p}_{i})^2}.\n\\] Whereas misclassification loss (i.e., \\(\\mathbb{I}(y \\neq \\mathbb{I}(\\hat{p} &gt;= 0.5))\\)) penalizes probability forecasts on the wrong side of the 50% threshold, the squared loss \\((y_{i} - \\hat{p})^{2}\\) is larger when \\(\\hat{p}\\) is further away from \\(y.\\)\n\nbrier &lt;- function(y, phat){\n  return(mean( (y - phat)^2 ))\n}\n\ncat(\"BodyPart Brier\", \n    round(brier(wi_shots$Y, wi_shots$XG1), digits = 4), \"\\n\")\n\nBodyPart Brier 0.0953 \n\ncat(\"BodyPart+Technique Brier\", \n    round(brier(wi_shots$Y, wi_shots$XG2) , digits = 4), \"\\n\")\n\nBodyPart+Technique Brier 0.0947 \n\ncat(\"StatsBomb Brier\",\n    round(brier(wi_shots$Y, wi_shots$shot.statsbomb_xg), digits = 4), \"\\n\")\n\nStatsBomb Brier 0.0706 \n\n\nNow, we see that the model that conditions on both body part and technique has an ever-so-slightly smaller Brier score.\nThe average log-loss provides another way to penalize differences between predicted probabilities \\(\\hat{p}\\) and binary outcomes \\(y\\) \\[\n\\textrm{Avg. log-loss} = -1 \\times \\sum_{i = 1}^{n}{\\left[ y_{i} \\times \\log(\\hat{p}_{i}) + (1 - y_{i})\\times\\log(1-\\hat{p}_{i})\\right]}.\n\\] Log-loss penalizes extreme mistakes much more aggressively than the Brier score. In practice, we often threshold \\(\\hat{p}\\) values that are very close to 0 or 1 when computing log-loss\n\nlogloss &lt;- function(y, phat){\n  \n  if(any(phat &lt; 1e-12)) phat[phat &lt; 1e-12] &lt;- 1e-12\n  if(any(phat &gt; 1-1e-12)) phat[phat &gt; 1-1e-12] &lt;- 1e-12\n  return(-1 * mean( y * log(phat) + (1-y) * log(1-phat)))\n}\n\ncat(\"BodyPart Brier:\", \n    round(logloss(wi_shots$Y, wi_shots$XG1), digits = 4), \"\\n\")\n\nBodyPart Brier: 0.3394 \n\ncat(\"BodyPart+Technique Brier:\", \n    round(logloss(wi_shots$Y, wi_shots$XG2) , digits = 4), \"\\n\")\n\nBodyPart+Technique Brier: 0.3358 \n\ncat(\"StatsBomb Brier:\",\n    round(logloss(wi_shots$Y, wi_shots$shot.statsbomb_xg), digits = 4), \"\\n\")\n\nStatsBomb Brier: 0.2521 \n\n\nTypically, we prefer models with **smaller* mis-classification rates, Brier scores, and average log-losses 1.\n\n\n\nTraining and testing\nSo far, we have evaluated our models using the same data on which they were trained.\nTo illustrate, in the code below we first create a copy of wi_shots and then add a column called train containing random 0’s and 1’s. We generate those random 0’s and 1’s in such a way that around 75% of them are equal to 1. We then pull out the training data\n\n# add an id number for every shot\nn &lt;- nrow(wi_shots)\nn_train &lt;- floor(0.75 * n)\nn_test &lt;- n - n_train\n\nwi_shots &lt;-\n  wi_shots |&gt;\n  mutate(id = 1:n)\n\n\nset.seed(478)\ntrain_data &lt;-\n  wi_shots |&gt;\n  slice_sample(n = n_train) |&gt;\n  select(-XG1,-XG2)\ntest_data &lt;-\n  wi_shots |&gt;\n  anti_join(y = train_data, by = \"id\") |&gt;\n  select(-XG1, -XG2)\n\nAs a sanity check, we can check whether any of the id’s in test_data are also in train_data:\n\nany(train_data$id %in% test_data$id)\n\n[1] FALSE\n\n\nNow that we have a single training and testing split, let’s fit our two simple XG models and then computing the average training and testing losses\n\nmodel1 &lt;- \n  train_data |&gt;\n  group_by(shot.body_part.name) |&gt;\n  summarise(XG1 = mean(Y))\nmodel2 &lt;-\n  train_data |&gt;\n  group_by(shot.body_part.name, shot.technique.name) |&gt;\n  summarise(XG2 = mean(Y), .groups = \"drop\")\n\ntrain_data &lt;-\n  train_data |&gt;\n  inner_join(y = model1, by = c(\"shot.body_part.name\")) |&gt;\n  inner_join(y = model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))\n\ntest_data &lt;-\n  test_data |&gt;\n  inner_join(y = model1, by = c(\"shot.body_part.name\")) |&gt;\n  inner_join(y = model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))\n\ncat(\"BodyPart train log-loss:\",\n    round(logloss(train_data$Y, train_data$XG1), digits = 4), \n    \"test log-loss:\",\n    round(logloss(test_data$Y, test_data$XG1), digits = 4), \"\\n\")\n\nBodyPart train log-loss: 0.3392 test log-loss: 0.3405 \n\ncat(\"BodyPart+Technique train log-loss:\",\n    round(logloss(train_data$Y, train_data$XG2), digits = 4), \n    \"BodyBart+Technique test log-loss:\",\n    round(logloss(test_data$Y, test_data$XG2), digits = 4), \"\\n\")\n\nBodyPart+Technique train log-loss: 0.3352 BodyBart+Technique test log-loss: 0.3637 \n\n\nFor this training/testing split, we find that although conditioning on both body-part and technique produced a slightly smaller training log-loss than conditioning only on body-part, the more complex model had larger testing loss. In other words, we obtained slightly more accurate out-of-sample predictions with the simpler model than the more complex model. This would suggest that the more complex model overfit the training data\nOf course, this was baesd on just training/testing split. We commonly do the same calculation using multiple training/testing splits and look at the average losses.\n\nn_sims &lt;- 10\ntrain_logloss &lt;- \n  matrix(nrow = 2, ncol = n_sims,\n         dimnames = list(c(\"XG1\",\"XG2\"), c()))\ntest_logloss &lt;- \n  matrix(nrow = 2, ncol = n_sims,\n         dimnames = list(c(\"XG1\",\"XG2\"), c()))\n\nfor(r in 1:n_sims){\n  set.seed(479+r) # for replicability\n  train_data &lt;-\n    wi_shots |&gt;\n    slice_sample(n = n_train) |&gt;\n    select(-XG1,-XG2)\n  test_data &lt;-\n    wi_shots |&gt;\n    anti_join(y = train_data, by = \"id\") |&gt;\n    select(-XG1, -XG2)\n  model1 &lt;- \n    train_data |&gt;\n    group_by(shot.body_part.name) |&gt;\n    summarise(XG1 = mean(Y))\n  \n  model2 &lt;-\n    train_data |&gt;\n    group_by(shot.body_part.name, shot.technique.name) |&gt;\n    summarise(XG2 = mean(Y), .groups = \"drop\")\n\n  train_data &lt;-\n    train_data |&gt;\n    inner_join(y = model1, by = c(\"shot.body_part.name\")) |&gt;\n    inner_join(y = model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))\n\n  test_data &lt;-\n    test_data |&gt;\n    inner_join(y = model1, by = c(\"shot.body_part.name\")) |&gt;\n    inner_join(y = model2, by = c(\"shot.body_part.name\", \"shot.technique.name\"))\n  \n  train_logloss[\"XG1\", r] &lt;- \n    logloss(train_data$Y, train_data$XG1)\n  train_logloss[\"XG2\",r] &lt;-\n    logloss(train_data$Y, train_data$XG2)\n  \n  test_logloss[\"XG1\", r] &lt;- \n    logloss(test_data$Y, test_data$XG1)\n  test_logloss[\"XG2\",r] &lt;-\n    logloss(test_data$Y, test_data$XG2)\n}\ncat(\"XG1 training logloss:\", round(mean(train_logloss[\"XG1\",]), digits = 4), \"\\n\")\n\nXG1 training logloss: 0.3424 \n\ncat(\"XG2 training logloss:\", round(mean(train_logloss[\"XG2\",]), digits = 4), \"\\n\")\n\nXG2 training logloss: 0.3378 \n\ncat(\"XG1 test logloss:\", round(mean(test_logloss[\"XG1\",]), digits = 4), \"\\n\")\n\nXG1 test logloss: 0.3314 \n\ncat(\"XG2 test logloss:\", round(mean(test_logloss[\"XG2\",]), digits = 4), \"\\n\")\n\nXG2 test logloss: 0.3448 \n\n\nWe see exactly the same pattern: our more complex model seemed to do slightly worse than our simplest model that accounted for",
    "crumbs": [
      "Flexible regression: Building our own XG model"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#logistic-regression",
    "href": "lectures/lecture4.html#logistic-regression",
    "title": "Flexible regression: Building our own XG model",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\nset.seed(478)\ntrain_data &lt;-\n  wi_shots |&gt;\n  slice_sample(n = n_train) |&gt;\n  select(-XG1,-XG2)\ntest_data &lt;-\n  wi_shots |&gt;\n  anti_join(y = train_data, by = \"id\") |&gt;\n  select(-XG1, -XG2)\n\nfit1 &lt;-\n  glm(Y~DistToGoal, data = train_data,\n      family = binomial(\"logit\"))\ntrain_pred1 &lt;- predict(object = fit1,\n                       newdata = train_data,\n                       type = \"response\")\ntest_pred1 &lt;-\n  predict(object = fit1,\n          newdata = test_data,\n          type = \"response\")\n\nfit2 &lt;- \n  glm(Y ~ DistToGoal+shot.body_part.name+shot.technique.name,\n      data = train_data,\n      family = binomial(\"logit\"))\n\ntest_pred2 &lt;-\n  predict(object = fit2,\n          newdata = test_data,\n          type = \"response\")\n\n\n\nlogloss(train_data$Y, train_pred1)\n\n[1] 0.3047536\n\nlogloss(test_data$Y, test_pred1)\n\n[1] 0.3087526\n\n\n\nwi_shots &lt;-\n  wi_shots |&gt;\n  mutate(shot.body_part.name = factor(shot.body_part.id),\n         shot.technique.name = factor(shot.technique.name))\n\nSo distance seems to help a little bit! But, the logistic regression model we just fit makes the strong assumption the change in XG between left & right footed shots is the same from these two locations.\nBut hang-on, this; let’s look at the triangle formed between shot and the goal; from this distance, you have to be much more precise just to get the ball on target. We’ll construct a new feature – ConeAngle – that measures precisely this angle. It’s not hard to compute with a bit trigonometry.\n\nSpatial smoothing with generalized additive models\nThe above model accounted for shot location somewhat indirectly through distance and ConeAngle. A somewhat more general model would take the form BodyPart + Technique + f(X,Y) for some to-be-estimated function \\(f\\). We would moreover assume that \\(f\\) is smooth, in the sense that moving from one part of the pitch to another\nWe can also visualize these estimates\n\n\nIncorporating more spatial features",
    "crumbs": [
      "Flexible regression: Building our own XG model"
    ]
  },
  {
    "objectID": "lectures/lecture4.html#tree-based-modeling",
    "href": "lectures/lecture4.html#tree-based-modeling",
    "title": "Flexible regression: Building our own XG model",
    "section": "Tree-based modeling",
    "text": "Tree-based modeling",
    "crumbs": [
      "Flexible regression: Building our own XG model"
    ]
  },
  {
    "objectID": "lectures/lecture6.html#adjusted-run-value",
    "href": "lectures/lecture6.html#adjusted-run-value",
    "title": "Wins Above Replacement I",
    "section": "Adjusted Run Value",
    "text": "Adjusted Run Value",
    "crumbs": [
      "Wins Above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture6.html#baserunning",
    "href": "lectures/lecture6.html#baserunning",
    "title": "Wins Above Replacement I",
    "section": "Baserunning",
    "text": "Baserunning",
    "crumbs": [
      "Wins Above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture6.html#batting",
    "href": "lectures/lecture6.html#batting",
    "title": "Wins Above Replacement I",
    "section": "Batting",
    "text": "Batting",
    "crumbs": [
      "Wins Above Replacement I"
    ]
  },
  {
    "objectID": "lectures/lecture7.html",
    "href": "lectures/lecture7.html",
    "title": "WAR II: Defensive Credit & Defining Replacement-Level",
    "section": "",
    "text": "How difficult is a ball-in-play (BIP) to field? Intuitively, if the pitcher gives up a home run, the remaining fielders should not get any blame. And if a fielder makes an error, the pitcher should not get any blame.\nOf the total \\(-\\delta_{i}\\) we need to",
    "crumbs": [
      "WAR II: Defensive Credit & Defining Replacement-Level"
    ]
  },
  {
    "objectID": "lectures/lecture7.html#probability-of-making-an-out",
    "href": "lectures/lecture7.html#probability-of-making-an-out",
    "title": "WAR II: Defensive Credit & Defining Replacement-Level",
    "section": "Probability of making an out",
    "text": "Probability of making an out\nWe will fit a generalized additive model, similar to what To do this, we will go back to our pitch-level data and pull out those pitches that resulted in hits. Later, we will want to join this to our atbat table so that there’s a column for p(fielded out)\nThen, we will grab the coordinates where the ball was fielded and whether an out was made (likely based on events)",
    "crumbs": [
      "WAR II: Defensive Credit & Defining Replacement-Level"
    ]
  },
  {
    "objectID": "lectures/lecture7.html#fielding-run-values",
    "href": "lectures/lecture7.html#fielding-run-values",
    "title": "WAR II: Defensive Credit & Defining Replacement-Level",
    "section": "Fielding run values",
    "text": "Fielding run values\n\n\nPitching run values",
    "crumbs": [
      "WAR II: Defensive Credit & Defining Replacement-Level"
    ]
  },
  {
    "objectID": "lectures/lecture7.html#replacement-level",
    "href": "lectures/lecture7.html#replacement-level",
    "title": "WAR II: Defensive Credit & Defining Replacement-Level",
    "section": "Replacement Level",
    "text": "Replacement Level\nMost teams carry 13 position players and 12 pitchers, we designate the \\(30 \\times 13 = 390\\) position players with the most PAs to be the non-replacement players. Everyone else is replacement level\nWe can compute the average RAA for all replacement level players. Then we look at (RAA_p - RAA_shadow)/10 to be WAR",
    "crumbs": [
      "WAR II: Defensive Credit & Defining Replacement-Level"
    ]
  }
]